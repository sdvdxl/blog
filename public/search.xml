<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[本站启用https]]></title>
      <url>http://todu.top/other/%E6%9C%AC%E7%AB%99%E5%90%AF%E7%94%A8https/</url>
      <content type="html"><![CDATA[<h1 id="本站启用https访问，同时可以使用http，建议使用https。另外因为迁移到阿里云美国西部，访问速度有点下降。"><a href="#本站启用https访问，同时可以使用http，建议使用https。另外因为迁移到阿里云美国西部，访问速度有点下降。" class="headerlink" title="本站启用https访问，同时可以使用http，建议使用https。另外因为迁移到阿里云美国西部，访问速度有点下降。"></a>本站启用https访问，同时可以使用http，建议使用https。另外因为迁移到阿里云美国西部，访问速度有点下降。</h1>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[SpringXD HA 配置]]></title>
      <url>http://todu.top/spring/SpringXD%20HA%20%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<p><a href="http://docs.spring.io/spring-xd/docs/1.3.1.RELEASE/reference/html" target="_blank" rel="external">SpringXD官方文档</a> 上说的不是很清楚，而且有些配置（如 配置 <code>hadoop</code> namenode ha ）并没有在上面说明，只是简单的说明了怎么配置 <code>namenode</code> ，如果没有ha配置，那么在生产环境中会令人头痛。</p>
<h1 id="XD-Admin-HA"><a href="#XD-Admin-HA" class="headerlink" title="XD Admin HA"></a>XD Admin HA</h1><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>在 <a href="http://docs.spring.io/spring-xd/docs/1.3.1.RELEASE/reference/html/#_configuring_spring_xd_for_high_availabilty_ha" target="_blank" rel="external">官方文档</a> 中，有说如何配置，就是通过启动多个<code>admin</code> ，然后通过 <code>zookeeper</code> 管理。<br><code>Spring XD</code> 要求只有一个主节点来和 <code>Container</code> 交互，例如 <code>Stream</code> 发布等。同时，这些操作都是按顺序处理的。假如只有一个 <code>admin</code> ，那么就存在单点失败的风险，因此，在生产环境中推荐做法是启动 2 个或者多 <code>admin</code> 。注意：在有多个 <code>admin</code> 节点的时候，每个 <code>admin</code> 都可以处理 <a href="http://docs.spring.io/spring-xd/docs/1.3.1.RELEASE/reference/html/#REST-API" target="_blank" rel="external">REST</a> 请求，但是只有一个实例会作为 <code>Leader</code> 处理请求并更新运行时的状态。如果 <code>Leader</code> 宕掉，另一个可用的admin就会成为新的 <code>Leader</code> 来接管任务。当然，Spring XD 的HA不只是他自身要求ha，还需要依赖外部服务，如：<code>zookeeper</code>，<code>MessageBus</code> 等 HA 配置。</p>
<h2 id="配置信息"><a href="#配置信息" class="headerlink" title="配置信息"></a>配置信息</h2><p>如果要配置 <code>admin</code> 的 ha，那么启动多个 <code>admin</code> 即可，但是请注意，如果是在同一台机器上部署多个<code>admin</code>，需要在启动时候添加如下参数以防止和默认的端口（<code>9393</code>）冲突：<br><code>--httpPort</code> 用来指定rest api端口<br><code>--mgmtPort</code> 用来指定管理端口<br>如果在不同机器上启动，只需配置相同的配置文件，然后启动即可。</p>
<h1 id="XD-Container-HA"><a href="#XD-Container-HA" class="headerlink" title="XD Container HA"></a>XD Container HA</h1><p>当添加 <code>Container</code> 的时候，Spring XD 可以动态水平扩展，也就是说不需要额外什么操作，只需像第一次启动 <code>Container</code> 一样输入命令 <code>bin/xd-container</code> 启动即可。</p>
<h1 id="XD-Hadoop-namenode-HA"><a href="#XD-Hadoop-namenode-HA" class="headerlink" title="XD Hadoop namenode HA"></a>XD Hadoop namenode HA</h1><p>如果 xd 中创建 <code>stream</code> 或者其他任务是用到了 <code>hdfs</code> 的功能，那么要配置 <code>hadoop</code> 的<code>namenode</code> ，要在 <code>xd/config/servers.xml</code>中的 <code>spring.hadoop.fsUri</code> 的配置项中配置。注意，这个地方只允许配置一个 <code>host</code>，如果有备用 <code>namenode</code> ，是不允许配置在这个地方的。但是这样配置是有问题的，就是存在 <code>hadoop</code> 的 <code>namenode</code> 主从切换后 xd 的 <code>stream</code> 无法写入 <code>hdfs</code> 或者读取 <code>hdfs</code> 的故障。要解决这个问题，我们要再 <code>xd/config/hadoop.properties</code> 中配置如下配置项：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dfs.nameservices=MyCluster</span><br><span class="line">dfs.ha.namenodes.MyCluster=nn1,nn2</span><br><span class="line">dfs.namenode.rpc-address.MyCluster.nn2=hadoop-master1-host:8020</span><br><span class="line">dfs.namenode.rpc-address.MyCluster.nn1=hadoop-master2-host:8020</span><br><span class="line">dfs.client.failover.proxy.provider.MyCluster=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</span><br></pre></td></tr></table></figure></p>
<p>其中，配置项中所有的 <code>MyCluster</code> 要换成自己项目中 hadoop 集群的名字，然后在 <code>xd/config/servers.xml</code> 中 <code>spring.hadoop.fsUri</code> 值配置成 <code>hdfs://MyCluster:8020</code>（注意<code>8020</code>端口换成自己配置的），<code>hadoop-master1-host</code> 和 <code>hadoop-master1-host</code> 换成自己集群的 hadoop的 master 的主机名字或者ip。这样配置后，重新启动 <code>admin</code> 和 <code>container</code> 就会自动检测 hadoop 的 <code>namenode</code> 主从，并自行切换。<br>如果要在 <code>xd-shell</code>中使用，需要登录shell之后（如果有安全设置，还需要先用密码登录成功），输入一下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hadoop config props set --property dfs.nameservices=MyCluster</span><br><span class="line">hadoop config props set --property dfs.ha.namenodes.MyCluster=nn1,nn2</span><br><span class="line">hadoop config props set --property dfs.namenode.rpc-address.MyCluster.nn1=hadoop-master1-host:8020</span><br><span class="line">hadoop config props set --property dfs.namenode.rpc-address.MyCluster.nn2=hadoop-master2-host:8020</span><br><span class="line">hadoop config props set --property dfs.client.failover.proxy.provider.MyCluster=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</span><br><span class="line">hadoop config fs --namenode hdfs://MyCluster</span><br></pre></td></tr></table></figure></p>
<p><code>MyCluster</code>，<code>hadoop-master1-host</code> 和 <code>hadoop-master2-host</code> 同上配置。对于 shell 来说，单纯配置 hadoop 的主 <code>namenode</code>也是可以的，因为这个配置只是对 shell 起作用。如果觉得每次打开shell都要输入上面几行配置太繁琐的话，可以将 <code>xd/config/hadoop.properties</code> 中配置的项目添加一份到<code>shell/config/hadoop.properties</code> 即可，这样在shell中操作hdfs，只需配置 <code>hadoop config fs --namenode hdfs://MyCluster:8020</code> 即可。</p>
<h2 id="附言"><a href="#附言" class="headerlink" title="附言"></a>附言</h2><p>对于如何在xd中使用hadoop的namenode ha配置，xd 官方文档中并未见说明，而是百般Goole之后得到的结果，而且由于xd资料尚少，搜索结果不佳，最后通过搜索关键词 <code>xd namenode fail</code> 才找到解决方案，<a href="https://jira.spring.io/browse/XD-1745" target="_blank" rel="external">请参见这里</a>。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[sbt源配置]]></title>
      <url>http://todu.top/spark/sbt%E6%BA%90%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<h1 id="sbt-默认源下载有点慢，我们可以调教它，让它从我们自己配置的源下载。"><a href="#sbt-默认源下载有点慢，我们可以调教它，让它从我们自己配置的源下载。" class="headerlink" title="sbt 默认源下载有点慢，我们可以调教它，让它从我们自己配置的源下载。"></a>sbt 默认源下载有点慢，我们可以调教它，让它从我们自己配置的源下载。</h1><h2 id="配置源"><a href="#配置源" class="headerlink" title="配置源"></a>配置源</h2><p>在 <code>.sbt</code> （默认是在用户名下）文件夹中创建 <code>repositories</code> 文件，然后添加如下内容:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[repositories]</span><br><span class="line">  local</span><br><span class="line">  my: http://o8r69qphn.bkt.clouddn.com/</span><br><span class="line">  Nexus osc: http://maven.oschina.net/content/groups/public/</span><br><span class="line">  Nexus osc thirdparty: http://maven.oschina.net/content/repositories/thirdparty/</span><br><span class="line">  central: http://central.maven.org/maven2/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[ivy]</span><br><span class="line">  local</span><br><span class="line">  my: http://o8r69qphn.bkt.clouddn.com/</span><br><span class="line">  Nexus osc: http://maven.oschina.net/content/groups/public/</span><br><span class="line">  Nexus osc thirdparty: http://maven.oschina.net/content/repositories/thirdparty/</span><br><span class="line">  central: http://central.maven.org/maven2/</span><br><span class="line">  TypeSafe: https://oss.sonatype.org/content/repositories/releases/</span><br><span class="line">  #proxy库</span><br><span class="line">  typesafe-ivy-releases: http://dl.bintray.com/typesafe/ivy-releases/</span><br><span class="line">  typesafe-maven-releases: http://dl.bintray.com/typesafe/maven-releases/</span><br><span class="line">  typesafe-sbt-plugin-releases: http://dl.bintray.com/sbt/sbt-plugin-releases/</span><br><span class="line"></span><br><span class="line">  #group库</span><br><span class="line">  ivy-releases : typesafe-ivy-releases,typesafe-sbt-plugin-releases</span><br></pre></td></tr></table></figure></p>
<p>上面 <code>repositories</code> 是说加载maven镜像中的库文件从这个标签下的路径中找， <code>local</code> 代表从本地中找，默认是 <code>.M2</code> 中，下面的都是自定义源，名字随便取。<br>下面 <code>ivy</code> 是加载ivy库的。</p>
<h2 id="修改加载配置项"><a href="#修改加载配置项" class="headerlink" title="修改加载配置项"></a>修改加载配置项</h2><p>单纯修改上面的源还不足以让sbt加载我们的源。打开 sbt 软件安装位置下的 <code>conf/sbtopts</code> 文件，在其中添加：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Dsbt.override.build.repos=true</span><br></pre></td></tr></table></figure></p>
<p>然后就可以生效了。</p>
<p><strong> 没有深入研究，如果有错还请指出 </strong></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Linux shell 命令]]></title>
      <url>http://todu.top/linux/Linux-Shell-%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<h2 id="lsof"><a href="#lsof" class="headerlink" title="lsof"></a>lsof</h2><p>适用于ip4</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof -Pnl +M -i4 | grep port</span><br></pre></td></tr></table></figure>
<p>适用于ip6</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof -Pnl +M -i6 | grep port</span><br></pre></td></tr></table></figure>
<h2 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h2><p>杀掉名字一样的java进程<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps |grep SparkSubmit | awk &apos;&#123;print &quot;kill -9 &quot; $1&#125;&apos; | sh</span><br></pre></td></tr></table></figure></p>
<p>如果仅仅是打印命令，则后面的管道和sh不需要加，如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps |grep SparkSubmit | awk &apos;&#123;print &quot;kill -9 &quot; $1&#125;&apos;</span><br></pre></td></tr></table></figure></p>
<h2 id="find"><a href="#find" class="headerlink" title="find"></a>find</h2><p>删除找到的符合条件的文件（或者目录）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -iname target -exec rm -rf &#123;&#125; \;</span><br></pre></td></tr></table></figure></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[sbt-idea-入门及配置]]></title>
      <url>http://todu.top/spark/sbt-idea-%E5%85%A5%E9%97%A8%E5%8F%8A%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<h1 id="Java-环境配置"><a href="#Java-环境配置" class="headerlink" title="Java 环境配置"></a>Java 环境配置</h1><p>这个就不多说了，这是前提条件，请自行安装后配置正确，如果不清楚请自行搜索 <strong>java 环境变量配置</strong> 相关问题。</p>
<h1 id="Scala-配置"><a href="#Scala-配置" class="headerlink" title="Scala 配置"></a>Scala 配置</h1><p>首先要要配置 scala 环境。从<a href="http://scala-lang.org/" target="_blank" rel="external">官方</a>地址下载，这里我们使用scala2.10.6版本，所以<a href="http://scala-lang.org/download/2.10.6.html" target="_blank" rel="external">从这里下载</a>对应的平台版本。Windows请下载 <a href="http://downloads.lightbend.com/scala/2.10.6/scala-2.10.6.zip" target="_blank" rel="external">scala-2.10.6.zip</a> ，MacOS和Linux请下载 <a href="http://downloads.lightbend.com/scala/2.10.6/scala-2.10.6.tgz" target="_blank" rel="external">scala-2.10.6.tgz</a> 。</p>
<p>下载完成后，解压到一个目录，然后配置环境变量 <code>SCALA_HOME</code> ，把scala的解压后的绝对路径配置到 <code>SCALA_HOME</code> ，然后增加 <code>PATH</code> 的配置。以下以 WIndows 和 Linux 举例来说，假如这里解压后得到的文件夹为 <code>scala-2.10.6</code>。</p>
<h2 id="Windows-环境"><a href="#Windows-环境" class="headerlink" title="Windows 环境"></a>Windows 环境</h2><p>假如 <code>scala-2.10.6</code> 文件夹放在了 <code>C:\</code>目录下，那么新增 <code>SCALA_HOME</code> 的值为 <code>C:\scala-2.10.6</code> ，然后找到 <code>PATH</code> 这个环境变量， 在已有的值后面添加 <code>;%SCALA_HOME%\bin</code> （注意前面的分号），重新打开一个新的命令行窗口即可操作。关于windows环境变量的其他说明情自行补脑，这里就不多啰嗦了。</p>
<h2 id="Linux-和-Mac-环境"><a href="#Linux-和-Mac-环境" class="headerlink" title="Linux 和 Mac 环境"></a>Linux 和 Mac 环境</h2><p>这里假定我们 <code>scala-2.10.6</code> 的 scala 目录存放在 <code>/usr/local/</code> 下，绝对路径就是 <code>/usr/local/scala-2.10.6</code> 。</p>
<h3 id="Bash-环境"><a href="#Bash-环境" class="headerlink" title="Bash 环境"></a>Bash 环境</h3><p>bash 环境下可以修改 <code>~/.bashrc</code> 或者 <code>/etc/profile</code> 文件，添加一下内容：             </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SCALA_HOME=/usr/<span class="built_in">local</span>/scala-2.10.6</span><br><span class="line">PATH=<span class="variable">$PATH</span>:<span class="variable">$SCALA_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SCALA_HOME PATH</span><br></pre></td></tr></table></figure>
<p>然后执行 <code>source ~/.bashrc</code> 或者 <code>source /etc/profile</code> 即可。</p>
<h3 id="Zsh-环境"><a href="#Zsh-环境" class="headerlink" title="Zsh 环境"></a>Zsh 环境</h3><p>如果你的终端bash用的是 zsh ，那么需要在 <code>~/.zshrc</code> 文件中增加上述内容，然后执行 <code>source ~/.zshrc</code> 即可。</p>
<h1 id="Sbt-配置"><a href="#Sbt-配置" class="headerlink" title="Sbt 配置"></a>Sbt 配置</h1><p><a href="http://www.scala-sbt.org/" target="_blank" rel="external">官方地址</a>，<a href="http://www.scala-sbt.org/download.html" target="_blank" rel="external">从这里下载</a>，如果是MacOS的话，可以依照这里提示的方法进行快捷安装，如果是其他平台或者想手动配置，<a href="https://dl.bintray.com/sbt/native-packages/sbt/0.13.11/sbt-0.13.11.zip" target="_blank" rel="external">点击这里直接下载</a>即可。</p>
<p>下载完成并解压，得到文件夹 <code>sbt</code>。</p>
<h2 id="Windows-环境-1"><a href="#Windows-环境-1" class="headerlink" title="Windows 环境"></a>Windows 环境</h2><p>假如我们将 <code>sbt</code> 文件夹放到了 <code>C:\</code>目录下。新增环境变量 <code>SBT_HOME</code> 值为 <code>C:\sbt</code>， 在 <code>PATH</code> 变量值后面添加 <code>;%SBT_HOME%\bin</code>，重新打开一个新的命令行窗口即可。</p>
<h2 id="Linux-或者-Mac-环境"><a href="#Linux-或者-Mac-环境" class="headerlink" title="Linux 或者 Mac 环境"></a>Linux 或者 Mac 环境</h2><p>这里假定我们将 <code>sbt</code> 目录放在了 <code>/usr/local/</code> 目录下。同上面配置 scala 环境变量一样。</p>
<h3 id="Bash-环境-1"><a href="#Bash-环境-1" class="headerlink" title="Bash 环境"></a>Bash 环境</h3><p>编辑 <code>~/.bashrc</code> 或者 <code>/etc/profile</code> ，新增以下内容:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SBT_HOME=/usr/<span class="built_in">local</span>/sbt</span><br><span class="line">PATH=<span class="variable">$PATH</span>:<span class="variable">$SBT_HOEM</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SBT_HOME PATH</span><br></pre></td></tr></table></figure>
<p>然后执行 <code>source ~/.bashrc</code> 或者 <code>source /etc/profile</code> 即可生效。</p>
<h3 id="Zsh-环境-1"><a href="#Zsh-环境-1" class="headerlink" title="Zsh 环境"></a>Zsh 环境</h3><p>编辑 <code>~/.zshrc</code>， 添加上面的内容并保存后，执行 <code>source ~/.zshrc</code> 即可生效。</p>
<h2 id="示例程序"><a href="#示例程序" class="headerlink" title="示例程序"></a>示例程序</h2><h3 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h3><p>在随意一个地方创建一个文件夹，名字为 <code>spark-sbt-demo</code> ，下面是目录结构：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">spark-sbt-demo                                                                                                                                                                         </span><br><span class="line">├── build.sbt</span><br><span class="line">├── project</span><br><span class="line">│   ├── build.properties</span><br><span class="line">│   └── plugins.sbt</span><br><span class="line">└── src</span><br><span class="line">    ├── main</span><br><span class="line">        ├── scala</span><br><span class="line">           └── WordCount.scala</span><br></pre></td></tr></table></figure>
<p>build.sbt 文件中添加如下内容（注意每行要用空行隔开）：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">name := <span class="string">"spark-sbt-demo"</span></span><br><span class="line"></span><br><span class="line">version := <span class="string">"1.0"</span></span><br><span class="line"></span><br><span class="line">scalaVersion := <span class="string">"2.10.6"</span></span><br><span class="line"></span><br><span class="line">organization := <span class="string">"spark.demo"</span></span><br><span class="line"></span><br><span class="line">version := <span class="string">"1.0.0-SNAPSHOT"</span></span><br><span class="line"></span><br><span class="line">libraryDependencies += <span class="string">"org.apache.spark"</span> % <span class="string">"spark-core_2.10"</span> % <span class="string">"1.6.1"</span> % <span class="string">"provided"</span></span><br></pre></td></tr></table></figure>
<p>WordCount.scala 文件内容：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span><br><span class="line">  * Created by sdvdxl on 16/5/11.</span><br><span class="line">  */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"spark-sbt-demo"</span>).setMaster(<span class="string">"local[*]"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc  = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    sc.textFile(<span class="string">"src/main/scala/WordCount.scala"</span>).flatMap(_.split(<span class="string">" "</span>)).map(word=&gt;(word,<span class="number">1</span>)).reduceByKey(_+_).foreach(println)</span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>build.properties 文件内容 ：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbt.version = 0.13.11</span><br></pre></td></tr></table></figure>
<p>plugins.sbt 文件先保持为空。</p>
<p>至此，我们已经创建了一个 sbt 机构的项目。</p>
<p>接下来会说明使用sbt下载依赖，使用 idea 创建 sbt 项目，在idea中如何运行sbt管理的 spark app。</p>
<h2 id="Sbt-的基本使用"><a href="#Sbt-的基本使用" class="headerlink" title="Sbt 的基本使用"></a>Sbt 的基本使用</h2><p>上面我们创建了一个用 sbt 管理的 spark app 项目，如果想要提交到spark中运行，那么需要打包成jar包，好在 sbt 本身或者插件提供了这样的功能。</p>
<h3 id="应用打包"><a href="#应用打包" class="headerlink" title="应用打包"></a>应用打包</h3><p>打开命令行，切换到该项目目录下，然后输入 <code>sbt</code> 之后，进入 sbt 的交互中，然后输入 <code>package</code> ，开始打包，最后如果看到类似</p>
<blockquote>
<p>[info] Done packaging.<br>  [success] Total time: 11 s, completed 2016-5-11 12:32:09</p>
</blockquote>
<p>字样，那么说明打包成功，打成的 jar 包在上面的日志中可以找到。</p>
<h3 id="第三方-jar-统一打包"><a href="#第三方-jar-统一打包" class="headerlink" title="第三方 jar 统一打包"></a>第三方 jar 统一打包</h3><p>在写应用的时候，我们不只是用到 <code>spark</code> 自身的 jar 包，还会用到好多其他第三方类库，那么，在提交应用到 spark 运行的时候，这些第三方依赖也需要一并提交上去，否则会出现找不到类的问题。如果依赖少的话，直接将这些 jar 包直接一个一个提交上去也没问题，但是一旦依赖了大量的类库，这种方法显然是低效费力的，那么怎么才能将这些所有的第三方依赖打成一个 jar 包呢？</p>
<p>sbt 本身没有提供这样的功能，但是我们可以依靠相应的插件完成此操作。记得上面有个文件内容留空的 <code>plugins.sbt</code> 文件吗？这个文件中可以配置我们想要完成特定功能的插件，现在我们在其中添加如下内容：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">addSbtPlugin(<span class="string">"com.eed3si9n"</span> % <span class="string">"sbt-assembly"</span> % <span class="string">"0.14.2"</span>)</span><br></pre></td></tr></table></figure>
<p>然后重新 进入 sbt 交互式环境，输入 <code>assemblyPackageDependency</code> 回车，稍后将看到类似如下输出：    </p>
<blockquote>
<p>[info] Done packaging.<br>  [success] Total time: 41 s, completed 2016-5-11 13:36:37</p>
</blockquote>
<p>这样就成功的将所有依赖的第三方类库打包到一个 jar 包中了，具体打包的文件可以在上面的日志中看到。</p>
<h2 id="使用-idea-创建-sbt-项目"><a href="#使用-idea-创建-sbt-项目" class="headerlink" title="使用 idea 创建 sbt 项目"></a>使用 idea 创建 sbt 项目</h2><h3 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h3><p>使用 idea 创建 sbt 项目需要安装 <code>scala</code> 和 <code>sbt</code> 插件。<br>打开idea的首选项，然后找到 <code>Plugins</code> ，点击 <code>Browser repositores...</code> 按钮，输入 <code>scala</code> 搜索，然后找到 <code>scala</code> 和 <code>sbt</code> 的插件进行安装，如下图所示：<br><img src="/images/scala/scala-sbt-plugin.png" alt="scala-sbt-plugins"><br>安装完成后重启idea。</p>
<h3 id="创建-sbt-项目"><a href="#创建-sbt-项目" class="headerlink" title="创建 sbt 项目"></a>创建 sbt 项目</h3><p>File -&gt; New -&gt; Project… 打开项目创建向导：<br><img src="/images/scala/sbt-project-1.png" alt="创建sbt项目"><br>创建完成后，等待idea刷新项目，目录结构大体如下（project/project 和 target相关没有列出）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">spark-sbt-demo                                                                                                                                                                </span><br><span class="line">├── build.sbt</span><br><span class="line">├── project</span><br><span class="line">│   ├── build.properties</span><br><span class="line">│   └── plugins.sbt</span><br><span class="line">└── src</span><br><span class="line">    ├── main</span><br><span class="line">    │   ├── java</span><br><span class="line">    │   ├── resources</span><br><span class="line">    │   ├── scala</span><br><span class="line">    │   └── scala-2.11</span><br><span class="line">    └── test</span><br><span class="line">        ├── java</span><br><span class="line">        ├── resources</span><br><span class="line">        ├── scala</span><br><span class="line">        └── scala-2.11</span><br></pre></td></tr></table></figure>
<ul>
<li><code>plugins.sbt</code> 文件放置插件配置</li>
<li><code>build.sbt</code> 是整体的项目配置信息</li>
<li><code>build.properties</code> 可以设置 sbt 版本</li>
<li><code>java</code> 目录存放 java 文件</li>
<li><code>scala</code> 目录存放 scala 文件</li>
<li><code>resources</code> 目录用来存放配置文件</li>
<li><code>test</code> 相关目录用来存放测试相关文件<h2 id="在-idea-中-运行-spark-app"><a href="#在-idea-中-运行-spark-app" class="headerlink" title="在 idea 中 运行 spark app"></a>在 idea 中 运行 spark app</h2>上面我们介绍了如何使用 idea 项目向导创建一个 sbt 项目，现在我们来说一下如何在 idea 中直接运行 sbt 构建的 spark app。</li>
</ul>
<p>这里我们使用一开始我们创建的那个项目，使用 idea 导入功能，File -&gt; Open 找到项目目录打开即可。<br>在 <code>WordCount.scala</code> 文件中右键，选择 <code>Run WordCount</code> ，开始运行，但是结果可能不是我们所期望的：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread <span class="string">"main"</span> java.lang.NoClassDefFoundError: org/apache/spark/SparkConf</span><br><span class="line">	at WorldCount$.main(WorldCount.scala:<span class="number">8</span>)</span><br><span class="line">	at WorldCount.main(WorldCount.scala)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">62</span>)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line">	at java.lang.reflect.Method.invoke(Method.java:<span class="number">497</span>)</span><br><span class="line">	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:<span class="number">144</span>)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: org.apache.spark.SparkConf</span><br><span class="line">	at java.net.URLClassLoader.findClass(URLClassLoader.java:<span class="number">381</span>)</span><br><span class="line">	at java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">424</span>)</span><br><span class="line">	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:<span class="number">331</span>)</span><br><span class="line">	at java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">357</span>)</span><br><span class="line">	... <span class="number">7</span> more</span><br><span class="line"></span><br><span class="line">Process finished with exit code <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>这是为什么呢？原因是我们在 <code>build.sbt</code> 中配置的 spark 依赖是这样的：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">libraryDependencies += <span class="string">"org.apache.spark"</span> % <span class="string">"spark-core_2.10"</span> % <span class="string">"1.6.1"</span> % <span class="string">"provided"</span></span><br></pre></td></tr></table></figure>
<p>注意到后面的 <code>provided</code> 了吗？这个代表打包或者运行的时候不会将这个 jar 包的文件包含进去（注意：spark app 要求这样，注意不要把spark相关的jar包包含进去）。这样导致我们无法再 idea 中调试或者运行 spark app。</p>
<p>解决方案还是有的，sbt 和 maven（也是一个项目管理的软件）一样，提供了模块开发功能，我们定义两个模块，一个模块就是我们上面我们做好的，另一个是用来运行的，这个里面包含了运行时类库，配置如下：</p>
<ol>
<li>创建一个名为 <code>main</code> 的文件夹，把项目中的 <code>src</code> 文件夹移动到这个目录下</li>
<li>在项目根目录下创建名为 <code>run</code> 的文件夹</li>
<li><p>修改项目根目录下的 <code>build.sbt</code> 文件，内容为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">name := &quot;spark-sbt-demo&quot;</span><br><span class="line"></span><br><span class="line">version := &quot;1.0&quot;</span><br><span class="line"></span><br><span class="line">scalaVersion := &quot;2.10.4&quot;</span><br><span class="line"></span><br><span class="line">organization := &quot;spark.demo&quot;</span><br><span class="line"></span><br><span class="line">version := &quot;1.0.0-SNAPSHOT&quot;</span><br><span class="line"></span><br><span class="line">libraryDependencies += &quot;org.apache.spark&quot; % &quot;spark-core_2.10&quot; % &quot;1.6.1&quot; % &quot;provided&quot;</span><br><span class="line"></span><br><span class="line">lazy val root = (project in file(&quot;.&quot;)).aggregate(main, run)</span><br><span class="line"></span><br><span class="line">lazy val main = (project in file(&quot;main&quot;))</span><br><span class="line"></span><br><span class="line">lazy val run = (project in file(&quot;run&quot;)).dependsOn(main)</span><br></pre></td></tr></table></figure>
</li>
<li><p>在子项目 <code>main</code> 创建 <code>build.sbt</code> 内容为：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">libraryDependencies += <span class="string">"org.apache.spark"</span> % <span class="string">"spark-core_2.10"</span> % <span class="string">"1.6.1"</span> % <span class="string">"provided"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>在子项目 <code>run</code> 创建 <code>build.sbt</code> 内容为 ：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">libraryDependencies += &quot;org.apache.spark&quot; % &quot;spark-core_2.10&quot; % &quot;1.6.1&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置运行参数，如下图：<br><img src="/images/scala/idea-spark-run-config.png" alt="idea-spark-run-config"><br>然后选择上面的运行配置，运行即可。这里可能会碰到一个异常：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread <span class="string">"main"</span> org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/Users/du/workspace/hekr/spark-sbt-demo/src/main/scala/WorldCount.scala</span><br><span class="line">	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:<span class="number">251</span>)</span><br><span class="line">	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:<span class="number">270</span>)</span><br><span class="line">	......</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这是由于上面我们修改了改程序main文件的位置，导致找不到该文件所致，请自行设置为一个存在的文件路径或者修改为 <code>main/src/main/scala/WorldCount.scala</code> 重新运行即可成功。</p>
<h2 id="Sbt-本地依赖库存储位置配置"><a href="#Sbt-本地依赖库存储位置配置" class="headerlink" title="Sbt 本地依赖库存储位置配置"></a>Sbt 本地依赖库存储位置配置</h2><p>抽空再补上，其实就是建立一个连接，先自行思考方案。</p>
<h1 id="项目下载"><a href="#项目下载" class="headerlink" title="项目下载"></a>项目下载</h1><p>没有源码下载的都是耍流氓，<a href="/files/spark-sbt-demo.tar.gz">点这里下载</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[JDK多版本管理]]></title>
      <url>http://todu.top/java/JDK%E5%A4%9A%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<p>在实际工作环境中经常碰到不同项目要用不同jdk版本问题，比如我的项目组现在用的是jdk8，而用spark打包的应用是用的jdk7，所以有必要记录一下版本配置和切换问题。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[通过SpringXD将信息分片|文件夹存储到HDFS]]></title>
      <url>http://todu.top/spring/%E9%80%9A%E8%BF%87SpringXD%E5%B0%86%E4%BF%A1%E6%81%AF%E5%88%86%E7%89%87-%E6%96%87%E4%BB%B6%E5%A4%B9%E5%AD%98%E5%82%A8%E5%88%B0HDFS/</url>
      <content type="html"><![CDATA[<pre><code>kafka --topic=kafka_test --zkconnect=10.10.1.20:2181 --queueSize=64 |hdfs --inputType=application/json --idleTimeout=10000 --partitionPath=dateFormat(&apos;yyyy/MM/dd/HH/mm&apos;)
</code></pre>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[sparkApp提交到SpringXD出现错误可能情况及解决方法]]></title>
      <url>http://todu.top/spark/sparkApp%E6%8F%90%E4%BA%A4%E5%88%B0SpringXD%E5%87%BA%E7%8E%B0%E9%94%99%E8%AF%AF%E5%8F%AF%E8%83%BD%E6%83%85%E5%86%B5%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
      <content type="html"><![CDATA[<p>编写spark代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSON;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.SparkConf;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaPairRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaRDD;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.Function2;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function.PairFunction;</span><br><span class="line"><span class="keyword">import</span> scala.Tuple2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span><br><span class="line"> * Created by sdvdxl on 2016/3/14.</span><br><span class="line"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SparkCalcDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String HADOOP_URL = <span class="string">"hdfs://10.10.1.110:8020/"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        SparkConf conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"test"</span>).setMaster(<span class="string">"local[1]"</span>);</span><br><span class="line">        JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br><span class="line">        JavaRDD&lt;String&gt; textFile = sc.textFile(HADOOP_URL + <span class="string">"/xd/dataset1/2016/03/14/15/01"</span>, <span class="number">1</span>);</span><br><span class="line">        JavaRDD&lt;String&gt; words = textFile.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> Iterable&lt;String&gt; <span class="title">call</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">                List&lt;String&gt; list = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line"></span><br><span class="line">                JSONObject jobj = JSON.parseObject(<span class="keyword">new</span> String(org.apache.commons.codec.binary.Base64.decodeBase64(s.substring(<span class="number">1</span>, s.length() - <span class="number">1</span>))));</span><br><span class="line">                list.add(jobj.getString(<span class="string">"name"</span>));</span><br><span class="line">                list.add(jobj.getString(<span class="string">"random"</span>));</span><br><span class="line">                <span class="keyword">return</span> list;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; pairs = words.mapToPair(<span class="keyword">new</span> PairFunction&lt;String, String, Integer&gt;() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title">call</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(s, <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; counts = pairs.reduceByKey(<span class="keyword">new</span> Function2&lt;Integer, Integer, Integer&gt;() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> Integer <span class="title">call</span><span class="params">(Integer a, Integer b)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> a + b;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        counts.foreach(tuple2 -&gt;</span><br><span class="line">                System.out.println(tuple2._1 + <span class="string">" : "</span> + tuple2._2));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>pom依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span><br><span class="line">	<span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>kafka-demo<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-demo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>4.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>fastjson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.6.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="comment">&lt;!--&lt;exclusions&gt;</span><br><span class="line">				&lt;exclusion&gt;</span><br><span class="line">					&lt;groupId&gt;com.fasterxml.jackson.module&lt;/groupId&gt;</span><br><span class="line">					&lt;artifactId&gt;jackson-module-scala_2.10&lt;/artifactId&gt;</span><br><span class="line">				&lt;/exclusion&gt;</span><br><span class="line"></span><br><span class="line">			&lt;/exclusions&gt;--&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="comment">&lt;!--dependency&gt;</span><br><span class="line">			&lt;groupId&gt;com.fasterxml.jackson.module&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;jackson-module-scala_2.10&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;2.7.2&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;--&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-codec<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-codec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.camel<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>camel-base64<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.16.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">version</span>&gt;</span>3.5.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">					<span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-dependency-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">outputDirectory</span>&gt;</span>$&#123;project.build.directory&#125;/lib<span class="tag">&lt;/<span class="name">outputDirectory</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">excludeTransitive</span>&gt;</span>false<span class="tag">&lt;/<span class="name">excludeTransitive</span>&gt;</span> <span class="comment">&lt;!-- 表示是否不包含间接依赖的包 --&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">stripVersion</span>&gt;</span>false<span class="tag">&lt;/<span class="name">stripVersion</span>&gt;</span> <span class="comment">&lt;!-- 去除版本信息 --&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>copy-dependencies<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>copy-dependencies<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                            <span class="comment">&lt;!-- 拷贝项目依赖包到lib/目录下 --&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">outputDirectory</span>&gt;</span>$&#123;project.build.directory&#125;/lib<span class="tag">&lt;/<span class="name">outputDirectory</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">excludeTransitive</span>&gt;</span>false<span class="tag">&lt;/<span class="name">excludeTransitive</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">stripVersion</span>&gt;</span>false<span class="tag">&lt;/<span class="name">stripVersion</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">&lt;!-- 项目资源插件 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-resources-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>copy-resources<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>copy-resources<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">encoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">encoding</span>&gt;</span></span><br><span class="line">                            <span class="comment">&lt;!-- 拷贝项目src/main/resources/下，除.bat以外的所有文件到conf/目录下 --&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">outputDirectory</span>&gt;</span>$&#123;project.build.directory&#125;/conf<span class="tag">&lt;/<span class="name">outputDirectory</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">resources</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">resource</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">directory</span>&gt;</span>src/main/resources/<span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">filtering</span>&gt;</span>true<span class="tag">&lt;/<span class="name">filtering</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>*.bat<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;/<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">resources</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>copy-command<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>copy-resources<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">encoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">encoding</span>&gt;</span></span><br><span class="line">                            <span class="comment">&lt;!-- 只拷贝项目src/main/resources/目录下的.bat文件到输出目录下 --&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">outputDirectory</span>&gt;</span>$&#123;project.build.directory&#125;<span class="tag">&lt;/<span class="name">outputDirectory</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">resources</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">resource</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">directory</span>&gt;</span>src/main/resources/<span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">filtering</span>&gt;</span>true<span class="tag">&lt;/<span class="name">filtering</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">includes</span>&gt;</span></span><br><span class="line">                                        <span class="tag">&lt;<span class="name">include</span>&gt;</span>*.bat<span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;/<span class="name">includes</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">resource</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">resources</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">&lt;!-- 打包插件 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-jar-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">archive</span>&gt;</span></span><br><span class="line">                        <span class="comment">&lt;!-- 生成MANIFEST.MF的设置 --&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">manifest</span>&gt;</span></span><br><span class="line">                            <span class="comment">&lt;!-- 为依赖包添加路径, 这些路径会写在MANIFEST文件的Class-Path下 --&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">addClasspath</span>&gt;</span>true<span class="tag">&lt;/<span class="name">addClasspath</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">classpathPrefix</span>&gt;</span>lib/<span class="tag">&lt;/<span class="name">classpathPrefix</span>&gt;</span></span><br><span class="line">                            <span class="comment">&lt;!-- jar启动入口类--&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>com.some.package.some.class.Main<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">manifest</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">manifestEntries</span>&gt;</span></span><br><span class="line">                            <span class="comment">&lt;!-- 在Class-Path下添加配置文件的路径 --&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">Class-Path</span>&gt;</span>conf/<span class="tag">&lt;/<span class="name">Class-Path</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">manifestEntries</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">archive</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">includes</span>&gt;</span></span><br><span class="line">                        <span class="comment">&lt;!-- 打jar包时，只打包class文件 --&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">include</span>&gt;</span>**/*.class<span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">includes</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">id</span>&gt;</span>oschina<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.oschina.net/content/groups/public<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">id</span>&gt;</span>mavenspring<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.springframework.org/release<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">id</span>&gt;</span>jcenter<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://jcenter.bintray.com<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">id</span>&gt;</span>spring-milestones<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">name</span>&gt;</span>Spring Milestones<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repo.spring.io/milestone<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">snapshots</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">id</span>&gt;</span>spring-release<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">name</span>&gt;</span>Spring Releases<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repo.spring.io/libs-release<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">snapshots</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">id</span>&gt;</span>spring-snapshots<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">name</span>&gt;</span>Spring Snapshots<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">url</span>&gt;</span>http://repo.spring.io/snapshot<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">snapshots</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">releases</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">releases</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>定义xd job:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job create --name sparkAppDemo --definition &quot;sparkapp --mainClass=com.demo.SparkCalcDemo --appJar=/home/spark/spark-app.jar --master=local[1]&quot; --deploy</span><br></pre></td></tr></table></figure>
<p>加载job</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job launch sparkAppDemo</span><br></pre></td></tr></table></figure>
<p>然后出现以下类似的错误，主要是：<code>...redis:queue-inbound-channel-adapter...</code>错误</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">2016-03-16T10:16:10+0800 1.3.1.RELEASE INFO DeploymentSupervisor-0 zk.ZKJobDeploymentHandler - Deployment status for job &apos;sparkAppDemo&apos;: DeploymentStatus&#123;state=deployed&#125;</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark application &apos;com.demo.SparkCalcDemo&apos; finished with exit code: 1</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: Exception in thread &quot;main&quot; java.lang.SecurityException: Invalid signature file digest for Manifest main attributes</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:284)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:238)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.util.jar.JarVerifier.processEntry(JarVerifier.java:316)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.util.jar.JarVerifier.update(JarVerifier.java:228)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.util.jar.JarFile.initializeVerifier(JarFile.java:383)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.util.jar.JarFile.getInputStream(JarFile.java:450)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at sun.misc.JarIndex.getJarIndex(JarIndex.java:137)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at sun.misc.URLClassPath$JarLoader$1.run(URLClassPath.java:839)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at sun.misc.URLClassPath$JarLoader$1.run(URLClassPath.java:831)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at sun.misc.URLClassPath$JarLoader.ensureOpen(URLClassPath.java:830)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at sun.misc.URLClassPath$JarLoader.&lt;init&gt;(URLClassPath.java:803)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at sun.misc.URLClassPath$3.run(URLClassPath.java:530)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at sun.misc.URLClassPath$3.run(URLClassPath.java:520)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at sun.misc.URLClassPath.getLoader(URLClassPath.java:519)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at sun.misc.URLClassPath.getLoader(URLClassPath.java:492)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at sun.misc.URLClassPath.getNextLoader(URLClassPath.java:457)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at sun.misc.URLClassPath.getResource(URLClassPath.java:211)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.net.URLClassLoader$1.run(URLClassLoader.java:365)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.net.URLClassLoader$1.run(URLClassLoader.java:362)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.net.URLClassLoader.findClass(URLClassLoader.java:361)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.lang.Class.forName0(Native Method)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at java.lang.Class.forName(Class.java:348)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:538)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)</span><br><span class="line">2016-03-16T10:16:14+0800 1.3.1.RELEASE ERROR inbound.job:sparkAppDemo-redis:queue-inbound-channel-adapter1 tasklet.SparkTasklet - Spark Logger: Using Spark&apos;s default log4j profile: org/apache/spark/log4j-defaults.properties</span><br></pre></td></tr></table></figure>
<p>仔细看的话，在上面有一句<code>Exception in thread &quot;main&quot; java.lang.SecurityException: Invalid signature file digest for Manifest main attributes</code>错误，这个错误是由于导出的jar包结构信息不正确导致的。用eclipse的导出runnable jar 功能导出的jar包就没问题了。</p>
<p>另外如果有依赖的jar包没哟被加载进去，则会在最上方出现<code>java.lang.NoClassDefFoundError:</code>类似信息。</p>
<p>相关资料：<a href="http://www.todu.top/2016/03/09/以分布式方式运行Spring-XD" target="_blank" rel="external">以分布式方式运行Spring-XD</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[linux下根据端口号查询对应进程]]></title>
      <url>http://todu.top/linux/linux%E4%B8%8B%E6%A0%B9%E6%8D%AE%E7%AB%AF%E5%8F%A3%E5%8F%B7%E6%9F%A5%E8%AF%A2%E5%AF%B9%E5%BA%94%E8%BF%9B%E7%A8%8B/</url>
      <content type="html"><![CDATA[<p>适用于ip4</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof -Pnl +M -i4 | grep port</span><br></pre></td></tr></table></figure>
<p>适用于ip6</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof -Pnl +M -i6 | grep port</span><br></pre></td></tr></table></figure>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[golang打印错误栈信息]]></title>
      <url>http://todu.top/golang/golang%E6%89%93%E5%8D%B0%E9%94%99%E8%AF%AF%E6%A0%88%E4%BF%A1%E6%81%AF/</url>
      <content type="html"><![CDATA[<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> mainimport (</span><br><span class="line">    <span class="string">"runtime"</span></span><br><span class="line">    <span class="string">"fmt"</span>)<span class="keyword">func</span> main() &#123;</span><br><span class="line">    outer()&#125;<span class="keyword">func</span> outer() &#123;</span><br><span class="line">    inner()&#125;<span class="keyword">func</span> inner() &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">defer</span> <span class="keyword">func</span>() &#123;</span><br><span class="line">        <span class="keyword">if</span> err := <span class="built_in">recover</span>(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">            trace := <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="number">1024</span>)</span><br><span class="line">            count := runtime.Stack(trace, <span class="literal">true</span>)</span><br><span class="line">            fmt.Printf(<span class="string">"Recover from panic: %s\n"</span>, err)</span><br><span class="line">            fmt.Printf(<span class="string">"Stack of %d bytes: %s\n"</span>, count, trace)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">panic</span>(<span class="string">"Fake error!"</span>)&#125;</span><br></pre></td></tr></table></figure>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[golang容易忽略导致入坑的方面]]></title>
      <url>http://todu.top/golang/golang%E5%AE%B9%E6%98%93%E5%BF%BD%E7%95%A5%E5%AF%BC%E8%87%B4%E5%85%A5%E5%9D%91%E7%9A%84%E6%96%B9%E9%9D%A2/</url>
      <content type="html"><![CDATA[<h1 id="main-函数"><a href="#main-函数" class="headerlink" title="main 函数"></a>main 函数</h1><p>main函数必须定义在main包里，不可导出。当main函数调用完毕，程序就会立即退出，不会等待运行中的goroutine运行完毕。</p>
<h1 id="初始化函数"><a href="#初始化函数" class="headerlink" title="初始化函数"></a>初始化函数</h1><p><code>func init() { … }</code></p>
<p>此函数无参，不需显示调用。</p>
<p>此函数根据依赖顺序执行初始化顺序，并且是顺序执行，如：</p>
<p>A 依赖 B， B 依赖 C，并且A，B，C 都有init函数，那么初始化顺序是C ，B ， A</p>
<h1 id="iota"><a href="#iota" class="headerlink" title="iota"></a>iota</h1><ul>
<li><p>iota 只能用在const定义的常量上</p>
</li>
<li><p>iota在一个const范围，不管中间的变量有没有用到iota，iota都是持续递增加1的，如</p>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line"></span><br><span class="line">       aa = <span class="literal">iota</span></span><br><span class="line"></span><br><span class="line">       bb</span><br><span class="line"></span><br><span class="line">       cc = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">       dd = <span class="literal">iota</span></span><br><span class="line"></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>dd 是3</p>
<ul>
<li>如果重新定义const，那么值会是重新从0开始，如</li>
</ul>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line"></span><br><span class="line">       ee = <span class="literal">iota</span></span><br><span class="line"></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h1 id="类型断言"><a href="#类型断言" class="headerlink" title="类型断言"></a>类型断言</h1><p>x.(T) x为变量， T为要判断的类型，其中有两种用法</p>
<ul>
<li><p><code>a := x.(T)</code> ，如果x是类型T的实现类型变量，那么可以得到转换后的值a，否则panic: interface conversion: (x的类型) is not package.T: missing method （T的方法）</p>
</li>
<li><p><code>a, ok := x.(T)</code>，如果x是类型T的实现的类型变量，那么ok为true， 转换成功，否则，ok为false，说明转换失败。</p>
</li>
</ul>
<h1 id="从Panic中恢复"><a href="#从Panic中恢复" class="headerlink" title="从Panic中恢复"></a>从Panic中恢复</h1><p>需要用到build-in recover()方法，函数原型：</p>
<p><code>func recover() interface{}</code></p>
<p>要捕获panic，必须在有可能发生panic的地方的上面进行处理，</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">defer</span> <span class="keyword">func</span>()&#123;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">if</span> err := <span class="built_in">recover</span>(); err !=<span class="literal">nil</span> &#123;</span><br><span class="line"></span><br><span class="line">   <span class="comment">//处理错误</span></span><br><span class="line"></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">&#125;()</span><br></pre></td></tr></table></figure>
<p>一般来说，会将上面的代码放在函数（或者方法）的开始的地方。</p>
<p><strong> 注意 ， recover函数只能用在defer中，否则不会进行错误捕获。</strong></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[sink-hdfs]]></title>
      <url>http://todu.top/spring/sink-hdfs/</url>
      <content type="html"><![CDATA[<p>hdfs根据时间自动划分文件夹<br><code>stream create --name dataset1 --definition &quot;kafka --topic=kafka_test --zkconnect=10.10.1.20:2181 --queueSize=64  |hdfs --inputType=application/json --idleTimeout=10000 --partitionPath=dateFormat(&#39;yyyy/MM/dd/HH/mm&#39;)&quot; --deploy</code><br>其中，–partitionPath=dateFormat(‘yyyy/MM/dd/HH/mm’)用来指定划分 策略，这个是说用年(四位)/月(两位)/天(2位)/时(2位)/分(2位)这种格式来划分</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[golang命令]]></title>
      <url>http://todu.top/golang/golang%E5%91%BD%E4%BB%A4/</url>
      <content type="html"><![CDATA[<p>Go 提供了很多好用的命令，比如可以用go get 直接从网络上导入包，下面介绍一些常用的Go命令</p>
<h1 id="go-get"><a href="#go-get" class="headerlink" title="go get"></a>go get</h1><h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><p>go get 命令用来直接下载并安装网络上的包到GOPATH中。事实上它依赖于版本控制工具，比如常用的Git和Mercurial。比如我们要使用<code>github.com/golang/text</code>这个包，那么可以执行命令 <code>go get github.com/golang/text</code>，稍后片刻（依照网络情况时间长短不一），那么这个包源码就会放到 <code>GOPATH/src</code>对应的目录下，编译好的文件会放到<code>GOPATH/pkg</code>对应的目录下，如果有可执行性代码，那么会将编译好的可执行性文件放到<code>GOPATH/bin</code>目录下。</p>
<h2 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h2><p>像刚才例子中提到的<code>github.com/golang/text</code>这个包下又有子包，也想get下来，该如何做呢？也许你想没办法，一个一个get吧，的确这是一个不错的方法，但是有一个更为高效和优雅的方式，那就是 <code>...</code>，这个符号代表旗下子目录，那我们可以这样操作<code>go get github.com/golang/text ...</code>，就可以将text和其子包同时get下来了。</p>
<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><ul>
<li><code>-v</code> 可以显示正在get的包</li>
<li><code>-x</code> 可以显示正在执行的命令<h1 id="go-build"><a href="#go-build" class="headerlink" title="go build"></a>go build</h1>编译go文件。<br>可以切换到要build的包中执行<code>go build</code>，也可以直接 “go build” + “包名”，如要build包 <code>github.com/golang/text</code>，可以切换到text包目录下执行 <code>go build</code>，也可以直接执行 <code>go build github.com/golang/text</code>，这样就可以build text包了，如果要build子包，那么输入<code>go build ./...</code>。<code>build</code>命令会将main函数编译成可执行性文件，如果没有main，那么没有额外的文件产生。</li>
</ul>
<h1 id="go-clean"><a href="#go-clean" class="headerlink" title="go clean"></a>go clean</h1><p><code>clean</code>和<code>build</code>作用相反，是将build出来的可执行性文件清除掉。</p>
<h1 id="go-install"><a href="#go-install" class="headerlink" title="go install"></a>go install</h1><p><code>install</code> 命令是将包编译成二进制文件并放到<code>GOPATH/pkg/目标平台/</code>对应的目录下。比如我们自己从github上克隆了<code>github.com/golang/text</code>，要使用它的话，需要进入到text包中，然后执行 <code>go install</code>；加入有子包也要安装的话，输入<code>go install ./...</code>，就会在<code>GOPATH/pkg/目标平台/</code>产生后缀为<code>.a</code>的文件。当然也可以和build一样输入完整的包路径。</p>
<h1 id="go-list"><a href="#go-list" class="headerlink" title="go list"></a>go list</h1><p>这个命令用来查看所引用的包。</p>
<h2 id="基本用法-1"><a href="#基本用法-1" class="headerlink" title="基本用法"></a>基本用法</h2><ol>
<li>直接跟包名，如：<code>github.com/golang/text</code>，会打印这个包本身；也可以切换到该包目录下执行<code>go list</code>，效果相同。</li>
<li>可以直接跟”包名”+”/…”，比如要查看<code>github.com/golang/text</code>这个包的导入情况，执行<code>go list github.com/golang/text/...</code>会打印本包的go文件。<h2 id="参数-1"><a href="#参数-1" class="headerlink" title="参数"></a>参数</h2><code>-f</code>可以指定打印格式，默认是<code>go list -f &#39; {{.ImportPath}} &#39;</code>， <code>-f</code>后面的参数可以用下面结构体的属性：<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">type</span> Package <span class="keyword">struct</span> &#123;</span><br><span class="line">    Dir           <span class="keyword">string</span> <span class="comment">// directory containing package sources</span></span><br><span class="line">    ImportPath    <span class="keyword">string</span> <span class="comment">// import path of package in dir</span></span><br><span class="line">    ImportComment <span class="keyword">string</span> <span class="comment">// path in import comment on package statement</span></span><br><span class="line">    Name          <span class="keyword">string</span> <span class="comment">// package name</span></span><br><span class="line">    Doc           <span class="keyword">string</span> <span class="comment">// package documentation string</span></span><br><span class="line">    Target        <span class="keyword">string</span> <span class="comment">// install path</span></span><br><span class="line">    Goroot        <span class="keyword">bool</span>   <span class="comment">// is this package in the Go root?</span></span><br><span class="line">    Standard      <span class="keyword">bool</span>   <span class="comment">// is this package part of the standard Go library?</span></span><br><span class="line">    Stale         <span class="keyword">bool</span>   <span class="comment">// would 'go install' do anything for this package?</span></span><br><span class="line">    Root          <span class="keyword">string</span> <span class="comment">// Go root or Go path dir containing this package</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Source files</span></span><br><span class="line">    GoFiles        []<span class="keyword">string</span> <span class="comment">// .go source files (excluding CgoFiles, TestGoFiles, XTestGoFiles)</span></span><br><span class="line">    CgoFiles       []<span class="keyword">string</span> <span class="comment">// .go sources files that import "C"</span></span><br><span class="line">    IgnoredGoFiles []<span class="keyword">string</span> <span class="comment">// .go sources ignored due to build constraints</span></span><br><span class="line">    CFiles         []<span class="keyword">string</span> <span class="comment">// .c source files</span></span><br><span class="line">    CXXFiles       []<span class="keyword">string</span> <span class="comment">// .cc, .cxx and .cpp source files</span></span><br><span class="line">    MFiles         []<span class="keyword">string</span> <span class="comment">// .m source files</span></span><br><span class="line">    HFiles         []<span class="keyword">string</span> <span class="comment">// .h, .hh, .hpp and .hxx source files</span></span><br><span class="line">    SFiles         []<span class="keyword">string</span> <span class="comment">// .s source files</span></span><br><span class="line">    SwigFiles      []<span class="keyword">string</span> <span class="comment">// .swig files</span></span><br><span class="line">    SwigCXXFiles   []<span class="keyword">string</span> <span class="comment">// .swigcxx files</span></span><br><span class="line">    SysoFiles      []<span class="keyword">string</span> <span class="comment">// .syso object files to add to archive</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Cgo directives</span></span><br><span class="line">    CgoCFLAGS    []<span class="keyword">string</span> <span class="comment">// cgo: flags for C compiler</span></span><br><span class="line">    CgoCPPFLAGS  []<span class="keyword">string</span> <span class="comment">// cgo: flags for C preprocessor</span></span><br><span class="line">    CgoCXXFLAGS  []<span class="keyword">string</span> <span class="comment">// cgo: flags for C++ compiler</span></span><br><span class="line">    CgoLDFLAGS   []<span class="keyword">string</span> <span class="comment">// cgo: flags for linker</span></span><br><span class="line">    CgoPkgConfig []<span class="keyword">string</span> <span class="comment">// cgo: pkg-config names</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Dependency information</span></span><br><span class="line">    Imports []<span class="keyword">string</span> <span class="comment">// import paths used by this package</span></span><br><span class="line">    Deps    []<span class="keyword">string</span> <span class="comment">// all (recursively) imported dependencies</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Error information</span></span><br><span class="line">    Incomplete <span class="keyword">bool</span>            <span class="comment">// this package or a dependency has an error</span></span><br><span class="line">    Error      *PackageError   <span class="comment">// error loading package</span></span><br><span class="line">    DepsErrors []*PackageError <span class="comment">// errors loading dependencies</span></span><br><span class="line"></span><br><span class="line">    TestGoFiles  []<span class="keyword">string</span> <span class="comment">// _test.go files in package</span></span><br><span class="line">    TestImports  []<span class="keyword">string</span> <span class="comment">// imports from TestGoFiles</span></span><br><span class="line">    XTestGoFiles []<span class="keyword">string</span> <span class="comment">// _test.go files outside package</span></span><br><span class="line">    XTestImports []<span class="keyword">string</span> <span class="comment">// imports from XTestGoFiles</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>如果想打印比较全的信息，也有一个参数可以使用：<code>-json</code>，这会将上面部分信息以json格式打印出来，读者可以自行实验。</p>
<h1 id="go-run"><a href="#go-run" class="headerlink" title="go run"></a>go run</h1><p>这个命令可以直接运行go文件（带main函数），不需要编译成二进制可执行性文件。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Android通话自动录音]]></title>
      <url>http://todu.top/android/Android%E9%80%9A%E8%AF%9D%E8%87%AA%E5%8A%A8%E5%BD%95%E9%9F%B3/</url>
      <content type="html"><![CDATA[<h1 id="应用介绍："><a href="#应用介绍：" class="headerlink" title="应用介绍："></a>应用介绍：</h1><p>通话自动录音，包括去电/来电接通录音。 启动服务之后，当电话接通之后开始录音, 录音文件保存在存储卡上My Record文件夹内。 同时可以用本软件进行查看录音文件，播放，删除等操作。 单击录音文件可以长按录音文件可以单个删除</p>
<h1 id="版本：1-5"><a href="#版本：1-5" class="headerlink" title="版本：1.5"></a>版本：1.5</h1><h1 id="百度应用地址"><a href="#百度应用地址" class="headerlink" title="百度应用地址"></a><a href="http://shouji.baidu.com/soft/item?docid=2357503&amp;from=web_alad_multi&amp;f=search_app_%E9%80%9A%E8%AF%9D%E8%87%AA%E5%8A%A8%E5%BD%95%E9%9F%B3%40list_1_title%401%40search_sug_app" target="_blank" rel="external">百度应用地址</a></h1><p><a href="http://shouji.baidu.com/s?wd=%E9%80%9A%E8%AF%9D%E8%87%AA%E5%8A%A8%E5%BD%95%E9%9F%B3&amp;data_type=app&amp;f=search_sug%40app&amp;from=web_alad_multi" target="_blank" rel="external">百度应用同类搜索占位为第一位</a></p>
<h1 id="应用截图"><a href="#应用截图" class="headerlink" title="应用截图"></a>应用截图</h1><p><img src="http://7xiyb7.com1.z0.glb.clouddn.com/worksandroid%E9%80%9A%E8%AF%9D%E8%87%AA%E5%8A%A8%E5%BD%95%E9%9F%B31.jpg" alt="android通话自动录音1"></p>
<p><img src="http://7xiyb7.com1.z0.glb.clouddn.com/worksandroid%E9%80%9A%E8%AF%9D%E8%87%AA%E5%8A%A8%E5%BD%95%E9%9F%B32.jpg" alt="android通话自动录音2"></p>
<p><img src="http://7xiyb7.com1.z0.glb.clouddn.com/worksandroid%E9%80%9A%E8%AF%9D%E8%87%AA%E5%8A%A8%E5%BD%95%E9%9F%B33.jpg" alt="android通话自动录音3"></p>
<p><img src="http://7xiyb7.com1.z0.glb.clouddn.com/worksandroid%E9%80%9A%E8%AF%9D%E8%87%AA%E5%8A%A8%E5%BD%95%E9%9F%B34.jpg" alt="android通话自动录音4"></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[linux工具集锦]]></title>
      <url>http://todu.top/linux/linux%E5%B7%A5%E5%85%B7%E9%9B%86%E9%94%A6/</url>
      <content type="html"><![CDATA[<h1 id="bcompare"><a href="#bcompare" class="headerlink" title="bcompare"></a>bcompare</h1><p>Beyond Compare是一套超级的文件及文件夹(目录)的比较工具，不仅可以快速比较出两个目录的不同，还可以比较每个文件的内容，而且可以任意显示比较结果。程序内建了文件浏览器，方便您对文件、文件夹、压缩包、FTP网站之间的差异比对以及资料同步。使用它可以管理源代码，保持文件夹的同步，比较程序输出，及验证光盘的复制。它还支持脚本、插件，尤其对中文支持很好。</p>
<h1 id="Geany"><a href="#Geany" class="headerlink" title="Geany"></a>Geany</h1><h1 id="Evince"><a href="#Evince" class="headerlink" title="Evince"></a>Evince</h1><p>pdf阅读器</p>
<p>#Markdown 编辑器<br>Farbox</p>
<h1 id="tmux"><a href="#tmux" class="headerlink" title="tmux"></a>tmux</h1><p>一款可以在原有的终端上进行分屏工作的工具。</p>
<h1 id="mutate"><a href="#mutate" class="headerlink" title="mutate"></a>mutate</h1><p>类似 mac上的alfred的软件，<a href="https://github.com/qdore/Mutatehttps://github.com/qdore/Mutate" target="_blank" rel="external">地址</a><br>ppa安装方式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:mutate/ppa</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install mutate</span><br></pre></td></tr></table></figure></p>
<h1 id="plank"><a href="#plank" class="headerlink" title="plank"></a>plank</h1><p>一款友好实用的dock工具。</p>
<h1 id="virtualbox"><a href="#virtualbox" class="headerlink" title="virtualbox"></a>virtualbox</h1><p>一款跨平台的可以安装任何操作系统的虚拟机软件。<a href="https://www.virtualbox.org/" target="_blank" rel="external">官方地址</a>，同时最好安装扩展，可以有增强功能（拷贝，拖拽，更好的显示）。</p>
<h1 id="xfce-zhuti"><a href="#xfce-zhuti" class="headerlink" title="xfce zhuti"></a>xfce zhuti</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:rebuntu16/other-stuff</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install xfce-theme-manager</span><br></pre></td></tr></table></figure>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[配置Idea的Go开发环境]]></title>
      <url>http://todu.top/golang/%E9%85%8D%E7%BD%AEIdea%E7%9A%84Go%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</url>
      <content type="html"><![CDATA[<h1 id="获取IDEA"><a href="#获取IDEA" class="headerlink" title="获取IDEA"></a>获取IDEA</h1><ol>
<li><a href="https://www.jetbrains.com/idea/download/" target="_blank" rel="external">最新版戳这里下载</a>，下载对应平台的版本，一般来说，社区版(Community Edition)就已经足够了。</li>
<li>安装IDEA。Windows和Mac是安装版，一步一步安装完成即可；Linux是免安装版，解压，给IDEA的执行文件添加可执行权限即可。假设安装目录是<code>H:\software\dev\JetBrains\IntelliJ IDEA Community Edition 14.1.1</code>，其他平台自行设置目录。</li>
</ol>
<h1 id="获取Go"><a href="#获取Go" class="headerlink" title="获取Go"></a>获取Go</h1><ol>
<li>Go的官方网站是<a href="http://golang.org/" target="_blank" rel="external">http://golang.org/</a>，<a href="https://golang.org/dl/" target="_blank" rel="external">下载地址</a>，但是鉴于中国网络问题，不科学上网则没法下载，各位同学可以从<a href="http://golangtc.com/download" target="_blank" rel="external">这里下载</a>，最好下载最新的，当然这个网站(<a href="http://golangtc.com/)本身就是国内较活跃的一个Go社区。" target="_blank" rel="external">http://golangtc.com/)本身就是国内较活跃的一个Go社区。</a></li>
<li>下载后解压到本地目录，假设安装目录是<code>H:\software\dev\go</code>。其他平台自行设置目录。</li>
</ol>
<h1 id="获取Git和hg"><a href="#获取Git和hg" class="headerlink" title="获取Git和hg"></a>获取Git和hg</h1><p>因为Go get命令要使用到git或者hg，所以需要安装git和hg。<br>git可以<a href="http://git-scm.com/" target="_blank" rel="external">从这里下载</a>, hg(执行命令是hg，实际下载的软件叫mercurial)可以<a href="http://mercurial.selenic.com/" target="_blank" rel="external">从这里下载</a>，加入git安装到<code>H:\software\dev\Git</code>，hg安装到<code>H:\software\dev\Mercurial</code></p>
<h1 id="配置Go和Git-hg"><a href="#配置Go和Git-hg" class="headerlink" title="配置Go和Git(hg)"></a>配置Go和Git(hg)</h1><p>配置环境变量，这里以Windows为例，其他平台请自行换成对应的路径即可。如果打开命令行分别执行以下命令都成功，那么不需要额外配置环境变量，否则配置对应的环境变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">go version</span><br><span class="line">git version</span><br><span class="line">hg version</span><br></pre></td></tr></table></figure></p>
<table>
<thead>
<tr>
<th>变量名称</th>
<th>变量值</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>GOROOT</td>
<td>H:\software\dev\go</td>
<td>go根路径</td>
</tr>
<tr>
<td>GOPATH</td>
<td>H:\software\dev\gopath</td>
<td>gopath可以是任何一个目录</td>
</tr>
<tr>
<td>PATH</td>
<td>%PATH%;%GOROOT%\bin;H:\software\dev\Git\bin;H:\software\dev\Mercuria;</td>
<td>注意不要忘了加入原来的path变量</td>
</tr>
</tbody>
</table>
<h1 id="配置IDEA的Go环境"><a href="#配置IDEA的Go环境" class="headerlink" title="配置IDEA的Go环境"></a>配置IDEA的Go环境</h1><ol>
<li><p>打开IDEA，File -&gt; Settings -&gt; Plugins -&gt; Browse repositiores… -&gt; Manage repositories… ，添加自定义repository url <code>https://plugins.jetbrains.com/plugins/nightly/list</code>(nightly build)或者 <code>https://plugins.jetbrains.com/plugins/alpha/list</code>(alpha version)，添加完成之后，等待刷新完成后，输入go，选择go插件，点击安装，等待安装完成后，重启生效。网络环境不好的话，可能插件不能下载，可以直接<a href="https://plugins.jetbrains.com/plugin/download?updateId=19402" target="_blank" rel="external">去idea官网下载插件</a>，如何获取最新插件呢，这里是根据updateId来的，这个最新的id就是从上面的repository的url中获取的，用浏览器打开这个url，就会观察到以下内容</p>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">idea-plugin</span> <span class="attr">downloads</span>=<span class="string">"97922"</span> <span class="attr">size</span>=<span class="string">"1071401"</span> <span class="attr">date</span>=<span class="string">"1428797441000"</span> <span class="attr">url</span>=<span class="string">""</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>Go<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>ro.redeul.google.go<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">&lt;![CDATA[</span><br><span class="line">Support for Go programming language. &lt;p&gt;Alpha pre-release of the 1.0.0 version.&lt;/p&gt; &lt;p&gt;Doesn't contain all the functionality of the 0.9.x branch but has a completely reworked internals. It's faster than 0.9.x, refactoring works to some degree and has native support for gopath packages.&lt;/p&gt; Compatibility &lt;p&gt;Plugin can be installed on IntelliJ platform 141.2 or greater. It corresponds to IntelliJ IDEA 14.1, WebStorm 10, PhpStorm 9&lt;/p&gt;</span><br><span class="line">]]&gt;</span><br><span class="line"><span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>0.9.271<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">vendor</span> <span class="attr">email</span>=<span class="string">""</span> <span class="attr">url</span>=<span class="string">"https://github.com/go-lang-plugin-org"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">download-url</span>&gt;</span>../../plugin/download?updateId=19402<span class="tag">&lt;/<span class="name">download-url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">idea-version</span> <span class="attr">min</span>=<span class="string">"n/a"</span> <span class="attr">max</span>=<span class="string">"n/a"</span> <span class="attr">until-build</span>=<span class="string">"3999"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">change-notes</span>&gt;</span></span><br><span class="line">&lt;![CDATA[</span><br><span class="line">&lt;ul&gt; &lt;li&gt;Initial GAE support: running dev server. &lt;strong&gt;Requires resetting project SDK.&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;</span><br><span class="line">]]&gt;</span><br><span class="line"><span class="tag">&lt;/<span class="name">change-notes</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">rating</span>&gt;</span>4.3<span class="tag">&lt;/<span class="name">rating</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">idea-plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>其中 download-url 中的 updateId 就是最新的下载id。<br>如果还是没法下载，那么<a href="http://pan.baidu.com/s/1c0o50ys" target="_blank" rel="external">请点击这里</a>，从百度云上下载。<br>然后 File -&gt; Settings -&gt; Install plugin from disk…选择刚才下载的压缩包（不要解压），确定后重启成效。</p>
<ol>
<li>File -&gt; Other settings -&gt; Default Project Structure… -&gt; Platform Settings -&gt; SDKs -&gt; + -&gt; Go SDK -&gt; 选择GOROOT路径，确定。</li>
<li><p>File -&gt; New Project -&gt; Go -&gt; Next -&gt; 输入Project name和Project location -&gt; Finish -&gt; 在项目根目录中新建main.go，添加以下内容</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">package</span> main</span><br><span class="line">    <span class="keyword">import</span> (</span><br><span class="line">	<span class="string">"fmt"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">func</span> main() &#123;</span><br><span class="line">	fmt.Println(<span class="string">"hello world"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>Run -&gt; Edit Configrations -&gt; + -&gt; Go Application -&gt; File 中在原来的路径基础上添加main文件即 添加 <code>\main.go</code>，点击确定，然后运行可以看到控制台打印 hello world。</p>
<h1 id="配置GDB-debug"><a href="#配置GDB-debug" class="headerlink" title="配置GDB debug"></a>配置GDB debug</h1><p>Run -&gt; Edit Configrations -&gt; Defaults -&gt; Go GDB -&gt;<br>Name：可以随便填写<br>GDB executeable：dbg.exe的完整路径<br>Application executable：填写生成的可执行文件的完整路径，路径要是windows写法，如G:\gopath\src\example\main.exe则需要两个反斜杠，就变成了G:\gopath\src\example\main.exe，或者是Unix写法 G:/gopath/src/example/main.exe,否则会提示找不到文件。这里的可执行文件必须使用<code>go build -gcflags &quot;-N -l&quot;</code>编译出来的，这样的文件带有debug信息并且没有被go内联优化。</p>
<h1 id="配置保存时自动格式化代码和自动导入"><a href="#配置保存时自动格式化代码和自动导入" class="headerlink" title="配置保存时自动格式化代码和自动导入"></a>配置保存时自动格式化代码和自动导入</h1><p>这个配置需要用到IDEA的宏（所谓的宏，就是一系列操作），下面就说怎么录制这个宏。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[go读取文件]]></title>
      <url>http://todu.top/golang/go%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6/</url>
      <content type="html"><![CDATA[<h1 id="使用File"><a href="#使用File" class="headerlink" title="使用File"></a>使用File</h1><pre><code>不多说，直接上代码
</code></pre><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">func</span> readUseFile() &#123;</span><br><span class="line">	file, err := os.Open(<span class="string">"f:/file.txt"</span>)</span><br><span class="line">	handleError(err)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">defer</span> file.Close()</span><br><span class="line"></span><br><span class="line">	buf := <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="number">512</span>)</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		n, err := file.Read(buf)</span><br><span class="line"></span><br><span class="line">		<span class="comment">//1</span></span><br><span class="line">		<span class="comment">//		if err != nil &amp;&amp; err == io.EOF &#123;</span></span><br><span class="line">		<span class="comment">//			break</span></span><br><span class="line">		<span class="comment">//		&#125;</span></span><br><span class="line"></span><br><span class="line">		<span class="comment">//2</span></span><br><span class="line">		<span class="comment">//		if n == 0 &#123;</span></span><br><span class="line">		<span class="comment">//			break</span></span><br><span class="line">		<span class="comment">//		&#125;</span></span><br><span class="line"></span><br><span class="line">		<span class="comment">//3</span></span><br><span class="line">		<span class="keyword">if</span> n == <span class="number">0</span> &amp;&amp; err != <span class="literal">nil</span> &amp;&amp; err == io.EOF &#123;</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		fmt.Print(n)</span><br><span class="line">		fmt.Print(<span class="keyword">string</span>(buf))</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	handleError(err)</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<pre><code>可以看到，file本身具有读取文件内容的函数，入参事一个切片，是数据的缓冲区，出参第一个是实际读取的大小，第二个是读取过程中发生的错误。如果有数据且读取成功，则n&gt;0,如果恰好读到文件末尾，则n=0。如果读取过程中有错误发生，则err不为nil，如果读取正常且读到了文件末尾，则err为io.EOF。
读取过程中有三种方法可以跳出死循环。第一种方法是判断err状态，如果不为nil且是io.EOF，则已经读取完毕；第二种方法是判断实际读取的数量，如果读取的量为0，则认为已经读取结束。第三种方式是上面两种的结合，这种判断要比上面两种中仁和一种都要保险，缺点就是罗嗦点。
</code></pre>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[go交叉编译]]></title>
      <url>http://todu.top/golang/go%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91/</url>
      <content type="html"><![CDATA[<p>1.5之前需要进入go安装目录下的src目录，然后执行<br><code>GOOS=windows GOARCH=i386  CGO_ENABLED=0 ./make.bash --no-clean</code></p>
<p>1.5及其之后可以直接执行<code>CGO_ENABLED=0 GOOS=windows GOARCH=386 go build -o 输出文件名 go文件</code><br>其中<code>GOOS</code>有：<code>windows</code>,<code>linux</code>,<code>darwin</code>也就是mac系统<br><code>GOARCH</code>有：<code>adm64</code>和<code>386</code>分别对应64位平台和32位平台</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[go中main]]></title>
      <url>http://todu.top/golang/go%E4%B8%ADmain/</url>
      <content type="html"><![CDATA[<p>想必很多朋友在入门的时候都是拿main开始，而不是test，我也喜欢这样，我想可能是main比较为人熟知的用法吧，test在go中也是非常友好的，不需要依赖其他库就可方便使用。既然都偏向于main方法的开始和入门，那么这个博文就说一下go语言main相关的事情。<br>原本只打算写一下main包的拆分和运行方式，突然想到还有其他一些注意地方，那么就一并记录一下，其他的如果使用过程中遇到了，再进行记录。<br><strong>以下示例都是在GOPATH下进行</strong></p>
<h1 id="main函数定义"><a href="#main函数定义" class="headerlink" title="main函数定义"></a>main函数定义</h1><p>想要作为程序的运行入口，那么这个函数必须明明为main，同时要放到main包。main函数声明极其简单，如下：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">func</span> main()&#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这样就声明并定义好了程序的运行的入口函数，不需要其他额外的参数和返回值。加上包的声明，完整的main文件就如下格式：<br><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"><span class="keyword">func</span> main() &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>另外main文件名字可以随意命名，只需要后缀是<code>.go</code>就可以了，如：<code>a.go</code>, <code>main.go</code>, <code>server.go</code>等都是可以的。</p>
<h1 id="main-的运行"><a href="#main-的运行" class="headerlink" title="main 的运行"></a>main 的运行</h1><p>要运行main文件，go提供了2中方式：</p>
<ol>
<li><code>go run main.go</code> 其中main.go 就是要运行的main函数所在的文件</li>
<li><code>go build</code>命令，文件名可以省略，也可以加上， 还可以用用参数 <code>-o</code> 指定编译后的文件，如 <code>go build -o main.exe main.go</code> 就是把main.go文件编译成main.exe可执行文件，然后直接执行main.exe就可以运行了。</li>
</ol>
<h1 id="main-包文件（内容）的拆分"><a href="#main-包文件（内容）的拆分" class="headerlink" title="main 包文件（内容）的拆分"></a>main 包文件（内容）的拆分</h1><p>假如觉得一个main文件中放太多东西有点杂乱，那么可以把main函数和其他内容拆开，放到不同的文件中（这里指的都是main这个包中），文件名字随意。比如我们有个sum函数，那么可以把它放到math.go这个main包的文件中，然后main函数独立在main.go文件中，main方法可以直接调用main包（相同名字的包）的函数、方法或者变量。那么如何执行呢，当然就可以用上述的方法运行。但是如果用<code>go run main.go</code>这种方式，那么可能遇到一个问题：找不到sum这个函数。因为run的只是main.go 这一个文件，没有加载其他文件的内容，自然就找不到sum这个函数了，那么加载sum这个函数内容，自然就可以了，对应执行方式就变成了<code>go run main.go math.go</code>，也就是说，要把相关以来的内容相关的文件也要加到run 后面。用<code>go build</code> 如果不指定文件名字，那么go会自行加载依赖项目，可以顺利执行。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[golang入门]]></title>
      <url>http://todu.top/golang/golang%E5%85%A5%E9%97%A8/</url>
      <content type="html"><![CDATA[<p>本文同步发表于<a href="http://www.jianshu.com/users/dc3cafc2a2f1" target="_blank" rel="external">我的简书</a>,<a href="http://www.jianshu.com/p/e00f0cf4f01c" target="_blank" rel="external">点此穿越</a></p>
<h1 id="Go-基本介绍"><a href="#Go-基本介绍" class="headerlink" title="Go 基本介绍"></a>Go 基本介绍</h1><h2 id="Go发展"><a href="#Go发展" class="headerlink" title="Go发展"></a>Go发展</h2><p>早在2007年9月，Go语言还是这帮大牛的20%自由时间的实验项目。 幸运的是， 到了2008年5月 ， Google发现了Go语言的巨大潜力， 从而开始全力支持这个项目 ， 让这批人可以全身心投入Go语言的设计和开发工作中。 Go语言的第一个版本在2009年11月正式对外发布，并在此后的两年内快速迭代，发展迅猛。 第一个正式版本的Go语言于2012年3月28 日正式发布， 让Go语言迎来了第一个引人瞩目的里程碑。截至现在，Go已经更新到1.5版本，1.5正式版就在8月份中旬发布。<br>Go编程语言是一个使得程序员更加有效率的开源项目。Go 是有表达力、简洁、清晰和有效率的。它的并行机制使其很容易编写多核和网络应用，而新奇的类型系统允许构建有弹性 的模块化程序。Go 编译到机器码非常快速，同时具有便利的垃圾回收和强大的运行时反射。它是快速的、静态类型编译语言，但是感觉上是动态类型的，解释型语言。</p>
<h2 id="Go语言最主要的特性："><a href="#Go语言最主要的特性：" class="headerlink" title="Go语言最主要的特性："></a>Go语言最主要的特性：</h2><ul>
<li>自动垃圾回收</li>
<li>更丰富的内置类型</li>
<li>函数多返回值</li>
<li>错误处理</li>
<li>匿名函数和闭包</li>
<li>类型和接口</li>
<li>并发编程</li>
<li>反射</li>
<li>语言交互性</li>
</ul>
<h1 id="开发环境配置"><a href="#开发环境配置" class="headerlink" title="开发环境配置"></a>开发环境配置</h1><p>请参见另一篇博客<a href="http://todu.top/golang/golanghuan-jing-da-jian">Golang 环境搭建</a></p>
<hr>
<p>下面切入正题，介绍Go语言编程，由于只是本篇只是一个快速了解Go，所以有些内容会略微一提，如果读者用到或者要深入了解，可自行找文档参考，这里有个印象即可。</p>
<h1 id="Go-编程基础"><a href="#Go-编程基础" class="headerlink" title="Go 编程基础"></a>Go 编程基础</h1><h2 id="基础数据类型"><a href="#基础数据类型" class="headerlink" title="基础数据类型"></a>基础数据类型</h2><ul>
<li>布尔类型：<code>bool</code></li>
<li>整数类型：<code>int8</code> <code>uint8</code> <code>int16</code> <code>uint16</code> <code>int32</code> <code>uint32</code> <code>int64</code>  <code>uint64</code> <code>int</code> <code>rune</code> <code>byte</code> <code>complex128</code> <code>complex64</code>，其中，<code>byte</code> 是 <code>int8</code> 的别名</li>
<li>浮点类型：<code>float32</code> <code>float64</code></li>
<li>字符串类型：<code>string</code></li>
<li>字符类型： <code>rune</code>，是 <code>int32</code> 的别名</li>
<li>空： <code>nil</code></li>
<li>万能类型： <code>interface{}</code><h2 id="操作符"><a href="#操作符" class="headerlink" title="操作符"></a>操作符</h2><code>+</code>    <code>&amp;</code>     <code>+=</code>    <code>&amp;=</code>     <code>&amp;&amp;</code>    <code>==</code>    <code>!=</code>   <code>(</code>    <code>)</code><br><code>-</code>    <code>|</code>     <code>-=</code>    <code>|=</code>     <code>||</code>    <code>&lt;</code>     <code>&lt;=</code>    <code>[</code>    <code>]</code><br><code>*</code>    <code>^</code>     <code>*=</code>    <code>^=</code>     <code>&lt;-</code>   <code>&gt;</code>     <code>&gt;=</code>   <code>{</code>    <code>}</code><br><code>/</code>    <code>&lt;&lt;</code>    <code>/=</code>    <code>&lt;&lt;=</code>    <code>++</code>    <code>=</code>     <code>:=</code>    <code>,</code>    <code>;</code><br><code>%</code>    <code>&gt;&gt;</code>    <code>%=</code>    <code>&gt;&gt;=</code>    <code>--</code>    <code>!</code>     <code>...</code>   <code>.</code>    <code>:</code><br><code>&amp;^</code>       <code>&amp;^=</code>    <code>-&gt;</code><h2 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h2></li>
<li><code>len</code>：计算（字符串，数组或者切片，map）长度</li>
<li><code>cap</code>：计算（数组或者切片，map）容量</li>
<li><code>close</code>：关闭通道</li>
<li><code>append</code>：追加内容到切片</li>
<li><code>copy</code>：拷贝数组/切片内容到另一个数组/切片</li>
<li><code>delete</code>：用于删除map的元素<h2 id="变量的定义和赋值"><a href="#变量的定义和赋值" class="headerlink" title="变量的定义和赋值"></a>变量的定义和赋值</h2></li>
</ul>
<ol>
<li><p>先定义，后赋值。变量的定义要用<code>var</code> 关键字声明，如,<code>var str string</code>，这就定义了一个名字为“str”的<code>string</code>类型的变量；（有过其他编程语言经验的读者可能会有点不适应，不过没错，Go的变量类型就是放在变量后面的。）还可以一次定义多个变量，如 <code>var a string, b int</code>;这样就同时定义了一个字符串类型和一个int类型的变量；如果几个连续的变量是同样的类型，可以一次性在最后该类型变量后说明，不需要单个说明。<code>var a, b, c string, int d</code>。也可以多行分别定义，如：</p>
 <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="keyword">string</span></span><br><span class="line"><span class="keyword">var</span> b <span class="keyword">string</span></span><br><span class="line"><span class="keyword">var</span> c <span class="keyword">int</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这种写法要重复写<code>var</code>这个关键字，其实这种写法是可以只写一个<code>var</code>的，等价于下面的写法：</p>
<pre><code><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">    a, b <span class="keyword">string</span></span><br><span class="line">    c <span class="keyword">int</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</code></pre><ol>
<li>变量的赋值<br><code>var a string</code>,定义一个<code>string</code>类型的<code>a</code>变量，然后<code>a = &quot;this is a string&quot;</code>就可以把字符串的值赋给a了。这里有个简便的写法，就是声明和赋值同时进行，以上两句等同于<code>var a string = &quot;this is a string&quot;</code>,这种写法大多数语言都是类似的.由于Go可以根据变量的值自动推断该变量的数据类型，所以还等价于<code>var a = &quot;this is a string&quot;</code>；另外Go中还有个更为简洁的写法，等同于<code>a := &quot;this is a string&quot;</code>，直接省略关键字<code>var</code>，取而代之的是一个操作符<code>：=</code>，这个操作符的作用就是声明并赋值。</li>
<li>常量的定义和赋值<br>常量用关键词<code>const</code>说明，并且常量的值是在定义的时候一次性赋值的，如定义一个字符串常量，<code>const CONST_STR = &quot;const string&quot;</code>等价于<code>const CONST_STR string = &quot;const string&quot;</code>。</li>
<li>*注意<br><code>const</code>，<code>var</code>和<code>:=</code>不可同时使用。</li>
</ol>
<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><p>函数的结构如下 <code>func func_name([param_name type][...]) [return_value type[...]]</code>。<br>以关键字<code>func</code>开头， 后面是函数名， 函数名后面是函数参数，参数个数大于等于0个，参数后面是返回值，返回值个数&gt;=0，也就是说，Go语言支持多返回值。<br>其中go中有个特殊的函数(其实还有一个init函数，但是作为入门篇，不在这里介绍了)，那就是main函数，main函数是无参，无返回值，名字是main的一个特殊函数，它是程序的入口，并且main函数只能定义在mian的包（下面有介绍）中。</p>
<h2 id="包"><a href="#包" class="headerlink" title="包"></a>包</h2><p>如果您是Java开发者，想必对包的概念并不陌生。在Go语言中，如果开发中有来自不同库的同名的函数，该如何处理，这就要依靠package来区分，也就是说包的作用类似于作用于，是对函数，变量等作用范围的一种约束。</p>
<h3 id="包的定义"><a href="#包的定义" class="headerlink" title="包的定义"></a>包的定义</h3><p>包的定义是通过 <code>package</code>这个关键字来说明的，一般写在文件的最上方。如<code>package a</code>，则定义了一个名字为a的包。包的名字只允许有一级目录，即不允许类似java的<code>com.example.a</code>或者<code>com/example/a</code>这样的多层级定义。一般来说，包的名字最好和其父目录的名字一致，这样在使用包和包里的内容时会比较容易理解（另会有文章说明）。</p>
<h3 id="包的使用"><a href="#包的使用" class="headerlink" title="包的使用"></a>包的使用</h3><p>包的导入使用关键字<code>import</code>来声明，如要在其他包中导入上面定义的包<code>a</code>，则声明如下：<code>import &quot;a&quot;</code>，如果多个，可以类似定义变量：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">"a"</span></span><br><span class="line">    <span class="string">"b"</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="函数和变量（常量）导出规则"><a href="#函数和变量（常量）导出规则" class="headerlink" title="函数和变量（常量）导出规则"></a>函数和变量（常量）导出规则</h2><p>Go语言中，抛弃了类似C++和Java中的private，public，protected，或者是friendld的可见性定义，采取了极简方式。如果变量或者函数首字母大写，代表可以导出，即对其他包是可见的，否则是不可见的。</p>
<p>到这里，Go的基本概念已经基本讲清楚，下面用一个示例说明上面的概念。</p>
<ol>
<li>创建一个文件夹，名字假设叫做 <code>example</code>。</li>
<li><p>进入example，创建文件<code>main.go</code>,并添加以下内容：</p>
 <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main <span class="comment">//因为这里有程序的入口，main方法存在，所以包名必须命名为main</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里导入要使用的包</span></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">"./number"</span> <span class="comment">//这里导入我们自己定义的包，“./”是说用相对路径的方式导入包</span></span><br><span class="line">	<span class="string">"fmt"</span> <span class="comment">//fmt是go标准包，用于处理输入输出</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">//这是程序的主函数，写法就是这样固定的，无参，无返回值</span></span><br><span class="line"><span class="keyword">func</span> main() &#123;</span><br><span class="line">	<span class="comment">//调用我们的函数并把产生的结果赋值给定义的max和min变量，根据GetMaxAndMin的返回值类型，go自动推断出max和min的是int类型</span></span><br><span class="line">	max, min := number.GetMaxAndMin(<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment">//调用格式话输出打印max和min</span></span><br><span class="line">	fmt.Printf(<span class="string">"max:%v, min:%v\n"</span>, max, min)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建文件<code>numbner.go</code>，并添加如下内容：</p>
 <figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这里可以添加注释，这是单行注释</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span><br><span class="line">	这里也是注释，</span><br><span class="line">	是多行注释，</span><br><span class="line">	允许注释跨行</span><br><span class="line">*/</span></span><br><span class="line"><span class="keyword">package</span> number<span class="comment">// 这是包名，除了文件的注释，一般包名要放在最上方</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里定义一个函数，用来获取values参数中的最大值和最小值。</span></span><br><span class="line"><span class="comment">// 函数名GetMaxAndMin大写代表其他包可见，如果是小写，则其他包不可引用该函数</span></span><br><span class="line"><span class="comment">// (a, b int, values ...int)，a，b, values都是该函的参数，a,b是必填的参数，</span></span><br><span class="line"><span class="comment">// ...代表values是变参，即长度不固定，个数&gt;=0,并且都是int类型</span></span><br><span class="line"><span class="comment">// (int, int)代表该函数有两个返回值，都是int类型</span></span><br><span class="line"><span class="keyword">func</span> GetMaxAndMin(a, b <span class="keyword">int</span>, values ...<span class="keyword">int</span>) (<span class="keyword">int</span>, <span class="keyword">int</span>) &#123;</span><br><span class="line">	max, min := a, a <span class="comment">//定义并赋值两个变量 max，min，并把a的值赋给max和min</span></span><br><span class="line">	<span class="keyword">if</span> a&lt;b &#123; <span class="comment">//go允许简单条件和控制语句之间不加小括号，并且大括号左部分必须和条件在同一行</span></span><br><span class="line">		max = b</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		min = b</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 这里是for循环，在go中for是非常给力的循环控制器，没有其他方式（不推荐用goto）</span></span><br><span class="line">	<span class="comment">// _ 的作用是说把遍历values产生的下标的值忽略掉，v是产生的values的值，</span></span><br><span class="line">	<span class="comment">// range 关键词 用来配合for，构成一个简单的循环结构，相当于for-each</span></span><br><span class="line">	<span class="comment">// 关于 “_”，因为go中不允许有多余的为使用的参数和为使用的包，所以“_”就充当了一个垃圾桶的角色，多返回值产生的不必要值可以填入“_”,</span></span><br><span class="line">	<span class="comment">// 从而达到控制编译器编译过程中不会报错。</span></span><br><span class="line">	<span class="keyword">for</span> _, v := <span class="keyword">range</span> values &#123;</span><br><span class="line">		<span class="keyword">if</span> v&gt;a &#123;</span><br><span class="line">			max = v</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> v&lt;b &#123;</span><br><span class="line">			min = v</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> max, min</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>注意，文件保存编码是utf-8 。<br>打开终端（命令行工具），切换到example目录下，执行<code>go run main.go</code>,可以看到有内容输出：<br>&gt;<br>max:8, min:0</p>
<p><a href="http://todu.top/golang/golangming-ling">附Go命令</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[golang-http-client-post]]></title>
      <url>http://todu.top/golang/golang-http-client-post/</url>
      <content type="html"><![CDATA[<hr>
<p>title: Golang环境搭建<br>date: 2016-03-13 11:10:48<br>tags:</p>
<ul>
<li>go</li>
<li>golang<br>category: golang</li>
</ul>
<hr>
<h1 id="下载Go"><a href="#下载Go" class="headerlink" title="下载Go"></a>下载Go</h1><p><a href="http://golang.org" target="_blank" rel="external">go官方网站</a>在大陆已经被和谐，要访问，如果没有梯子，这里有个<a href="http://www.tvdaili.com/" target="_blank" rel="external">传送门</a>,可以在线代理访问。首先就是要下载go开发程序了，建议<a href="http://golangtc.com/download" target="_blank" rel="external">在此处下载</a>对应版本。</p>
<h1 id="配置Go环境"><a href="#配置Go环境" class="headerlink" title="配置Go环境"></a>配置Go环境</h1><pre><code>## Window 环境
</code></pre><p>下载对应的windows版本（注意64位和32位系统），然后解压得到go目录，假如名字就叫go，绝对路径是E:\go。右键计算机(xp 是我的电脑，windows8是这台电脑)，选择属性，选择左侧的高级系统设置，接下来选择环境变量，出现环境变量的对话框。上面是当前用户的环境变量，也就是说配置的变量只是针对当前用户生效；下面是系统变量，对于整个系统的所有用户生效。我习惯于配置成系统变量，在此也是用系统变量举例。<br>点击系统变量下的新建按钮，变量名填写 GOROOT,变量值填写上面解压后的go路径，在这也就是 E:\go，然后点击确定。这个变量是用来配置go的home目录。再点击新建按钮，变量名填写GOPATH，变量值填写E:\gopath(gopath要存在，当然也可以选择其他文件夹)，点击确定。这个变量是用来指定go查找包的路径，也是用go get 命令所需安装的位置目录。然后找到PATH变量，点击编辑，变量值最后添加一个半角分号，然后再输入 %GOROOT%\bin，点击确定。可以关闭所有窗口了。<br>在开始菜单中打开cmd命令行（也可以用快捷键，windows键+R，然后输入cmd回车）。在窗口中输入go回车，如果有go相关的帮助打印，则说明配置成功，否则没有成功，重新校验上面的环境变量配置是否正确。</p>
<pre><code>## Linux 环境
假设对应版本的go解压后绝对路径是/home/user/go。
vi（或者你喜欢的其他编辑器）打开 ~/.bashrc文件，在后面加入
&gt;
GOROOT=/home/user/go
GOPATH=/home/user/gopath
PATH=$PATH:$GOROOT/bin
export GOROOT GOPATH PATH

然后 运行命令 `soure ~/.bashrc`
输入 go ，如果打印go帮助文档，说明配置成功，否则检查环境变量配置是否正确。
</code></pre><h1 id="编写第一个Go程序"><a href="#编写第一个Go程序" class="headerlink" title="编写第一个Go程序"></a>编写第一个Go程序</h1><p>用你喜欢的编辑器编辑一个文件，加入文件名叫 hello.go 。<br>敲入以下代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line">import （</span><br><span class="line">“fmt”</span><br><span class="line">）</span><br><span class="line">func main()&#123;</span><br><span class="line">    fmt.println(&quot;Hello World!&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>然后再该文件当前目录下，输入 go build hello.go，在目录下会生成一个 hello(windows下是hello.exe)文件，运行该文件，可以看到控制台输入出 HelloWorld,运行成功。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Golang环境搭建]]></title>
      <url>http://todu.top/golang/Golang%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<h1 id="下载Go"><a href="#下载Go" class="headerlink" title="下载Go"></a>下载Go</h1><p><a href="http://golang.org" target="_blank" rel="external">go官方网站</a>在大陆已经被和谐，要访问，如果没有梯子，这里有个<a href="http://www.tvdaili.com/" target="_blank" rel="external">传送门</a>,可以在线代理访问。首先就是要下载go开发程序了，建议<a href="http://golangtc.com/download" target="_blank" rel="external">在此处下载</a>对应版本。</p>
<h1 id="配置Go环境"><a href="#配置Go环境" class="headerlink" title="配置Go环境"></a>配置Go环境</h1><pre><code>## Window 环境
</code></pre><p>下载对应的windows版本（注意64位和32位系统），然后解压得到go目录，假如名字就叫go，绝对路径是E:\go。右键计算机(xp 是我的电脑，windows8是这台电脑)，选择属性，选择左侧的高级系统设置，接下来选择环境变量，出现环境变量的对话框。上面是当前用户的环境变量，也就是说配置的变量只是针对当前用户生效；下面是系统变量，对于整个系统的所有用户生效。我习惯于配置成系统变量，在此也是用系统变量举例。<br>点击系统变量下的新建按钮，变量名填写 GOROOT,变量值填写上面解压后的go路径，在这也就是 E:\go，然后点击确定。这个变量是用来配置go的home目录。再点击新建按钮，变量名填写GOPATH，变量值填写E:\gopath(gopath要存在，当然也可以选择其他文件夹)，点击确定。这个变量是用来指定go查找包的路径，也是用go get 命令所需安装的位置目录。然后找到PATH变量，点击编辑，变量值最后添加一个半角分号，然后再输入 %GOROOT%\bin，点击确定。可以关闭所有窗口了。<br>在开始菜单中打开cmd命令行（也可以用快捷键，windows键+R，然后输入cmd回车）。在窗口中输入go回车，如果有go相关的帮助打印，则说明配置成功，否则没有成功，重新校验上面的环境变量配置是否正确。</p>
<pre><code>## Linux 环境
假设对应版本的go解压后绝对路径是/home/user/go。
vi（或者你喜欢的其他编辑器）打开 ~/.bashrc文件，在后面加入
&gt;
GOROOT=/home/user/go
GOPATH=/home/user/gopath
PATH=$PATH:$GOROOT/bin
export GOROOT GOPATH PATH

然后 运行命令 `soure ~/.bashrc`
输入 go ，如果打印go帮助文档，说明配置成功，否则检查环境变量配置是否正确。
</code></pre><h1 id="编写第一个Go程序"><a href="#编写第一个Go程序" class="headerlink" title="编写第一个Go程序"></a>编写第一个Go程序</h1><p>用你喜欢的编辑器编辑一个文件，加入文件名叫 hello.go 。<br>敲入以下代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line">import （</span><br><span class="line">“fmt”</span><br><span class="line">）</span><br><span class="line">func main()&#123;</span><br><span class="line">    fmt.println(&quot;Hello World!&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>然后再该文件当前目录下，输入 go build hello.go，在目录下会生成一个 hello(windows下是hello.exe)文件，运行该文件，可以看到控制台输入出 HelloWorld,运行成功。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[删除git已经跟踪的文件或者目录]]></title>
      <url>http://todu.top/git/%E5%88%A0%E9%99%A4git%E5%B7%B2%E7%BB%8F%E8%B7%9F%E8%B8%AA%E7%9A%84%E6%96%87%E4%BB%B6%E6%88%96%E8%80%85%E7%9B%AE%E5%BD%95/</url>
      <content type="html"><![CDATA[<p>如果第一次提交的时候，没有在gitignore文件中添加忽略文件，那么这些文件（目录也是文件）就会被git跟踪，push的时候也会被推送到远程。所以最好就是一开始在commit之前先添加到gitignore中。</p>
<p>如果文件已经被跟踪且被推送到远程，可以按照下面方法解决：<br>1.<code>rm -rf 文件</code></p>
<ol>
<li><code>git rm -r --cached 要忽略的文件</code><br>3.<code>git add -A (添加所有)</code><br>4.<code>git push origin 分支</code></li>
</ol>
<p>如果同名的文件过多，如：.class 文件被提交了，那么如果这样一个一个显然效率太低，可以按照下面方法操作</p>
<ol>
<li><code>find . -iname 文件名 -exec rm -rf {}\;</code></li>
<li>重复上面的步骤，文件名替换为下一个要删除的文件名</li>
<li>修改gitignore，添加忽略文件</li>
<li><code>git rm -r --cached 要忽略的文件</code></li>
<li><code>git add -A</code></li>
<li><code>git push origin 分支</code></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[hadoop集成hive]]></title>
      <url>http://todu.top/hadoop/hadoop%E9%9B%86%E6%88%90hive/</url>
      <content type="html"><![CDATA[<h1 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h1><p>hadoop和yarn已经配置好并且成功运行。</p>
<h1 id="选择版本和下载"><a href="#选择版本和下载" class="headerlink" title="选择版本和下载"></a>选择版本和下载</h1><p><a href="http://www.apache.org/dyn/closer.cgi/hive/" target="_blank" rel="external">下载hive</a>，有两个版本可以选择，hive1和hive2，hive2版本MR功能已经废弃，将来版本可能会直接去掉，如果要用hive的MR功能，那么请选择hive1相应版本，否则的话选哪个都可以进行测试。</p>
<h1 id="配置hive"><a href="#配置hive" class="headerlink" title="配置hive"></a>配置hive</h1><ol>
<li>下载完hive后，解压，然后<code>sudo vi /etc/profile</code>编辑文件，添加环境变量</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">HIVE_HOME=hive目录的绝路路径</span><br><span class="line">PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME PATH</span><br></pre></td></tr></table></figure>
<ol>
<li><p>控制台输入<code>source /etc/profile</code>使环境变量生效。</p>
</li>
<li><p>进入$HIVE_HOME/conf目录，拷贝<code>hive-default.xml.template</code>并重命名为<code>hive-site.xml</code>，编辑：（如果没有该参数，请自行添加，存在则改之）</p>
</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="comment">&lt;!--hdfs目录 hive目录需要手动创建,并改为777权限--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Scratch space for Hive jobs<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="comment">&lt;!--hdfs目录，需要手动创建--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>location of default database for the warehouse<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="comment">&lt;!--修改为自己的mysql数据库--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>JDBC connect string for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="comment">&lt;!--mysql用户名--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="comment">&lt;!--mysql密码--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>password to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol>
<li><p>然后查找value是<code>${system</code>开头的，替换成具体的本地绝对路径，可以创建一个hive用户，放到hive用户目录下。</p>
</li>
<li><p>拷贝<code>hive-env.sh.template</code>并重命名<code>hive-env.sh</code>，添加如下内容，注意环境变量值更换为自己的路径。</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_HOME=/home/hadoop/hadoop-2.7.1 </span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/share/jdk1.8.0_73</span><br></pre></td></tr></table></figure>
<ol>
<li>将hive-site.xml拷贝一份到hadoop的配置目录。</li>
<li>下载mysql驱动放到hive目录下的lib目录中。</li>
<li>启动hive，控制台输入<code>hive</code>，如果正确则输出一段信息后进入hive交互模式。</li>
</ol>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ol>
<li><blockquote>
<p>Caused by: org.datanucleus.store.rdbms.connectionpool.DatastoreDriverNotFoundException: The specified datastore driver (“com.mysql.jdbc.Driver”) was not found in the CLASSPATH. Please check your CLASSPATH specification, and the name of the driver.</p>
</blockquote>
<p> <strong>解决方法</strong>：下载mysql驱动放到hive的lib目录</p>
</li>
<li><blockquote>
<p>org.apache.hadoop.security.AccessControlException: Permission denied: user=hive, access=WRITE, inode=”/tmp/hadoop-yarn/staging/hive/.staging”:hadoop:supergroup:drwxr-xr-x</p>
</blockquote>
<p> <strong>解决方法</strong>：在hdfs中创建tmp目录，并改为777权限。</p>
</li>
<li><blockquote>
<p>Starting Job = job_1457683200911_0001, Tracking URL = <a href="http://10.10.1.110:8088/proxy/application_1457683200911_0001/" target="_blank" rel="external">http://10.10.1.110:8088/proxy/application_1457683200911_0001/</a><br>Kill Command = /home/hadoop/hadoop-2.7.1/bin/hadoop job  -kill job_1457683200911_0001<br>Hadoop job information for Stage-1: number of mappers: 0; number of reducers: 0，打开管理页面发现信息：waiting for AM container to be allocated, launched and register with RM.</p>
</blockquote>
<p> <strong>解决方法</strong>：yarn没有配置正确，没有启动<code>nodemanager</code>，启动命令<code>yarn-daemon.sh start nodemanager</code>，启动之后即可运行job。</p>
</li>
</ol>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol>
<li><a href="http://blog.csdn.net/jyf211314/article/details/34110721" target="_blank" rel="external">hadoop2.2完全分布式集群+hive+mysql存储元数据配置</a>排版有点乱，请将就看</li>
<li><a href="http://blog.csdn.net/z363115269/article/details/39048589" target="_blank" rel="external">hive导入HDFS数据</a> 和上面毛病类似</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[SpingXD结合Hadoop]]></title>
      <url>http://todu.top/spring/SpingXD%E7%BB%93%E5%90%88Hadoop/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>之前的文章介绍了<a href="/Spring-XD简介">Spring XD</a>，<a href="/以分布式方式运行Spring-XD">以分布式方式运行Spring-XD</a>和<a href="/安装启动Hadoop集群">安装启动Hadoop集群</a>的文章。本文将简单介绍（刚学，很LOW(⊙﹏⊙)b）SpringXD和Hadoop，HDFS结合配置和使用方法。</p>
<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>已经按照上述提到的两篇文章或者其他资料搭建并运行了SpringXD和Hadoop。</p>
<h1 id="配置SpringXD"><a href="#配置SpringXD" class="headerlink" title="配置SpringXD"></a>配置SpringXD</h1><ol>
<li>运行命令<code>jps</code>找到<code>AdminServerApplication</code>和<code>ContainerServerApplication</code>两项，结束进程<code>kill 进程pid</code>。</li>
<li>编辑SpingXD的配置文件<code>server.yaml</code>，在<code>spring</code>节点下增加以下hadoop的配置信息：</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">hadoop:</span></span><br><span class="line">	&lt;!-- 注意换成自己的hdfs地址 --<span class="string">&gt;</span><br><span class="line"></span><span class="attr">    fsUri:</span> hdfs://<span class="number">10.10</span><span class="number">.1</span><span class="number">.110</span>:<span class="number">8020</span></span><br><span class="line"><span class="attr">    resourceManagerHost:</span> <span class="number">10.10</span><span class="number">.1</span><span class="number">.110</span></span><br><span class="line"><span class="attr">    resourceManagerPort:</span> <span class="number">8032</span></span><br><span class="line"><span class="attr">    yarnApplicationClasspath:</span></span><br></pre></td></tr></table></figure>
<p>然后启动xd-admin<code>bin/xd-admin</code>和xd-container<code>bin/xd-container</code>。</p>
<ol>
<li>切换到hadoop用户下，使用命令<code>hadoop fs -mkdir /xd</code>创建目录，然后更改权限<code>hadoop fs -chmod -R 777 /xd</code>（如果没有配置hadoop的环境变量，则请进入hadoop的目录使用<code>bin/hadoop</code>命令代替<code>hadoop</code>）</li>
<li>打开新的控制台，进入xd-shell交互环境，假如根据上面的Spring-XD配置文章配置了安全措施，那么还需要执行下面的命令<code>admin config server --uri http://xd-adminIP:9393 --username 用户名 --password 密码</code>进行授权后登录。</li>
<li>创建stream，向hdfs中写入数据<code>stream create --name myhdfsstream1 --definition &quot;time | hdfs&quot; --deploy</code>，用命令<code>hadoop fs ls /xd/myhdfsstream1</code>即可看到有临时文件生成。</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Hexo+Git+Oschina+Golang+Tenxcloud打造博客]]></title>
      <url>http://todu.top/other/Hexo-Git-Oschina-Golang-Tenxcloud%E6%89%93%E9%80%A0%E5%8D%9A%E5%AE%A2/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><em>Hexo</em> 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。具体使用方法<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="external">参见这里</a></p>
<p><em>Git</em> 介绍和使用<a href="http://gitref.org/zh/index.html" target="_blank" rel="external">参见这里</a></p>
<p><em>OSCina</em> 开源信息平台，这里指的是<a href="http://git.oschina.net/" target="_blank" rel="external">其下的Git托管平台</a></p>
<p><em>Golang</em> 谷歌开发的一款跨平台的语言，<a href="golang.org">官方地址</a>在国内无法打开，<a href="http://golangtc.com/" target="_blank" rel="external">golangtc</a>是一个Golang学习网站，可以自行查阅。</p>
<p><em>TenxCloud</em> 也就是<a href="https://www.tenxcloud.com/" target="_blank" rel="external">时速云</a>，是国内最早的容器云平台之一(Container as a service)，提供丰富的容器化应用，镜像构建与发布，弹性可伸缩的容器服务，以及灵活、高性能的容器主机管理。容器化应用包括但不限于云主机，云数据库，大数据，Web应用等。</p>
<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><ol>
<li>安装hexo</li>
<li>安装Golang，并配置Golang环境</li>
<li>安装Git，并配置相关环境变量</li>
</ol>
<h1 id="创建Git仓库"><a href="#创建Git仓库" class="headerlink" title="创建Git仓库"></a>创建Git仓库</h1><p>打开<a href="http://git.oschina.net/" target="_blank" rel="external">开源中国Git托管平台</a>，(注册后)登录，点击右上角<code>+</code>号，新建项目，输入项目名，描述，如果不想公开的话，可以选择私有，其余默认即可，点击创建。然后克隆到本地。命令行切换到刚才克隆的项目根目录，输入<code>hexo init</code>，hexo博客初始化完成。输入<code>hexo generate</code>可以渲染页面，生成静态页面，默认是在public文件夹。hexo默认初始化忽略了public文件夹，我们需要修改<code>.gitignore</code>文件，删除public的记录，这样保证可以同步到git仓库中。</p>
<h1 id="编写Golang-Server服务"><a href="#编写Golang-Server服务" class="headerlink" title="编写Golang Server服务"></a>编写Golang Server服务</h1><p>在项目根目录创建一个叫<code>server.go</code>的文件，把下面的代码考入即可。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">"net/http"</span></span><br><span class="line">	<span class="string">"log"</span></span><br><span class="line">	<span class="string">"os/exec"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">func</span> main() &#123;</span><br><span class="line">	fs := http.FileServer(http.Dir(<span class="string">"public"</span>))</span><br><span class="line">	http.Handle(<span class="string">"/"</span>, fs)</span><br><span class="line"></span><br><span class="line">	<span class="comment">//用于git的webhook，触发pull</span></span><br><span class="line">	http.HandleFunc(<span class="string">"/_blog/_pull"</span>, <span class="keyword">func</span>(writer http.ResponseWriter, request *http.Request) &#123;</span><br><span class="line">		cmd := exec.Command(<span class="string">"git"</span>,<span class="string">"pull"</span>)</span><br><span class="line">		<span class="keyword">if</span> err:=cmd.Start(); err!=<span class="literal">nil</span> &#123;</span><br><span class="line">			log.Println(<span class="string">"git pull error"</span>, err)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;)</span><br><span class="line"></span><br><span class="line">	err := http.ListenAndServe(<span class="string">":80"</span>, <span class="literal">nil</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatal(<span class="string">"ListenAndServe: "</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过git提交文件到远程。</p>
<h1 id="创建容器"><a href="#创建容器" class="headerlink" title="创建容器"></a>创建容器</h1><p>这里之所以选择时速云，是因为一开始接触这类最早的就是这个平台，所以使用的还算熟悉。下面我们就在上面创建一个容器。</p>
<ol>
<li>登录之后，<a href="https://hub.tenxcloud.com/repos/sdvdxl/golang" target="_blank" rel="external">选择这个镜像</a>，此镜像集成了Git，Golang，SSH服务，点击右侧部署镜像按钮。如下图配置：<br><img src="/images/other/2016-03-09_2351.png" alt="配置">，点击创建按钮，等待片刻即可创建成功。</li>
<li><a href="https://console.tenxcloud.com/containers?0" target="_blank" rel="external">返回容器服务</a>，切换到北京2区，可以看到我们刚才创建的容器服务，点击如图所示的图标，进入控制台：<br><a href="/images/other/2016-03-09_2355.png">进入控制台</a>。</li>
<li>进入控制台后，使用git命令<code>git clone 之前创建的git仓库地址</code>，克隆完后，进入项目目录，输入<code>go build server.go</code>，然后输入<code>./server &amp;</code>运行服务端。</li>
<li>现在打开容器服务视图，找到我们创建的容器，点击右侧的查看所有服务地址，点击协议为<code>HTTP</code>的那个服务地址，在打开的页面中即可看到我们的博客内容。</li>
<li>点击绑定域名，绑定80端口域名，我们就可以通过自己的域名访问了。</li>
</ol>
<h1 id="设置WebHooks"><a href="#设置WebHooks" class="headerlink" title="设置WebHooks"></a>设置WebHooks</h1><p>打开开源中国git平台，找到刚创建的项目，点击右侧的管理，然后点击左侧的WebHooks，URL输入<code>http://你的域名/_blog/_pull</code>，Push和合并请求打上勾，然后提交。</p>
<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><ol>
<li>不要选择杭州区的服务，因为采用的是阿里云服务，所以会导致没有备案的域名没法打开。</li>
<li>本博客公开托管在<a href="http://git.oschina.net/sdvdxl/blog" target="_blank" rel="external">开源中国的Git服务上</a>，大家可以fork之后改动后用作自己的博客平台。</li>
<li>方便起见，Golang脚本已经编译成了<code>Windows</code> <code>Mac</code> <code>Linux</code> 各平台的32和64位版本，无需编译server.go文件了，可以直接选择相应平台文件进行运行，启动web服务。</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[安装启动Hadoop集群]]></title>
      <url>http://todu.top/hadoop/%E5%AE%89%E8%A3%85%E5%90%AF%E5%8A%A8Hadoop%E9%9B%86%E7%BE%A4/</url>
      <content type="html"><![CDATA[<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><p>UCloud云主机，2.6.32-431.11.15.el6.ucloud.x86_64<br>假设三台主机内网IP分别为10.10.1.10, 10.10.1.11和10.10.1.12，hostname分别为：10-10-1-10,10-10-1-11和10-10-1-12</p>
<h1 id="配置JDK"><a href="#配置JDK" class="headerlink" title="配置JDK"></a>配置JDK</h1><p>本次搭建测试用的是jdk8，可以从<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="external">Oracle官网下载</a>对应的版本。</p>
<h2 id="配置jdk"><a href="#配置jdk" class="headerlink" title="配置jdk"></a>配置jdk</h2><p>假设jdk解压后目录存放在<code>/usr/local/jdk8</code>，命令行输入<code>sudo vi /etc/profile</code>，添加一下内容：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/usr/<span class="built_in">local</span>/jdk8</span><br><span class="line">CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/jre/lib</span><br><span class="line">PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br></pre></td></tr></table></figure></p>
<p>然后输入<code>source /etc/profile</code>使环境变量生效，输入<code>java -version</code>有java版本信息输出说明配置成功，三台主机均这么配置。</p>
<h1 id="配置hadoop用户"><a href="#配置hadoop用户" class="headerlink" title="配置hadoop用户"></a>配置hadoop用户</h1><p>控制台输入<code>sudo useradd -m -U hadoop</code> 添加hadoop用户，然后输入<code>sudo passwd hadoop</code> 修改hadoop用户的密码，输入<code>su -l hadoop</code>，输入刚才设置的密码，切换到hadoop用户。</p>
<h1 id="配置ssh"><a href="#配置ssh" class="headerlink" title="配置ssh"></a>配置ssh</h1><p>前提是已经切换到hadoop用户。<br>在每个主机控制台输入<code>ssh-keygen</code>回车，一直回车直到结束。最后在master主机上使用<code>ssh-copy-id</code>命令拷贝认证信息到本主机和其他两台主机，这样可以免密码登录。<code>ssh-copy-id hadoop@主机地址</code>，注意本机地址不要使用localhost和127.0.0.1，请使用局域网ip，在这里是10.10.1.10。</p>
<h1 id="配置网络"><a href="#配置网络" class="headerlink" title="配置网络"></a>配置网络</h1><p>以修改10.10.1.10主机为例，在控制台输入<code>sudo vi /etc/hosts</code>，在内容中添加一下信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1 10-10-128-53</span><br><span class="line">10.10.248.115 10-10-248-115</span><br><span class="line">10.10.227.51 10-10-227-51</span><br></pre></td></tr></table></figure></p>
<p>注意，千万不要配置<code>10.10.1.10 10-10-1-10</code>本主机ip映射本主机名的条目，否则会造成主机间无法监听。其余两台参照这个也进行配置。</p>
<h1 id="配置Hadoop"><a href="#配置Hadoop" class="headerlink" title="配置Hadoop"></a>配置Hadoop</h1><ol>
<li><a href="http://hadoop.apache.org/releases.html" target="_blank" rel="external">下载Hadoop</a>，这里下载的是<code>2.7.1</code>版本。控制输入<code>wget http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz</code>，等待下载完成。</li>
<li>控制台输入<code>tar -xvf hadoop-2.7.1.tar.gz</code>解压，会生成<code>hadoop-2.7.1</code>目录。</li>
<li>输入<code>cd hadoop-2.7.1/etc/hadoop</code>进入配置文件目录。</li>
<li>修改<code>hadoop-env.sh</code>中的<code>export JAVA_HOME=</code>，将等号后的内容改成上面配置的jdk绝对路径，在这里就是<code>/usr/local/jdk8</code>，修改完后应该是<code>export JAVA_HOME=/usr/local/jdk8</code>，保存退出。</li>
<li>修改<code>core-site.xml</code>，配置config内容：</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 注意，这里改成自己本机的ip --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://10.10.1.10:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.default.namenode<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 注意，这里改成自己本机的ip --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://10.10.1.10:8082<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>io.file.buffer.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.native.lib<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Should native hadoop libraries, if present, be used.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol>
<li>修改<code>hdfs-site.xml</code>，修改config内容为：</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop-cluster1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 注意修改为自己的ip --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.10.1.10:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol>
<li>修改<code>yarn-site.xml</code></li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 注意ip改为自己的 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.10.1.10:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.10.1.10:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.10.1.10:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.10.1.10:8033<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.10.1.10:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol>
<li>修改<code>mapred-site.xml</code></li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobtracker.http.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.10.128.53:50030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.10.128.53:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10.10.128.53:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol>
<li>修改<code>slaves</code>文件，添加其他两台ip</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">10.10</span>.1.11</span><br><span class="line"><span class="number">10.10</span>.1.12</span><br></pre></td></tr></table></figure>
<p>将hadoop目录覆盖到其余机器对应目录。<br>下面开始操作hadoop命令，如果遇到hadoop native错误，请查看文末<code>Hadoop Native 配置</code>部分。</p>
<ol>
<li>格式化文件系统<br>注意：这里的格式化文件系统并不是硬盘格式化，只是针对主服务器hdfs-site.xml的dfs.namenode.name.dir和dfs.datanode.data.dir目录做相应的清理工作。切换到Hadoop的home目录，执行<code>bin/hdfs namenode -format</code>。</li>
<li>启动停止服务<br>启动<code>sbin/start-dfs.sh</code>，可以一次性启动master和slaves节点服务。<code>sbin/start-yarn.sh</code>启动yarn资源管理服务。要停止服务，用对应的<code>sbin/stop-dfs.sh</code>和<code>sbin/stop-dfs.sh</code>即可停止服务。</li>
<li>单独启动一个datanode<br>增加节点或者重启节点，需要单独启动，则可使用以下命令:<br><code>sbin/hadoop-daemon.sh start datanode</code>，启动nodeManager<code>sbin/yarn-daemon.sh start nodemanager</code>，当然也可以操作namenode<code>sbin/hadoop-daemon.sh start namenode</code> <code>sbin/yarn-daemon.sh start resourcemanager</code>。<br><strong>注意</strong>：原文中是<code>sbin/yarn-daemons.sh</code>和<code>sbin/hadoop-daemons.sh</code>，运行后发现并没有启动成功，去掉s后启动成功。</li>
</ol>
<h1 id="Hadoop-Native-配置"><a href="#Hadoop-Native-配置" class="headerlink" title="Hadoop Native 配置"></a>Hadoop Native 配置</h1><p>输入  <code>hadoop checknative</code> 检查Hadoop本地库版本和相关依赖信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">16/03/10 12:17:56 DEBUG util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...</span><br><span class="line">16/03/10 12:17:56 DEBUG util.NativeCodeLoader: Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: /home/hadoop/hadoop-2.6.3/lib/native/libhadoop.so.1.0.0: /lib64/libc.so.6: version `GLIBC_2.14&apos; not found (required by /home/hadoop/hadoop-2.6.3/lib/native/libhadoop.so.1.0.0)</span><br><span class="line">16/03/10 12:17:56 DEBUG util.NativeCodeLoader: java.library.path=/home/hadoop/hadoop-2.6.3/lib/native</span><br><span class="line">16/03/10 12:17:56 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">16/03/10 12:17:56 DEBUG util.Shell: setsid exited with exit code 0</span><br><span class="line">Native library checking:</span><br><span class="line">hadoop:  false</span><br><span class="line">zlib:    false</span><br><span class="line">snappy:  false</span><br><span class="line">lz4:     false</span><br><span class="line">bzip2:   false</span><br><span class="line">openssl: false</span><br><span class="line">16/03/10 12:17:56 INFO util.ExitUtil: Exiting with status 1</span><br></pre></td></tr></table></figure>
<p>发现<code>/lib64/libc.so.6: version</code>GLIBC_2.14’ not found`信息，说明该版本的Hadoop需要glibc_2.14版本。下面就安装所需的版本。</p>
<ol>
<li><code>mkdir glib_build &amp;&amp; cd glib_build</code></li>
<li><code>wget http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.gz &amp;&amp; wget http://ftp.gnu.org/gnu/glibc/glibc-linuxthreads-2.5.tar.bz2</code></li>
<li><code>tar zxf glibc-2.14.tar.gz &amp;&amp; cd glibc-2.14 &amp;&amp; tar jxf ../glibc-linuxthreads-2.5.tar.bz2</code></li>
<li><code>cd ../ &amp;&amp; export CFLAGS=&quot;-g -O2&quot; &amp;&amp; ./glibc-2.14/configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin</code></li>
<li><code>make</code></li>
<li><code>make install</code><br>install最后会遇到错误信息：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">CC=&quot;gcc -B/usr/bin/&quot; /usr/bin/perl scripts/test-installation.pl /root/</span><br><span class="line">/usr/bin/ld: cannot find -lnss_test1</span><br><span class="line">collect2: ld returned 1 exit status</span><br><span class="line">Execution of gcc -B/usr/bin/ failed!</span><br><span class="line">The script has found some problems with your installation!</span><br><span class="line">Please read the FAQ and the README file and check the following:</span><br><span class="line">- Did you change the gcc specs file (necessary after upgrading from</span><br><span class="line">  Linux libc5)?</span><br><span class="line">- Are there any symbolic links of the form libXXX.so to old libraries?</span><br><span class="line">  Links like libm.so -&gt; libm.so.5 (where libm.so.5 is an old library) are wrong,</span><br><span class="line">  libm.so should point to the newly installed glibc file - and there should be</span><br><span class="line">  only one such link (check e.g. /lib and /usr/lib)</span><br><span class="line">You should restart this script from your build directory after you&apos;ve</span><br><span class="line">fixed all problems!</span><br><span class="line">Btw. the script doesn&apos;t work if you&apos;re installing GNU libc not as your</span><br><span class="line">primary library!</span><br><span class="line">make[1]: *** [install] Error 1</span><br><span class="line">make[1]: Leaving directory `/root/glibc-2.14&apos;</span><br><span class="line">make: *** [install] Error 2</span><br></pre></td></tr></table></figure>
<p>无需关注，检验是否成功<br><code>ls -l /lib64/libc.so.6</code><br>lrwxrwxrwx 1 root root 12 Mar 10 12:12 /lib64/libc.so.6 -&gt; libc-2.14.so<br>出现了<code>/lib64/libc.so.6 -&gt; libc-2.14.so</code>字样说明成功了。</p>
<p>安装openssl<br><code>yum install openssl-static.x86_64</code></p>
<h1 id="如何修改主机名称"><a href="#如何修改主机名称" class="headerlink" title="如何修改主机名称"></a>如何修改主机名称</h1><p>修改文件<code>/etc/sysconfig/network</code><br>然后执行<code>/etc/rc.d/init.d/network restart</code>重启网络模块</p>
<h1 id="secondaryNameNode-配置"><a href="#secondaryNameNode-配置" class="headerlink" title="secondaryNameNode 配置"></a>secondaryNameNode 配置</h1><ol>
<li>修改masters文件（如果没有则自己创建），添加一个主机名称，用以作为secondaryNameNode。</li>
<li>修改hdfs-site.xml的内容，删除<code>dfs.namenode.secondary.http-address</code>部分配置，添加新的配置（注意修改为自己的ip）：</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.http.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>10.10.1.10:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">		The address and the base port where the dfs namenode web ui will listen on.</span><br><span class="line">		If the port is 0 then the server will start on a free port.</span><br><span class="line">	<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>10.10.1.11<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h6 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h6><ol>
<li><a href="http://blog.csdn.net/tang9140/article/details/42869531" target="_blank" rel="external">Hadoop-2.5.2集群安装配置详解</a></li>
<li><a href="http://blog.csdn.net/zzu09huixu/article/details/36873669" target="_blank" rel="external">基于hadoop2.2的namenode与SecondaryNameNode分开配置在不同的计算机</a></li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Spring-XD简介]]></title>
      <url>http://todu.top/spring/Spring-XD%E7%AE%80%E4%BB%8B/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Spring XD is a unified, distributed, and extensible service for data ingestion, real time analytics, batch processing, and data export.<br><img src="/images/xd/xd-overview.png" alt="distributed-overview."></p>
<h1 id="Streams"><a href="#Streams" class="headerlink" title="Streams"></a>Streams</h1><p>翻译过来就是流，通过定义stream可以控制数据的流向，比如从MongoDB读取数据然后存储到HDFS中。<br><img src="/images/xd/stream.png" alt="stream"></p>
<h2 id="创建方式"><a href="#创建方式" class="headerlink" title="创建方式"></a>创建方式</h2><p>一个简单的示例：该示例创建一个名字叫<code>ticktock</code>的stream，每秒钟产生一条时间信息然后通过管道传送到log中。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xd:&gt; stream create --definition &quot;time | log&quot; --name ticktock</span><br></pre></td></tr></table></figure></p>
<h2 id="销毁Stream"><a href="#销毁Stream" class="headerlink" title="销毁Stream"></a>销毁Stream</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xd:&gt; stream destroy --name stream-name</span><br></pre></td></tr></table></figure>
<h1 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h1><p>模块，当前包含<code>source</code>, <code>sink</code>,<code>processor</code>, 和<code>job</code>。</p>
<h1 id="Souces"><a href="#Souces" class="headerlink" title="Souces"></a>Souces</h1><p>数据源，Stream的来源，有以下几种方式：</p>
<table>
<thead>
<tr>
<th>方式</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>File</td>
<td>文件方式</td>
</tr>
<tr>
<td>FTP</td>
<td>FTP方式</td>
</tr>
<tr>
<td>GemFire Continuous Query(gemfire-cq)</td>
<td>GemFire查询</td>
</tr>
<tr>
<td>GemFire source(gemfire)</td>
<td>GemFire文件</td>
</tr>
<tr>
<td>HTTP</td>
<td>http方式</td>
</tr>
<tr>
<td>JDBC Source(jdbc)</td>
<td>关系型数据库jdbc</td>
</tr>
<tr>
<td>JMS</td>
<td>JMS</td>
</tr>
<tr>
<td>Kafka</td>
<td>Kafka消息队列</td>
</tr>
<tr>
<td>Mail</td>
<td>通过接收电子邮件</td>
</tr>
<tr>
<td>MongoDB Source(mongodb)</td>
<td>MongoDB数据库</td>
</tr>
<tr>
<td>MQTT</td>
<td>MQTT</td>
</tr>
<tr>
<td>RabbitMQ</td>
<td>RabbitMQ消息队列</td>
</tr>
<tr>
<td>Reactor IP(reactor-ip)</td>
<td>Reactor IP(reactor-ip)</td>
</tr>
<tr>
<td>SFTP</td>
<td>SFTP</td>
</tr>
<tr>
<td>Stdout Capture</td>
<td>标准输入</td>
</tr>
<tr>
<td>Syslog</td>
<td>系统日志</td>
</tr>
<tr>
<td>Tail</td>
<td>Tail程序</td>
</tr>
<tr>
<td>TCP</td>
<td>TCP</td>
</tr>
<tr>
<td>TCP Client(tcp-client)</td>
<td>TCP 客户端</td>
</tr>
<tr>
<td>Time</td>
<td>时间</td>
</tr>
<tr>
<td>Trigger Source(trigger)</td>
<td>触发器</td>
</tr>
<tr>
<td>Twitter Search(twittersearch)</td>
<td>Twitter搜索</td>
</tr>
<tr>
<td>Twitter Stream(twitterstream)</td>
<td>Twitter Stream流</td>
</tr>
</tbody>
</table>
<h1 id="Sinks"><a href="#Sinks" class="headerlink" title="Sinks"></a>Sinks</h1><p>数据源，Stream的输出，有以下几种方式：</p>
<table>
<thead>
<tr>
<th>方式</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Dynamic Router(router)</td>
<td>动态路由</td>
</tr>
<tr>
<td>File Sink(file)</td>
<td>文件方式</td>
</tr>
<tr>
<td>FTP Sink(ftp)</td>
<td>FTP方式</td>
</tr>
<tr>
<td>GemFire Server</td>
<td>GemFire服务器</td>
</tr>
<tr>
<td>GPFDIST</td>
<td>GPFDIST</td>
</tr>
<tr>
<td>Cassandra</td>
<td>Cassandra 数据库</td>
</tr>
<tr>
<td>Hadoop(HDFS) (hdfs)</td>
<td>hdfs文件系统</td>
</tr>
<tr>
<td>HDFS Dataset(Avro/Parquet) (hdfs-dataset)</td>
<td>hdfs文件系统中的avro或者parquet类型文件</td>
</tr>
<tr>
<td>JDBC Source(jdbc)</td>
<td>关系型数据库jdbc</td>
</tr>
<tr>
<td>Kafka Sink (kafka)</td>
<td>Kafka消息队列</td>
</tr>
<tr>
<td>Log</td>
<td>log 文件</td>
</tr>
<tr>
<td>Mail</td>
<td>Mail 发送</td>
</tr>
<tr>
<td>Mongo</td>
<td>Mongo数据库</td>
</tr>
<tr>
<td>MQTT Sink (mqtt)</td>
<td>MQTT</td>
</tr>
<tr>
<td>Null Sink(null)</td>
<td>null</td>
</tr>
<tr>
<td>RabbitMQ</td>
<td>RabbitMQ 消息队列</td>
</tr>
<tr>
<td>Redis</td>
<td>Redis</td>
</tr>
<tr>
<td>Shell Sink (shell)</td>
<td>shell</td>
</tr>
<tr>
<td>Splunk Server (splunk)</td>
<td>splunk</td>
</tr>
<tr>
<td>TCP Sink (tcp)</td>
<td>TCP</td>
</tr>
</tbody>
</table>
<h1 id="Processors"><a href="#Processors" class="headerlink" title="Processors"></a>Processors</h1><p>可用的处理器包括<code>Aggregator</code> <code>Filter</code> <code>Header Enricher</code> <code>HTTP Client</code> <code>JSON to Tuple</code> <code>Object to JSON</code> <code>Script</code> <code>Shell Command</code> <code>Splitter</code> <code>Transform</code></p>
<ul>
<li>Aggregator – 作用和 splitter相反，用于聚合，</li>
<li>Splitter – 用于拆解</li>
<li>Filter – 过滤器，用于中间处理数据</li>
<li>Header Enricher (header-enricher) – 用于添加头部信息</li>
<li>HTTP Client – 通过httpClient方式发送URL请求</li>
<li>JSON to Tuple (json-to-tuple) – 转换json数据到Tuple类型</li>
<li>Object to JSON (object-to-json) – 将对象转换为json格式</li>
<li>Script 用于加载Groovy脚本</li>
<li>Shell – 用于加载Shell脚本</li>
<li>Transform – 用于负载类型转换</li>
</ul>
<h1 id="Taps"><a href="#Taps" class="headerlink" title="Taps"></a>Taps</h1><p>监听器，窃听器。<br>不用重复定义相同的stream，然后监听此stream就可以做其他操作。并且可以用Label来分别对每个部分内容做个别名，定义Tab时候可以使用别名。如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stream create foo --definition &quot;httpLabel: http | fLabel: filter --expression=payload.startsWith(&apos;A&apos;) | flibble: transform --expression=payload.toLowerCase() | log&quot; --deploy</span><br><span class="line">stream create fooTap --definition &quot;tap:stream:foo.flibble &gt; log&quot; --deploy</span><br></pre></td></tr></table></figure></p>
<p>上面对trasfrom部分做了一个别名，叫做<code>flibble</code>，然后下面定义一个Tap，并且最后指定是flibble这个标签，那么就是对<code>foo</code>这个stream的<code>flibble</code>做监听。</p>
<h1 id="Jobs"><a href="#Jobs" class="headerlink" title="Jobs"></a>Jobs</h1><p>Job相比Stream不同点在于，Job算是静态的，Stream是动态的。Stream会持续接收数据，处理数据；Job是一次性接收数据，处理数据，如果数据改变，那么是不会进行处理的，除非有定时任务。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">job create --name jobtest --definition &apos;timestampfile --directory=D:/jobs&apos; --deploy</span><br><span class="line">stream create --name time-cron --definition &quot;trigger --cron=&apos;* * * * * *&apos; &gt; queue:job:jobtest&quot; --deploy</span><br></pre></td></tr></table></figure></p>
<h1 id="使用counter"><a href="#使用counter" class="headerlink" title="使用counter"></a>使用counter</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">stream create foo --definition &apos;http --outputType=application/json | log&apos;</span><br><span class="line">stream create countName --definition &apos;tap:stream:foo &gt; field-value-counter --fieldName=name&apos; --deploy</span><br><span class="line">stream deploy --name foo</span><br><span class="line">http post --data &#123;&quot;name&quot;:&quot;a&quot;&#125;</span><br><span class="line">http post --data &#123;&quot;name&quot;:&quot;a&quot;&#125;</span><br><span class="line">http post --data &#123;&quot;name&quot;:&quot;b&quot;&#125;</span><br></pre></td></tr></table></figure>
<p><code>field-value-counter list</code> 列出field-value-counter的名字<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FieldValueCounter name</span><br><span class="line">----------------------</span><br><span class="line">countName</span><br></pre></td></tr></table></figure></p>
<p><code>field-value-counter display --name countName</code> 列出名字为<code>countName</code>的描述</p>
<pre><code>FieldValueCounter=countName
---------------------------  -  -----
VALUE                        -  COUNT
a                            |  2
b                            |  1
</code></pre>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[以分布式方式运行Spring-XD]]></title>
      <url>http://todu.top/spring/%E4%BB%A5%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%B9%E5%BC%8F%E8%BF%90%E8%A1%8CSpring-XD/</url>
      <content type="html"><![CDATA[<p><em>主要以官方文档说明进行配置</em></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Spring XD分布式运行环境（DIRT）支持以分布式方式运行多个跨节点的任务。参见<a href="http://docs.spring.io/spring-xd/docs/1.3.1.RELEASE/reference/html/#getting-started" target="_blank" rel="external">Getting Started</a>获取以单个节点运行方式的信息。</p>
<p>XD的分布式运行架构主要由以下组件构成：</p>
<ul>
<li>Admin 主要用于管理Stream，Job的发布，用户操作，和提供运行时相关的状态，系统统计和分析的REST服务</li>
<li>Container 托管发布的模块（Stream处理任务）和批量任务</li>
<li>ZooKeeper 提供所有XD运行时的信息。追踪Container信息，如：modules，jobs发布情况，steam定义，发布状态等。</li>
<li>Spring Batch Job Repository Database –这个要求要配置一个关系型数据库。XD包含了HSQLDB，但是不推荐用在生产环境中。XD支持任何JDBC型数据库。</li>
<li>A Message Broker –用于数据传输。XD的数据传输模块设计成了插拔式。当前XD版本支持<code>Rabbit MQ</code>和<code>Redis</code>，这两个都支持stream和job过程产生的数据的传输，<code>Kafka</code>仅支持steam产生的数据传输。请注意：job使用Kafka作为数据传输是不稳定的。这个项目必须要配置一个作为数据传输的插件（推荐Redis）。</li>
<li>Analytics Repository – XD目前用Redis作为counters和gauges分析的存储方式。<br>XD的分布式运行环境概览如下：<br><img src="/images/xd/distributed-runtime-overview.png" alt="distributed-runtime-overview"></li>
</ul>
<h1 id="Server-Configuration"><a href="#Server-Configuration" class="headerlink" title="Server Configuration"></a>Server Configuration</h1><p>默认查找<code>$XD_HOME/config/servers.yml</code>文件，作为配置文件。<br>但是可以使用<code>XD_CONFIG_LOCATION</code>环境变量改变配置文件夹，使用<code>XD_CONFIG_NAME</code>改变配置文件位置，如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export XD_CONFIG_LOCATION=file:/xd/config/</span><br><span class="line">export XD_CONFIG_NAME=region1-servers</span><br></pre></td></tr></table></figure></p>
<ul>
<li>注意，<code>XD_CONFIG_LOCATION</code>最后的<code>/</code>是必须的。</li>
</ul>
<h1 id="Database-Configuration"><a href="#Database-Configuration" class="headerlink" title="Database Configuration"></a>Database Configuration</h1><p>MySQL，PostGresql选其中一个配置即可，当然还有Oracle也可以配置，但是在这里没有列出，可以<a href="http://docs.spring.io/spring-xd/docs/1.3.1.RELEASE/reference/html/#_database_configuration" target="_blank" rel="external">]参考官方文档</a><br><code>xd-singlenode</code>模式是使用了一个嵌入式<code>HSQLDB</code>数据库，运行分布式模式的时候，可以使用独立的<code>HSQLDB</code>，但是仅仅推荐在学习和开发的时候使用它，正式环境最好使用其他比如<code>MySQL</code>，<code>Postgres</code>等等数据库。</p>
<ul>
<li>注意：如果在stream模块中使用除了<code>Postgres</code>和<code>HSQLDB</code>数据库，那么需要把对应的驱动放到<code>$XD_HOME/lib</code>目录。<br><code>servers.yml</code>文件中已经注释了一部分jdbc配置信息，可以按需更改。</li>
</ul>
<h2 id="MySQL配置"><a href="#MySQL配置" class="headerlink" title="MySQL配置"></a><code>MySQL</code>配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">    datasource:</span><br><span class="line">    url: jdbc:mysql://yourDBhost:3306/yourDB</span><br><span class="line">    username: yourUsername</span><br><span class="line">    password: yourPassword</span><br><span class="line">    driverClassName: com.mysql.jdbc.Driver</span><br></pre></td></tr></table></figure>
<h2 id="Postgresql配置"><a href="#Postgresql配置" class="headerlink" title="Postgresql配置"></a>Postgresql配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  datasource:</span><br><span class="line">    url: jdbc:postgresql://yourDBhost:5432/yourDB</span><br><span class="line">    username: yourUsername</span><br><span class="line">    password: yourPassword</span><br><span class="line">    driverClassName: org.postgresql.Driver</span><br></pre></td></tr></table></figure>
<h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><p>stream和job的数据传输需要用到（Rabbit MQ也可以）（当用作数据分析时候也需要），这里推荐统一使用redis作为配置，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  redis:</span><br><span class="line">   port: 6379</span><br><span class="line">   host: localhost</span><br><span class="line">   pool:</span><br><span class="line">     maxIdle: 8 # max idle connections in the pool</span><br><span class="line">     minIdle: 0 # min idle connections in the pool</span><br><span class="line">     maxActive: -1 # no limit to the number of active connections</span><br><span class="line">     maxWait: 30000 # time limit to get a connection - only applies if maxActive is finite</span><br></pre></td></tr></table></figure></p>
<h3 id="安装redis"><a href="#安装redis" class="headerlink" title="安装redis"></a>安装redis</h3><p>从<a href="redis.io">官网</a>下载最新的redis，然后解压，进入redis根目录，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd deps</span><br><span class="line">make hiredis jemalloc linenoise lua</span><br><span class="line">cd ..</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></p>
<p>注意：依赖于gcc和make（Ubuntu系列如果没有安装 apt-get install gcc make）</p>
<h1 id="开启页面登录密码保护"><a href="#开启页面登录密码保护" class="headerlink" title="开启页面登录密码保护"></a>开启页面登录密码保护</h1><p>默认ui管理界面是没有安全配置的，不需密码即可访问，为了安全起见，我们可以设置登录用户和密码。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  profiles: admin                                                     (1)</span><br><span class="line">security:</span><br><span class="line">  basic:</span><br><span class="line">    enabled: true                                                     (2)</span><br><span class="line">    realm: SpringXD                                                  </span><br><span class="line">  user:</span><br><span class="line">    name: yourAdminUsername</span><br><span class="line">    password: yourAdminPassword</span><br><span class="line">    role: ADMIN, VIEW, CREATE</span><br></pre></td></tr></table></figure></p>
<p>注意：<code>spring.batch.initializer.enabled</code>默认是true，会使Spring Bath初始化表结构。</p>
<h1 id="启动admin"><a href="#启动admin" class="headerlink" title="启动admin"></a>启动admin</h1><p>admin只会有一个，用来协调container和管理相关stream，job等。<br><code>xd/bin/xd-admin</code></p>
<h1 id="启动container"><a href="#启动container" class="headerlink" title="启动container"></a>启动container</h1><p>container可以启动多个，也就是组成多个节点，由此构成分布式运行环境。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xd/bin/xd-container</span><br></pre></td></tr></table></figure></p>
<h1 id="创建Stream"><a href="#创建Stream" class="headerlink" title="创建Stream"></a>创建Stream</h1><p>进入<code>$XD_HOME/shell/</code>,控制台输入<code>bin/xd-shell</code>，进去xd命令行交互模式，然后输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream create --name foo --definition &apos;time | log&apos; --deploy</span><br></pre></td></tr></table></figure></p>
<p>即可看见admin日志（控制台没关闭的话也可以看到）有时间信息输出。</p>
<p>下面这个stream是从kafka读取信息，然后传输到log里，所以需要配置kafka，请查阅kafka相关资料。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stream create --name kafkaDevice --definition &apos;kafka --outputType=text/plain --zkconnect=10.10.1.20:2181 --topic=kafka_test --offsetStorage=redis | log &apos; --deploy</span><br></pre></td></tr></table></figure>
<h1 id="末"><a href="#末" class="headerlink" title="末"></a>末</h1><p>最后贴出一份比较完整的配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">security:</span><br><span class="line">  basic:</span><br><span class="line">    enabled: true</span><br><span class="line">    realm: SpringXD</span><br><span class="line">  user:</span><br><span class="line">    name: hekr</span><br><span class="line">    password: hekr</span><br><span class="line">    # 必须配置角色才会生效</span><br><span class="line">    role: ADMIN, VIEW, CREATE</span><br><span class="line">spring:</span><br><span class="line">    redis:</span><br><span class="line">       port: 6379</span><br><span class="line">       host: 127.0.0.1</span><br><span class="line">       pool:</span><br><span class="line">          maxIdle: 8 # max idle connections in the pool</span><br><span class="line">          minIdle: 0 # min idle connections in the pool</span><br><span class="line">          maxActive: -1 # no limit to the number of active connections</span><br><span class="line">          maxWait: 30000 # time limit to get a connection - only applies if maxActive is finite</span><br><span class="line">       #sentinel:</span><br><span class="line">       #   master: mymaster</span><br><span class="line">       #   nodes: 127.0.0.1:26379,127.0.0.1:26380,127.0.0.1:26381</span><br><span class="line">    batch:</span><br><span class="line">        isolationLevel: ISOLATION_SERIALIZABLE</span><br><span class="line">        # clobType:</span><br><span class="line">        dbType: MYSQL</span><br><span class="line">        maxVarcharLength: 2500</span><br><span class="line">        tablePrefix: BATCH_</span><br><span class="line">        validateTransactionState: true</span><br><span class="line">        initializer:</span><br><span class="line">          enabled: true</span><br><span class="line">    datasource:</span><br><span class="line">        url: jdbc:mysql://localhost:3306/xd</span><br><span class="line">        username: root</span><br><span class="line">        password: hekr</span><br><span class="line">        driverClassName: com.mysql.jdbc.Driver</span><br><span class="line">        testOnBorrow: true</span><br><span class="line">        validationQuery: select 1</span><br><span class="line">zk:</span><br><span class="line">  namespace: xd</span><br><span class="line">  client:</span><br><span class="line">     connect: 10.10.1.20:2181</span><br><span class="line">     sessionTimeout: 60000</span><br><span class="line">     connectionTimeout: 30000</span><br><span class="line">     initialRetryWait: 1000</span><br><span class="line">     retryMaxAttempts: 3</span><br><span class="line">xd:</span><br><span class="line">    transport: redis</span><br></pre></td></tr></table></figure>
<p>##注意：</p>
<ol>
<li>配置权限后，进入xd-shell会显示<code>server-unknown:&gt;</code>， 需要配置一下admin server才能进入交互</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">admin config server --uri http://服务器地址:端口(默认9393) --username 用户名 --password 密码</span><br></pre></td></tr></table></figure>
<ol>
<li><code>testOnBorrow</code>默认是<code>true</code>，如果配置为true或者没有配置，则需要配置正确的<code>validationQuery</code>，如果配置不正确则会有类似如下异常出现<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not get JDBC Connection; nested exception is java.sql.SQLException: Failed to validate a newly established connection.</span><br></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Jrebel插件配置参数]]></title>
      <url>http://todu.top/java/Jrebel%E6%8F%92%E4%BB%B6%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/</url>
      <content type="html"><![CDATA[<h1 id="JVM-参数"><a href="#JVM-参数" class="headerlink" title="JVM 参数"></a>JVM 参数</h1><p><code>-javaagent:/path/jrebel.jar</code></p>
<h1 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h1><h2 id="Spring-Bean-Core-MVC-Security-Webflow-WS"><a href="#Spring-Bean-Core-MVC-Security-Webflow-WS" class="headerlink" title="Spring Bean/Core/MVC/Security/Webflow/WS"></a>Spring Bean/Core/MVC/Security/Webflow/WS</h2><p><code>-Drebel.spring_plugin=true</code></p>
<h2 id="Spring-Data"><a href="#Spring-Data" class="headerlink" title="Spring Data"></a>Spring Data</h2><p><code>-Drebel.spring_data_plugin=true</code></p>
<h2 id="Struts"><a href="#Struts" class="headerlink" title="Struts"></a>Struts</h2><p><code>-Drebel.struts2_plugin=true</code></p>
<h1 id="Hibernate"><a href="#Hibernate" class="headerlink" title="Hibernate"></a>Hibernate</h1><p><code>-Drebel.hibernate_plugin=true</code></p>
<h1 id="Hibernate-Validator"><a href="#Hibernate-Validator" class="headerlink" title="Hibernate Validator"></a>Hibernate Validator</h1><p><code>-Drebel.hibernate_validator_plugin=true</code></p>
<h1 id="MyBatis"><a href="#MyBatis" class="headerlink" title="MyBatis"></a>MyBatis</h1><p><code>-Drebel.mybatis_plugin=true</code></p>
<h1 id="Logback"><a href="#Logback" class="headerlink" title="Logback"></a>Logback</h1><p><code>-Drebel.logback_plugin=true</code></p>
<h1 id="Log4J-2"><a href="#Log4J-2" class="headerlink" title="Log4J 2"></a>Log4J 2</h1><p><code>-Drebel.log4j2_plugin=true</code></p>
<p>#Groovy<br><code>-Drebel.groovy_plugin=true</code></p>
<h1 id="Jruby"><a href="#Jruby" class="headerlink" title="Jruby"></a>Jruby</h1><p><code>-Drebel.jruby_plugin=true</code></p>
<h1 id="GWT"><a href="#GWT" class="headerlink" title="GWT"></a>GWT</h1><p><code>-Drebel.gwt_plugin=true</code></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://manuals.zeroturnaround.com/jrebel/misc/frameworks.html" target="_blank" rel="external">plugins</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[archlinux安装ntfs驱动]]></title>
      <url>http://todu.top/linux/archlinux%E5%AE%89%E8%A3%85ntfs%E9%A9%B1%E5%8A%A8/</url>
      <content type="html"><![CDATA[<p>默认情况下，archlinux本身支持挂在ntfs文件系统，只不过是只读，不能写入。如果要支持ntfs系统文件，那么需要安装ntfs的驱动程序。<br>用命令 <code>yaourt -Ss ntfs</code> 可以查找关于ntfs的软件包<br>&gt;<br>extra/ntfs-3g 2014.2.15-1 [installed]<br>    NTFS filesystem driver and utilities<br>aur/disk-manager 1.0.1-3 (56)<br>    A tool to manage filesystems, partitions, and NTFS write mode<br>aur/fgetty 0.7-5 (14)<br>    A mingetty stripped of the printfs<br>aur/fgetty-pam 0.7-4 (4)<br>    A mingetty stripped of the printfs, patched for PAM-support.<br>aur/grub4dos 0.4.5c_20140822-1 (35)<br>    A GRUB boot loader support menu on windows(fat,ntfs)/linux(ext2,3,4)<br>aur/libntfs-wii 2013.1.13-1 (1)<br>    NTFS-3G filesystem access library (for Nintendo Gamecube/Wii homebrew<br>    development)<br>aur/ntfs-3g-ar 2014.2.15AR.3-1 (37)<br>    NTFS filesystem driver and utilities with experimental features<br>aur/ntfs-3g-fuse 2014.2.15-1 (46)<br>    Stable read and write NTFS driver and ntfsprogs. This package will allow<br>    normal users to mount NTFS Volumes.<br>aur/ntfs-3g_ntfsprogs-git 4695.db35a16-1 (7)<br>    Read and write NTFS driver and utilities - GIT version<br>aur/ntfs-config 1.0.1-13 (119)<br>    Enable/disable NTFS write support with a simple click<br>aur/ntfsfixboot 1.0-3 (18)<br>    Fix NTFS boot sector<br>aur/scrounge-ntfs 0.9-2 (28)<br>    Data recovery program for NTFS file systems<br>aur/ufsd-module 8.9.0-3 (9)<br>    Paragon NTFS &amp; HFS for Linux driver. - ACLs removed<br>aur/ufsd-module-dkms 8.9.0-3 (4)<br>    Paragon NTFS &amp; HFS for Linux driver. - ACLs removed. DKMS version<br>aur/wipefreespace 2.0-1 (3)<br>    Securely wipe the free space on an ext2/3/4,NTFS, XFS,ReiserFSv3,<br>    ReiserFSv4, FAT12/16/32,Minix,JFS and HFS+ partition or drive</p>
<p>可以看到有这么多相关软件包，其实只需要安装第一个也就是 <code>extra/ntfs-3g</code> 就可以了，输入命令 <code>yaourt -S extra/ntfs-3g</code>，安装完毕后重新插入ntfs分区U盘或者移动硬盘就可以进行写入操作了。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[archlinux安装]]></title>
      <url>http://todu.top/linux/archlinux%E5%AE%89%E8%A3%85/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本人也是第一次安装archlinux，严格来说是第一次安装成功，记录一下，既为自己也为新手。此方式是非UEFI模式，并且分区表使DOS的MBR方式，GPT分区表没有测试。以后也许会在虚拟机中测试过进行补充。</p>
<h1 id="温馨提示"><a href="#温馨提示" class="headerlink" title="温馨提示"></a>温馨提示</h1><p>建议现在虚拟机中安装几次，直到安装成功，并且可以正常开机，上网，打开桌面环境，有十足把握之后再在物理机上安装，以免中间出现问题又没办法解决。并在虚拟机安装的过程中记录遇到的问题，以便日后参考。同时安装的时候记得备份重要文件，以免安装错误导致文件丢失。</p>
<h1 id="准备安装介质"><a href="#准备安装介质" class="headerlink" title="准备安装介质"></a>准备安装介质</h1><ol>
<li>首先准备archlinux镜像，如果没有可以<a href="https://www.archlinux.org/download/" target="_blank" rel="external">点击这里下载</a>，最好选择中国的镜像服务，比如<a href="http://mirrors.163.com/archlinux/iso/2015.01.01/" target="_blank" rel="external">网易的</a>。下载完成后校验一下MD5值（官方文件的MD5值在md5sums.txt 这个文件中），如果相同那么可以进行下一步了；如果不相同需要重新下载并校验，不推荐在MD5值不同的情况下继续进行，因为不知道会发生什么问题。</li>
<li>刻录至U盘。如果用的是linux系统或者Mac系统（话说这么优雅的系统为啥要换呢，也可能是双系统吧），可以使用 <code>dd</code> 命令。把U盘插入计算机， 输入命令 <code>ls -al /dev/sd*</code>, 一般sdb是你的U盘，也请先做好文件备份。 现在假定U盘是 /dev/sdb, archlinux的文件路径是 /home/user/archlinux.iso,那么输入命令(需root权限) <code>dd -if=/home/user/archlinux.iso -of=/dev/sdb</code>，然后等待命令执行完毕，如果没有任何提示，则代表成功了。</li>
</ol>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>   <strong> 再次提醒，做好文件备份 </strong></p>
<ol>
<li>如果没有分区的话，先进行分区，并进行格式化，如果已经操作过了或者想重用上次系统(Linux)的分区，可以直接进入第2步。<ul>
<li>分区进行时：<br>敲入命令 <code>fdisk /dev/sda</code> (假定操作的磁盘时sda，请自行确认好，此操作要格外小心)。输入 <code>m</code> 可以查看帮助， <code>n</code> 是新建一个分区， <code>d</code> 是删除一个已有分区。如果想新建一个DOS分区表，则输入 <code>o</code>，已经有分区表，想重新分区的话，按 <code>d</code> ，直到删除所有分区。分区方案可以按照以下来： <code>/boot</code>  大概需要  <code>200M</code>， <code>/</code> 可以分配 <code>15G</code> ～ <code>40G</code>， <code>/var</code> <code>8G</code>～ <code>20G</code> (可选)  ， <code>/tmp</code> <code>4G</code> ～ <code>8G</code> (可选)，其余分给 <code>/home</code>分区（强烈建议单独分区，以后重装系统可以不用拷贝主目录下的资料了）， <code>swap</code> <code>4G</code> ～ <code>8G</code>（可选）。新建分区输入 <code>n</code>，默认（p主分区）即可，然后默认（分区号1），接下来也是默认扇区既可以，然后选择大小，可以输入G,M,K单位的大小，我们输入 <code>+200M</code>，确定；然后创建根分区，按<code>n</code>,一路下来，大小选择输入 <code>+15G</code>,确定，根分区创建完成。如果分区少于4个，可以按照上面步骤，直到分区创建完成；但是如果分区多于4个，就要创建扩展分区，然后再创建逻辑分区了。扩展分区的创建和上面一样，只不过在选择分区格式的时候不是输入 <code>p</code> 了，而是 <code>e</code>，其余一样的。创建逻辑分区的时候输入 <code>l</code> （英文L的小写字母），剩下的步骤也是和创建主分区一样的啦。所有分区创建完成后，输入 <code>w</code> ，上面的一系列操作才会真正写入磁盘，再次之前都是在内存中，所以，在按 <code>w</code> 之前，还是有后悔药吃的，但是按下之后，那就定格了。切记！</li>
<li>格式化分区：<br>格式化分区的命令是 <code>mkfs.xxx</code>，输入 <code>mkfs.</code>，按 <code>Tab</code> 键可以看到有如下格式：  <code>mkfs.bfs</code>       <code>mkfs.ext2</code>      <code>mkfs.ext4</code>      <code>mkfs.jfs</code>       <code>mkfs.reiserfs</code> <code>mkfs.cramfs</code>    <code>mkfs.ext3</code>      <code>mkfs.ext4dev</code>  <code>mkfs.minix</code>     <code>mkfs.xfs</code>。咦，好像没有swap分区格式，swap分区格式化的命令是 <code>mkswap</code> 啦。输入命令 <code>mkfs.ext4 /dev/sda1</code> 将 <code>/boot</code> 分区格式化成ext4格式的分区，根分区和其他非swap分区用此方法依次格式化，用 <code>mkswap /dev/sdax</code> 格式化上面分的swap分区，x是分swap分区所得的号码。</li>
</ul>
</li>
</ol>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ol>
<li>mount 相关分区。 <code>mkdir /mnt/home /mnt/tmp /mnt/var /mnt/boot</code>  创建home，tmp，var，boot挂载点目录，然后 <code>mount /dev/sdax /mnt/xx</code> x代表分区号，xx代表目录，把的分区挂载到相应挂载点上。</li>
<li><p>修改 <code>/etc/pacman.d/mirrorlist</code> 的镜像列表，可以删除所有的，然后输入<br>&gt;<br>Server = <a href="http://mirrors.163.com/archlinux/$repo/os/x86_64" target="_blank" rel="external">http://mirrors.163.com/archlinux/$repo/os/x86_64</a></p>
<p>   保存退出。</p>
<ol>
<li>执行 <code>pacstrap /mnt base</code> 命令进行基础安装。</li>
<li>生成fstab。 <code>genfstab -p /mnt &gt;&gt; /mnt/etc/fstab</code>, 查看一下/mnt/etc/fstab 内容格式是否正确，有无重复内容，如有请先订正。格式大体如下：<br>&gt;<br>#<br># /etc/fstab: static file system information<br>#<br># <file system="">    <dir>    <type>    <options>    <dump>    <pass><br># UUID=ee8bae58-9428-4917-b63e-0258d19a4567<br>/dev/sda5               /             ext4          rw,relatime,data=ordered0 1<br># UUID=cbac48fe-3345-4cba-96ec-acdbdc56d0ad<br>/dev/sda9               /home         ext4          rw,relatime,data=ordered0 2<br># UUID=59e210c2-fced-4cdd-b631-d9a50ba82312<br>/dev/sda7               /tmp          ext4          rw,relatime,data=ordered0 2</pass></dump></options></type></dir></file></li>
<li>切换到新系统的root目录下，命令  <code>arch-choot /mnt</code></li>
<li>设置主机名 <code>echo your_hostname &gt; /etc/hostname</code> ， your_hostname换成你想要的，最好是纯英文。</li>
<li>设置时区。 <code>ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</code>。</li>
<li>修改 <code>/etc/locale.gen</code> ， 添加以下内容<br>&gt;<br>en_US.UTF-8 UTF-8<br>zh_CN.UTF-8 UTF-8</li>
</ol>
<p>执行 <code>locale-gen</code>，</p>
<ol>
<li>执行 <code>echo LANG=zh_CN.UTF-8 &gt; /etc/locale.conf</code></li>
<li>设置键盘映射和字体，文件在 <code>/etc/vconsole.conf</code>，在这就保持默认配置了。</li>
<li>设置root密码 <code>passwd</code> 然后输入密码，再输入一次确认。</li>
<li>安装引导程序，这里用grub。 <code>pacman -Sy grub</code>，安装完成后，执行  <code>pacman-db-upgrade</code>， 然后再执行 <code>grub-install --target=i386-pc --recheck --debug /dev/sda</code> 安装grub引导到sda上。最后执行 <code>grub-mkconfig -o /boot/grub/grub.cfg</code> ，生成引导配置。</li>
<li>重启， 执行 <code>reboot</code>。如果成功安装的话，会出现grub引导选择系统菜单，选择默认的进入，输入root用户名，输入密码，登录成功。至此，安装已经完成，接下来是配置。</li>
</ol>
</li>
</ol>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><ol>
<li><p>网络配置</p>
<ul>
<li>查看网络设备名称 <code>ls /sys/class/net</code>, 记住所看到的网卡接口名称，假定叫做eth0</li>
<li>启用网络接口 ip link set eth0 up</li>
<li>检查结果状态 <code>ip link show dev eth0</code> 如果打印<br>&gt;<br>enp3s0: <broadcast,multicast,up,lower_up> mtu 1500 qdisc fq_codel state UP mode DEFAULT    group default qlen 1000<br>link/ether 00:e0:66:cb:e2:1e brd ff:ff:ff:ff:ff:ff</broadcast,multicast,up,lower_up></li>
</ul>
<p>类似内容，说明启用成功。</p>
</li>
<li>创建或编辑 <code>/etc/systemd/network/dhcp.network</code> ,添加以下内容：<br>&gt;<br>[Match]<br>Name=en*<br>[Network]<br>DHCP=v4</li>
</ol>
<ol>
<li>启用网络服务 <code>systemctl enable systemd-resolved</code></li>
<li><p>编辑 <code>/etc/resolv.conf</code> 配置dns ， 添加以下内容：<br>&gt;<br>nameserver 8.8.8.8<br>nameserver 4.4.4.4</p>
<p>如果你的IP段在192.168.xxx.yyy,则再添加 nameserver 192.168.xxx.1</p>
</li>
<li><p>执行 <code>dhcpd</code> 启用dhcp，要开机自动启动dhcp服务，则执行 <code>systemctl enable dhcpd</code><br>基本环境配置已经完成。</p>
</li>
</ol>
<h1 id="桌面环境配置"><a href="#桌面环境配置" class="headerlink" title="桌面环境配置"></a>桌面环境配置</h1><p>安装 fxce4</p>
<p>pacman -S xorg xorg-server<br>pacman -S slim #登录管理器<br>pacman -S xfce4<br>pacman -S xfce4-goodies<br>pacman -S fortune-mode<br>pacman -S gamin</p>
<ol>
<li>创建用户 <code>useradd -Um du</code></li>
<li>设置密码 <code>passwd du</code></li>
<li>切换用户  <code>su -l du</code></li>
<li>输入 <code>startxfce4</code> 可以进入xfce桌面了</li>
</ol>
<h1 id="美化显示："><a href="#美化显示：" class="headerlink" title="美化显示："></a>美化显示：</h1><ul>
<li><p>字体</p>
<ol>
<li>首先可以从windowns上或者其他地方准备字体文件，然后 <code>cp *.ttf ~/.fonts/</code></li>
<li>建立字体缓存<br><code>mkfontscale</code><br><code>mkfontdir</code><br><code>fc-cache -fv</code></li>
</ol>
</li>
<li><p>输入法 <a href="https://wiki.archlinux.org/index.php/Fcitx_%28%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87%29#.E8.BE.93.E5.85.A5.E6.B3.95.E6.A8.A1.E5.9D.97" target="_blank" rel="external">传送门</a><br>输入法就安装fcitx小企鹅输入法了</p>
<ol>
<li><p>安装输入法</p>
<p> <code>pacman -S fcitx</code>  </p>
</li>
<li>配置输入法<br> 安装输入法其他模块<br> <code>fcitx-ui-light</code> Fcitx 的轻量 UI.<br><code>fcitx-fbterm</code> Fbterm 对 Fcitx 的支持。<br><code>fcitx-table-extra</code> Fcitx 的一些额外码表支持，包括仓颉 3, 仓颉 5, 粤拼, 速成, 五笔, 郑码等等<br><code>fcitx-table-other</code> Fcitx 的一些更奇怪的码表支持，包括 Latex, Emoji, 以及一大堆不明字符等等。<br><code>kcm-fcitx</code> KDE 的 Fcitx 输入法模块</li>
<li>启动桌面环境时候启用输入法<br> 在 .bashrc 文件中加入如下代码<br> &gt;<br>export GTK_IM_MODULE=fcitx<br>export QT_IM_MODULE=fcitx<br>export XMODIFIERS=”@im=fcitx”</li>
</ol>
<p>退出用户，重新登陆，可以欢快的使用输入法了。</p>
</li>
</ul>
<p>ps:<br>浙大源：<code>Server = http://mirrors.zju.edu.cn/archlinux/$repo/os/$arch</code><br>网易源：<code>Server = http://mirrors.163.com/archlinux/$repo/os/x86_64</code><br>北京交大：<code>Server = http://mirror.bjtu.edu.cn/ArchLinux/$repo/os/x86_64</code></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[sql查找排除某些表后不存在某个字段的表]]></title>
      <url>http://todu.top/sql/sql%E6%9F%A5%E6%89%BE%E6%8E%92%E9%99%A4%E6%9F%90%E4%BA%9B%E8%A1%A8%E5%90%8E%E4%B8%8D%E5%AD%98%E5%9C%A8%E6%9F%90%E4%B8%AA%E5%AD%97%E6%AE%B5%E7%9A%84%E8%A1%A8/</url>
      <content type="html"><![CDATA[<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> table_name <span class="keyword">FROM</span> information_schema.<span class="keyword">tables</span></span><br><span class="line"><span class="keyword">WHERE</span> table_schema=<span class="string">'database_name'</span></span><br><span class="line">	<span class="keyword">AND</span> table_name <span class="keyword">NOT</span> <span class="keyword">LIKE</span> <span class="string">'table_name'</span></span><br><span class="line">	<span class="keyword">AND</span> table_name <span class="keyword">NOT</span> <span class="keyword">IN</span>(<span class="keyword">SELECT</span> <span class="keyword">col</span>.table_name  <span class="keyword">FROM</span> information_schema.<span class="string">`COLUMNS`</span> <span class="keyword">col</span></span><br><span class="line">	       <span class="keyword">WHERE</span> <span class="keyword">col</span>.table_name <span class="keyword">IN</span> (<span class="keyword">SELECT</span> table_name <span class="keyword">FROM</span> information_schema.<span class="keyword">tables</span></span><br><span class="line">					<span class="keyword">WHERE</span> table_schema=<span class="string">'database_name'</span></span><br><span class="line">					<span class="keyword">AND</span> table_name <span class="keyword">NOT</span> <span class="keyword">LIKE</span> <span class="string">'table_name'</span></span><br><span class="line">					<span class="keyword">AND</span> <span class="keyword">col</span>.column_name=<span class="string">'gmt_modified'</span>);</span><br></pre></td></tr></table></figure>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[MySql避免重复插入记录]]></title>
      <url>http://todu.top/sql/MySql%E9%81%BF%E5%85%8D%E9%87%8D%E5%A4%8D%E6%8F%92%E5%85%A5%E8%AE%B0%E5%BD%95/</url>
      <content type="html"><![CDATA[<h1 id="方案一：使用ignore关键字"><a href="#方案一：使用ignore关键字" class="headerlink" title="方案一：使用ignore关键字"></a>方案一：使用ignore关键字</h1><p>如果是用主键primary或者唯一索引unique区分了记录的唯一性,避免重复插入记录可以使用：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">ignore</span> <span class="keyword">into</span> table_name(email,phone,user_id) <span class="keyword">values</span>(<span class="string">'test9@163.com'</span>,<span class="string">'99999'</span>,<span class="string">'9999'</span>)</span><br></pre></td></tr></table></figure></p>
<p>这样当有重复记录就会忽略,执行后返回数字0,还有个应用就是复制表,避免重复记录：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">ignore</span> <span class="keyword">into</span> <span class="keyword">table</span>(<span class="keyword">name</span>)  <span class="keyword">select</span>  <span class="keyword">name</span> <span class="keyword">from</span> table2</span><br></pre></td></tr></table></figure></p>
<h1 id="方案二：使用Replace"><a href="#方案二：使用Replace" class="headerlink" title="方案二：使用Replace"></a>方案二：使用Replace</h1><p>replace的语法格式为：</p>
<ol>
<li><code>replace into table_name(col_name, ...) values(...)</code></li>
<li><code>replace into table_name(col_name, ...) select ...</code></li>
<li><code>replace into table_name set col_name=value, ...</code></li>
</ol>
<h2 id="算法说明："><a href="#算法说明：" class="headerlink" title="算法说明："></a>算法说明：</h2><p>REPLACE的运行与INSERT很相像,但是如果旧记录与新记录有相同的值，则在新记录被插入之前，旧记录被删除，即：</p>
<ol>
<li>尝试把新行插入到表中</li>
<li>当因为对于主键或唯一关键字出现重复关键字错误而造成插入失败时：<ul>
<li>从表中删除含有重复关键字值的冲突行</li>
<li>再次尝试把新行插入到表中<br>旧记录与新记录有相同的值的判断标准就是：表有一个PRIMARY KEY或UNIQUE索引，否则，使用一个REPLACE语句没有意义。该语句会与INSERT相同，因为没有索引被用于确定是否新行复制了其它的行。<h2 id="返回值："><a href="#返回值：" class="headerlink" title="返回值："></a>返回值：</h2>REPLACE语句会返回一个数，来指示受影响的行的数目。该数是被删除和被插入的行数的和。受影响的行数可以容易地确定是否REPLACE只添加了一行，或者是否REPLACE也替换了其它行：检查该数是否为1（添加）或更大（替换）。<h2 id="示例"><a href="#示例" class="headerlink" title="示例:"></a>示例:</h2>eg:(phone字段为唯一索引)<br><code>replace  into table_name(email,phone,user_id) values(&#39;test569&#39;,&#39;99999&#39;,&#39;123&#39;)</code><br>另外：在 SQL Server 中可以这样处理：<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if not exists (<span class="keyword">select</span> phone <span class="keyword">from</span> t <span class="keyword">where</span> phone= <span class="string">'1'</span>)  </span><br><span class="line">    <span class="keyword">insert</span> <span class="keyword">into</span> t(phone, update_time) <span class="keyword">values</span>(<span class="string">'1'</span>, <span class="keyword">getdate</span>())</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">update</span> t <span class="keyword">set</span> update_time = <span class="keyword">getdate</span>() <span class="keyword">where</span> phone= <span class="string">'1'</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
<p>更多信息<a href="http://dev.mysql.com/doc/refman/5.1/zh/sql-syntax.html#replace" target="_blank" rel="external">请看</a></p>
<h1 id="方案三：ON-DUPLICATE-KEY-UPDATE"><a href="#方案三：ON-DUPLICATE-KEY-UPDATE" class="headerlink" title="方案三：ON DUPLICATE KEY UPDATE"></a>方案三：ON DUPLICATE KEY UPDATE</h1><p>如‍上所写，你也可以在<code>INSERT INTO.....</code>后面加上 <code>ON DUPLICATE KEY UPDATE</code>方法来实现。如果您指定了<code>ON DUPLICATE KEY UPDATE</code>，并且插入行后会导致在一个UNIQUE索引或PRIMARY KEY中出现重复值，则执行旧行UPDATE。例如，如果列a被定义为UNIQUE，并且包含值1，则以下两个语句具有相同的效果：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">table</span> (a,b,c) <span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>) <span class="keyword">ON</span> <span class="keyword">DUPLICATE</span> <span class="keyword">KEY</span> <span class="keyword">UPDATE</span> c=c+<span class="number">1</span>; `</span><br><span class="line"><span class="keyword">UPDATE</span> <span class="keyword">table</span> <span class="keyword">SET</span> c=c+<span class="number">1</span> <span class="keyword">WHERE</span> a=<span class="number">1</span>;</span><br></pre></td></tr></table></figure></p>
<p>如果行作为新记录被插入，则受影响行的值为1；如果原有的记录被更新，则受影响行的值为2。注释：如果列b也是唯一列，则INSERT与此UPDATE语句相当：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> <span class="keyword">table</span> <span class="keyword">SET</span> c=c+<span class="number">1</span></span><br><span class="line"><span class="keyword">WHERE</span> a=<span class="number">1</span> <span class="keyword">OR</span> b=<span class="number">2</span> <span class="keyword">LIMIT</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure></p>
<p>如果a=1 OR b=2与多个行向匹配，则只有一个行被更新。通常，您应该尽量避免对带有多个唯一关键字的表使用ON DUPLICATE KEY子句。<br>您可以在UPDATE子句中使用VALUES(col_name)函数从INSERT…UPDATE语句的INSERT部分引用列值。换句话说，如果没有发生重复关键字冲突，则UPDATE子句中的VALUES(col_name)可以引用被插入的col_name的值。本函数特别适用于多行插入。VALUES()函数只在INSERT…UPDATE语句中有意义，其它时候会返回NULL。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">table</span> (a,b,c) <span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>)    </span><br><span class="line"><span class="keyword">ON</span> <span class="keyword">DUPLICATE</span> <span class="keyword">KEY</span> <span class="keyword">UPDATE</span> c=<span class="keyword">VALUES</span>(a)+<span class="keyword">VALUES</span>(b);</span><br></pre></td></tr></table></figure></p>
<p>本语句与以下两个语句作用相同：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">table</span> (a,b,c) <span class="keyword">VALUES</span> (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)  <span class="keyword">ON</span> <span class="keyword">DUPLICATE</span> <span class="keyword">KEY</span> <span class="keyword">UPDATE</span> c=<span class="number">3</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">table</span> (a,b,c) <span class="keyword">VALUES</span> (<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>)  <span class="keyword">ON</span> <span class="keyword">DUPLICATE</span> <span class="keyword">KEY</span> <span class="keyword">UPDATE</span> c=<span class="number">9</span>;</span><br></pre></td></tr></table></figure></p>
<p>当您使用<code>ON DUPLICATE KEY UPDATE</code>时，<code>DELAYED</code>选项被忽略。<br>注：<a href="http://www.cnblogs.com/zeroone/archive/2012/04/18/2454728.html" target="_blank" rel="external">来源</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[特定国家版windows8]]></title>
      <url>http://todu.top/hack/%E7%89%B9%E5%AE%9A%E5%9B%BD%E5%AE%B6%E7%89%88windows8/</url>
      <content type="html"><![CDATA[<p>有强迫症的同学真是伤不起，他们就认定只有OEM厂商预装的系统才是正版的，其他通过密钥激活、kms激活的系统就是盗版的，为了满足这些同学的强迫症，笔者搜罗了半天网络资源，终于将OEM厂商使用的预装系统镜像收集完毕，他们分别是特定国家版（CoreCountrySpecific）和单语言版（CoreSingleLanguage），在大多华硕笔记本、联想笔记本中预装的系统通常显示为win8/8.1中文版，其实这些版本的实质就是特定国家版，今天给大家讲解一下他们与其他系统版本的区别以及分享一下他们的下载地址和有效安装密钥。</p>
<p>如何查看你预装的系统版本具体是什么？</p>
<p>win8/8.1中文版，可以通过注册表查看系统的具体版本，打开注册表定位到HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion，然后在右边找到EditionID和ProductName项，如果EditionID处显示为CoreCountrySpecific，ProductName处显示为Windows 8/8.1 China，那么就说明你预装的系统为特定国家版，如果EditionID处显示为CoreSingleLanguage，那么说明你预装的系统为单语言版，目前国内OEM厂商使用的基本就是这两种系统了。</p>
<p>特定国家版、单语言版与其他版本的区别是什么？</p>
<p>一般预装系统显示为win8/8.1中文版的大多都是特定国家版（CoreCountrySpecific），细心的同学可能会发现不管特定国家版还是单语言版，他们的英文名字都带一个“Core”，Core是什么呢？大家都知道win8/8.1分为核心板、专业版、企业版，那么Core就是核心板，这说明特定国家版和单语言版的实质就是核心板，他们与核心版的不同之处：特定国家使用，并且无法更换系统语言，比如是中文版，无法通过语言包或语言设置更换成其他版本，另外他们的密钥也不通用。（本文由 亦是美网络 yishimei.cn 原创）</p>
<p>为什么有些同学哭死哭活的要安装win8/8.1预装系统版本？</p>
<p>OEM厂商在电脑出厂时就将密钥集成在主板里了，如果使用预装系统的版本，在安装成功后，输入OEM集成在主板里的密钥就可以直接联网激活了，那些同学心目中的“正版概念”就是这么来的。</p>
<p>win8.1 CoreCountrySpecific（特定国家版）下载地址：</p>
<p>32位系统：<a href="http://pan.baidu.com/s/1dDCNHdR" target="_blank" rel="external">http://pan.baidu.com/s/1dDCNHdR</a></p>
<p>64位系统：<a href="http://pan.baidu.com/s/1c05ym0w" target="_blank" rel="external">http://pan.baidu.com/s/1c05ym0w</a></p>
<p>安装密钥：TNH8J-KG84C-TRMG4-FFD7J-VH4WX</p>
<p>激活方法：</p>
<p>1、使用安装密钥安装完成后，参考<a href="http://www.yishimei.cn/network/374.html" target="_blank" rel="external">（oem预装系统主板密钥提取神器 - RW - Read &amp; Write utility ）</a>获取系统集成的密钥，然后在线联网激活。</p>
<p>2、下载kms神龙版激活<a href="http://www.yishimei.cn/network/319.html" target="_blank" rel="external">（KMS在线激活windows8/8.1、windows7和office2013/2010之MicroKMS 神龙版）</a>。</p>
<p>win8.1 CoreSingleLanguage（单语言版）下载地址：</p>
<p>32位系统：<a href="http://pan.baidu.com/s/1bn3ytzx" target="_blank" rel="external">http://pan.baidu.com/s/1bn3ytzx</a></p>
<p>64位系统：<a href="http://pan.baidu.com/s/1hqGLrRA" target="_blank" rel="external">http://pan.baidu.com/s/1hqGLrRA</a></p>
<p>安装密钥：Y9NXP-XT8MV-PT9TG-97CT3-9D6TC</p>
<p>激活方法：同win8.1 CoreCountrySpecific（特定国家版）。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Spark基础知识]]></title>
      <url>http://todu.top/spark/Spark%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
      <content type="html"><![CDATA[<h1 id="Spark基本概念"><a href="#Spark基本概念" class="headerlink" title="Spark基本概念"></a>Spark基本概念</h1><ul>
<li>RDD——Resillient Distributed Dataset A Fault-Tolerant Abstraction for In-Memory Cluster Computing弹性分布式数据集。</li>
<li>Operation——作用于RDD的各种操作分为transformation和action。</li>
<li>Job——作业，一个JOB包含多个RDD及作用于相应RDD上的各种operation。</li>
<li>Stage——一个作业分为多个阶段。</li>
<li>Partition——数据分区， 一个RDD中的数据可以分成多个不同的区。</li>
<li>DAG——Directed Acycle graph，有向无环图，反应RDD之间的依赖关系。</li>
<li>Narrow dependency——窄依赖，子RDD依赖于父RDD中固定的data partition。</li>
<li>Wide Dependency——宽依赖，子RDD对父RDD中的所有data partition都有依赖。</li>
<li>Caching Managenment——缓存管理，对RDD的中间计算结果进行缓存管理以加快整 体的处理速度。</li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[运行第一个SparkStreaming程序（及过程中问题解决）]]></title>
      <url>http://todu.top/spark/SparkStreaming%E7%A8%8B%E5%BA%8F%EF%BC%88%E5%8F%8A%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%EF%BC%89/</url>
      <content type="html"><![CDATA[<h1 id="官方示例说明"><a href="#官方示例说明" class="headerlink" title="官方示例说明"></a>官方示例说明</h1><p>按照官方文档的 <a href="http://spark.apache.org/docs/1.0.0/streaming-programming-guide.html#a-quick-example" target="_blank" rel="external">这个示例说明</a>，可以轻松的在本地的spark-shell环境中测试这个示例。示例，即为了更好的入门，那么就再说明一下。<br>运行这个统计单词的方式有三种，前面两种是官方文档上的指引，第三种则是用scala程序运行。</p>
<hr>
<ul>
<li><h2 id="第一种方式-run-demo"><a href="#第一种方式-run-demo" class="headerlink" title="第一种方式, run-demo"></a>第一种方式, run-demo</h2></li>
</ul>
<ol>
<li>打开一个终端，打开一个终端，输入 命令 <code>nc -lk 9999</code>，暂时叫做 “nc终端” 吧</li>
<li><p>再打开终端，切换到Spark HOME目录， 执行命令 <code>bin/run-example org.apache.spark.examples.streaming.NetworkWordCount localhost 9999</code>， 然后每秒会有类似一下日志循环输出<br>&gt;<br>-——————————————<br>Time: 1415701382000 ms<br>-——————————————<br>-——————————————<br>Time: 1415701383000 ms<br>-——————————————</p>
</li>
<li><p>在nc终端随便输入一些字符串，用空格隔开，回车，如aa aa bb c。可以在上面的Spark终端中看到有新内容输出<br>&gt;<br>-——————————————<br>Time: 1415701670000 ms<br>-——————————————<br>(aa,2)<br>(bb,1)<br>(c,1)</p>
</li>
</ol>
<p>OK，成功！</p>
<hr>
<ul>
<li><h2 id="第二种-spark-shell-模式"><a href="#第二种-spark-shell-模式" class="headerlink" title="第二种 spark-shell 模式"></a>第二种 spark-shell 模式</h2>下面介绍在spark-shell中输入scala代码运行的方式。</li>
</ul>
<ol>
<li>同上面第一步，打开一个终端，打开一个终端，输入 命令 <code>nc -lk 9999</code>，暂时叫做 “nc终端” 吧</li>
<li><p>再打开一个终端， 切换到Spark HOME目录下，输入 <code>bin/spark-shell</code> （如果你已经安装好了Spark的话，直接输入 <code>spark-shell</code> 即可），等待Spark启动成功，会打印信息<br>&gt;<br>Spark context available as sc.<br>scala&gt;</p>
<p>然后输入以下语句：</p>
</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.streaming._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.<span class="type">StreamingContext</span>._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.api._</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create a StreamingContext with a local master</span></span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc, <span class="type">Seconds</span>(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create a DStream that will connect to serverIP:serverPort, like localhost:9999</span></span><br><span class="line"><span class="keyword">val</span> lines = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Split each line into words</span></span><br><span class="line"><span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.<span class="type">StreamingContext</span>._</span><br><span class="line"></span><br><span class="line"><span class="comment">// Count each word in each batch</span></span><br><span class="line"><span class="keyword">val</span> pairs = words.map(word =&gt; (word, <span class="number">1</span>))</span><br><span class="line"><span class="keyword">val</span> wordCounts = pairs.reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Print a few of the counts to the console</span></span><br><span class="line">wordCounts.print()</span><br><span class="line">ssc.start()             <span class="comment">// Start the computation</span></span><br><span class="line">ssc.awaitTermination()  <span class="comment">// Wait for the computation to terminate</span></span><br></pre></td></tr></table></figure>
<p> 会打印以下信息：<br>&gt;<br>14/11/11 18:07:23 INFO MemoryStore: ensureFreeSpace(2216) called with curMem=100936, maxMem=278019440<br>.…..<br>14/11/11 18:07:23 INFO DAGScheduler: Stage 91 (take at DStream.scala:608) finished in 0.004 s<br>14/11/11 18:07:23 INFO SparkContext: Job finished: take at DStream.scala:608, took 0.007531701 s<br> -——————————————<br>Time: 1415700443000 ms<br>-——————————————</p>
<ol>
<li><p>同第一种方式的第3步，随便输入一些字符串，用空格隔开，回车，如aa aa bb c。可以在上面的Spark终端中看到有新内容输出<br>&gt;<br>-——————————————<br>Time: 1415701670000 ms<br>-——————————————<br>(aa,2)<br>(bb,1)<br>(c,1)</p>
<p>OK，成功！</p>
</li>
</ol>
<hr>
<ul>
<li><h2 id="第三种-scala-ide编程方式"><a href="#第三种-scala-ide编程方式" class="headerlink" title="第三种 scala-ide编程方式"></a>第三种 scala-ide编程方式</h2>在用这种方式运行这个demo代码的时候，遇到了不少问题，记录下来，供大家参考。这个例子，请大家先根据这里记录的方式进行操作，得到一个可以运行的程序，后面我会记录遇到的问题。</li>
</ul>
<ol>
<li>下载scala-ide, <a href="http://scala-ide.org/download/sdk.html" target="_blank" rel="external">下载链接</a>，下载 For Scala 2.10.4 下的对应平台的ide，解压，运行。</li>
<li>安装sbt，<a href="http://www.scala-sbt.org/download.html" target="_blank" rel="external">下载链接</a>,</li>
<li>安装sbteclipse, <a href="https://github.com/typesafehub/sbteclipse" target="_blank" rel="external">github地址</a>, 编辑 <code>~/.sbt/0.13/plugins/plugins.sbt</code> 文件， 添加以下内容 <code>addSbtPlugin(&quot;com.typesafe.sbteclipse&quot; % &quot;sbteclipse-plugin&quot; % &quot;2.5.0&quot;)</code>，如果没有plugins目录和plugins.sbt，自行创建。</li>
<li><p>用向导创建一个scala项目，并在项目根目录下创建一个build.sbt文件，添加以下内容(注意，每行正式语句之后要换行)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">name := &quot;spark-test&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">version := &quot;1.0&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">scalaVersion := &quot;2.10.4&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// set the main class for the main &apos;run&apos; task</span><br><span class="line">// change Compile to Test to set it for &apos;test:run&apos;</span><br><span class="line">mainClass in (Compile, run) := Some(&quot;test.SparkTest&quot;)</span><br><span class="line"></span><br><span class="line">libraryDependencies += &quot;org.apache.spark&quot; % &quot;spark-streaming_2.10&quot; % &quot;1.1.0&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建test.SparkTest.scala文件，添加以下代码</p>
</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> test</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.<span class="type">StreamingContext</span>._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.api.java.function._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.api._</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// Create a StreamingContext with a local master</span></span><br><span class="line">    <span class="comment">// Spark Streaming needs at least two working thread</span></span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(<span class="string">"local[2]"</span>, <span class="string">"NetworkWordCount"</span>, <span class="type">Seconds</span>(<span class="number">10</span>))</span><br><span class="line">    <span class="comment">// Create a DStream that will connect to serverIP:serverPort, like localhost:9999</span></span><br><span class="line">    <span class="keyword">val</span> lines = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line">    <span class="comment">// Split each line into words</span></span><br><span class="line">    <span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">    <span class="comment">// Count each word in each batch</span></span><br><span class="line">    <span class="keyword">val</span> pairs = words.map(word =&gt; (word, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">val</span> wordCounts = pairs.reduceByKey(_ + _)</span><br><span class="line">    wordCounts.print</span><br><span class="line">    ssc.start</span><br><span class="line">    ssc.awaitTermination</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>终端中切换目录到这个项目根目录，输入命令 <code>sbt</code> ， 命令运行成功后，敲入 <code>eclipse</code> 生成eclipse项目和项目所需依赖</li>
<li>同第一种方式的第1,3步，<br>再打开一个终端，输入 命令 <code>nc -lk 9999</code>。<br>然后运行刚才写的main程序，在nc终端中输入一些字符串，用空格隔开，回车，如aa aa bb c。可以在ide控制台中观察到<br>&gt;<br>-——————————————<br>Time: 1415701670000 ms<br>-——————————————<br>(aa,2)<br>(bb,1)<br>(c,1)</li>
</ol>
<p>OK，成功！</p>
<hr>
<h1 id="下面是遇到的问题及解决方法："><a href="#下面是遇到的问题及解决方法：" class="headerlink" title="下面是遇到的问题及解决方法："></a>下面是遇到的问题及解决方法：</h1><h3 id="1-运行程序说找不到主类"><a href="#1-运行程序说找不到主类" class="headerlink" title="1. 运行程序说找不到主类"></a>1. 运行程序说找不到主类</h3><p>解：没有在sbt文件配置主类是哪个，在<code>build.sbt</code>  文件中添加以下代码</p>
<blockquote>
<p>mainClass in (Compile, run) := Some(“test.SparkTest”)</p>
</blockquote>
<p> Some中就是主类的路径</p>
<h3 id="2-java-lang-NoClassDefFoundError-scala-collection-GenTraversableOnce-class"><a href="#2-java-lang-NoClassDefFoundError-scala-collection-GenTraversableOnce-class" class="headerlink" title="2. java.lang.NoClassDefFoundError: scala/collection/GenTraversableOnce$class"></a>2. java.lang.NoClassDefFoundError: scala/collection/GenTraversableOnce$class</h3><p>这个问题困扰了我很长时间，一直没找到怎么解决。后来看到说是scala每次版本升级不兼容以前的版本编译的库，于是换了对应的版本的ide才正常运行。<br>解：scala-ide版本和现在用的spark包依赖编译的scala版本不一致， 请下载上面说过的 <code>scala-ide For Scala 2.10.4</code> 版本。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[SparkStreaming+Zookeeper+Kafka入门程序]]></title>
      <url>http://todu.top/spark/SparkStreaming+Zookeeper+Kafka%E5%85%A5%E9%97%A8%E7%A8%8B%E5%BA%8F/</url>
      <content type="html"><![CDATA[<h2 id="准备工作："><a href="#准备工作：" class="headerlink" title="准备工作："></a>准备工作：</h2><ul>
<li>安装 <a href="http://spark.apache.org/" target="_blank" rel="external">spark</a></li>
<li>安装 <a href="http://zookeeper.apache.org/" target="_blank" rel="external">zookeeper</a></li>
<li>安装 <a href="http://kafka.apache.org/" target="_blank" rel="external">kafka</a></li>
</ul>
<h2 id="开始工作"><a href="#开始工作" class="headerlink" title="开始工作"></a>开始工作</h2><h4 id="1-启动zookeeper"><a href="#1-启动zookeeper" class="headerlink" title="1. 启动zookeeper"></a>1. 启动zookeeper</h4><p> 打开终端，切换到 <code>zookeeper HOME</code> 目录， 进入conf文件夹，拷贝一份 <code>zoo_sample.cfg</code> 副本并重命名为 <code>zoo.cfg</code><br> 切换到上级的bin目录中，执行 <code>./zkServer.sh start</code> 启动zookeeper，会有日志打印</p>
<blockquote>
<p>Starting zookeeper … STARTED</p>
</blockquote>
<p> 然后用 <code>./zkServer.sh status</code> 查看状态，如果有下列信息输出，则说明启动成功</p>
<blockquote>
<p>Mode: standalone</p>
</blockquote>
<p> 如果要停止zookeeper，则运行 <code>./zkServer stop</code> 即可</p>
<h4 id="2-启动kafka"><a href="#2-启动kafka" class="headerlink" title="2. 启动kafka"></a>2. 启动kafka</h4><p>打开终端，切换到 <code>kafka HOME</code> 目录,运行 <code>bin/kafka-server-start.sh config/server.properties</code> 会有以下类似日志输出<br>  &gt;<br>[2014-11-12 17:38:13,395] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [test,0] (kafka.server.ReplicaFetcherManager)<br>[2014-11-12 17:38:13,420] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions [test,0] (kafka.server.ReplicaFetcherManager)</p>
<h4 id="3-启动kafka生产者"><a href="#3-启动kafka生产者" class="headerlink" title="3. 启动kafka生产者"></a>3. 启动kafka生产者</h4><p>重新打开一个终端，暂叫做 生产者终端，方便后面引用说明。切换到 <code>kafka HOME</code> 目录,运行 <code>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test</code> 创建一个叫 <code>test</code> 的主题。</p>
<h4 id="4-编写scala应用程序"><a href="#4-编写scala应用程序" class="headerlink" title="4. 编写scala应用程序"></a>4. 编写scala应用程序</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">    <span class="keyword">package</span> test</span><br><span class="line">    <span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line">    <span class="keyword">import</span> kafka.producer._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.streaming._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.streaming.<span class="type">StreamingContext</span>._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.streaming.kafka._</span><br><span class="line">    <span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">object</span> <span class="title">KafkaWordCount</span> </span>&#123;</span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="comment">//    if (args.length &lt; 4) &#123;</span></span><br><span class="line">    <span class="comment">//      System.err.println("Usage: KafkaWordCount &lt;zkQuorum&gt;     &lt;group&gt; &lt;topics&gt; &lt;numThreads&gt;")</span></span><br><span class="line">    <span class="comment">//      System.exit(1)</span></span><br><span class="line">     <span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//    StreamingExamples.setStreamingLogLevels()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//val Array(zkQuorum, group, topics, numThreads) = args</span></span><br><span class="line">    <span class="keyword">val</span> zkQuorum = <span class="string">"localhost:2181"</span></span><br><span class="line">    <span class="keyword">val</span> group = <span class="string">"1"</span></span><br><span class="line">    <span class="keyword">val</span> topics = <span class="string">"test"</span></span><br><span class="line">    <span class="keyword">val</span> numThreads = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"KafkaWordCount"</span>).setMaster(<span class="string">"local[2]"</span>)</span><br><span class="line">    <span class="keyword">val</span> ssc =  <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">2</span>))</span><br><span class="line">    ssc.checkpoint(<span class="string">"checkpoint"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> topicpMap = topics.split(<span class="string">","</span>).map((_,numThreads)).toMap</span><br><span class="line">    <span class="keyword">val</span> lines = <span class="type">KafkaUtils</span>.createStream(ssc, zkQuorum, group, topicpMap).map(_._2)</span><br><span class="line">    <span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> pairs = words.map(word =&gt; (word, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wordCounts = pairs.reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//val wordCounts = words.map(x =&gt; (x, 1L))</span></span><br><span class="line">    <span class="comment">//  .reduceByKeyAndWindow(_ + _, _ - _, Minutes(10), Seconds(2), 2)</span></span><br><span class="line">    wordCounts.print()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>build.sbt</code> 文件中添加依赖<br> &gt;<br> libraryDependencies += “org.apache.spark” % “spark-streaming_2.10” % “1.1.0”<br>&gt;<br>libraryDependencies += “org.apache.spark” % “spark-streaming-kafka_2.10” % “1.1.0”</p>
<p>启动scala程序，然后在 上面第2步的 生产者终端中输入一些字符串，如  <code>sdfsadf a aa a a a a a a a a</code> ，在ide的控制台上可以看到有信息输出<br> &gt;<br>4/11/12 16:38:22 INFO scheduler.DAGScheduler: Stage 195 (take at DStream.scala:608) finished in 0.004 s<br>-——————————————<br>Time: 1415781502000 ms<br>-——————————————<br>(aa,1)<br>(a,9)<br>(sdfsadf,1)</p>
<p>说明程序成功运行。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Sqoop使用]]></title>
      <url>http://todu.top/sqoop/Sqoop%E4%BD%BF%E7%94%A8/</url>
      <content type="html"><![CDATA[<p><code>sqoop help</code> 查看帮助信息<br><code>sqoop help COMMAND</code> 查看 COMMAND具体的帮助，如要查看 list-databases 命令的用法，则使用 <code>sqoop help list-databases</code> 查看。</p>
<p>主要可用的命令如下：</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>help</td>
<td>List available commands</td>
</tr>
<tr>
<td>import</td>
<td>Import a table from a database to HDFS</td>
</tr>
<tr>
<td>list-databases</td>
<td>List available databases on a server</td>
</tr>
<tr>
<td>list-tables</td>
<td>List available tables in a database</td>
</tr>
</tbody>
</table>
<p>主要参数说明</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>–connect</td>
<td>用来指定jdbc链接url，如mysql的: jdbc:mysql://ip:port/database</td>
</tr>
<tr>
<td>–password</td>
<td>指定密码， 安全起见，建议使用 -P 参数，交互式填写密码或者使用 –password-file参数</td>
</tr>
<tr>
<td>–password-file</td>
<td>指定密码的文件，从该文件中读取密码</td>
</tr>
<tr>
<td>–username</td>
<td>指定用户名</td>
</tr>
</tbody>
</table>
<p>用help查看帮助，使用示例：<br>list-databases 是列出所有的数据库，sqoop help list-databases· 查看使用方法</p>
<p>使用示例，查看 本机上的mysql中的数据库<br>./sqoop  list-databases –connect jdbc:mysql://127.0.0.1:3306/test –username username -P<br>这样直接操作会提示找不到驱动，我们需要把对应的mysql驱动jar包放到$SQOOP/lib目录下，然后再次执行就可以了，或者用参数 -libjars 指定驱动jar包路径。</p>
<h1 id="配置项说明"><a href="#配置项说明" class="headerlink" title="配置项说明"></a>配置项说明</h1><p>按照此处的配置项进行可避免文末的错误，如果遇到错误请参考文末错误说明和解决方法。</p>
<ol>
<li>sqoop 要使用对应的hadoop版本，如使用的hadoo版本是2.0.4，那么对应的sqoop版本就要使用文件名包含hadoop2.0.4的信息的版本。</li>
<li>SQOOP_HOME   环境变量关系到sqoop运行时选择的版本问题，所以该变量请配置成正确的版本路径。如果配置成了别的，虽然执行命令是在正确的路径下执行，而真实运行的版本却是其他的版本，该问题可以通过运行sqoop version 查看，此问题比较隐晦，要注意。</li>
<li>执行sqoop所对应的SQOOP_HOME 文件要和hdfs文件系统上的一致，否则会产生找不到对应库文件的错误。</li>
<li>在/etc/hosts 文件中增加 archeagle 到 hdfs节点ip的映射，否则sqoop会用默认的ip映射，会连接不上。</li>
<li><p>用户权限问题，可以在 文件 hadoop/etc/hadoop/hdfs-site.xml中增加或者修改 配置</p>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.acls.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>hdfs 集群要启动yarn服务。</p>
</li>
</ol>
<h1 id="import-的使用"><a href="#import-的使用" class="headerlink" title="import 的使用"></a>import 的使用</h1><p>常用参数说明</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>-fs</td>
<td>指定hdfs节点</td>
</tr>
<tr>
<td>–target-dir</td>
<td>要到处到hdfs文件系统上的文件路径</td>
</tr>
<tr>
<td>–table</td>
<td>要导出的表名</td>
</tr>
<tr>
<td>–connect</td>
<td>jdbc url</td>
</tr>
<tr>
<td>–username</td>
<td>数据库用户名</td>
</tr>
<tr>
<td>-P</td>
<td>从控制台输入密码</td>
</tr>
</tbody>
</table>
<p>使用示例 ：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop  import -fs hdfs://192.168.6.63:9000 --target-dir /user/admin/<span class="built_in">export</span>_<span class="built_in">test</span>_admin_user11  --table admin_user --connect jdbc:mysql://192.168.6.201:3306/<span class="built_in">test</span> --username username -P</span><br></pre></td></tr></table></figure></p>
<h2 id="增量导入-原始链接"><a href="#增量导入-原始链接" class="headerlink" title="增量导入 原始链接"></a>增量导入 <a href="http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_incremental_imports" target="_blank" rel="external">原始链接</a></h2><p>主要参数如下：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>–incrementa</td>
<td>增量方式， 有两种方式，lastmodified和append</td>
</tr>
<tr>
<td>–last-value</td>
<td>以lastmodified方式的增量追加，要指定时间；append则要指定偏移id</td>
</tr>
<tr>
<td>–check-column</td>
<td>要检查的字段， 即以哪个字段为标准计算增量范围</td>
</tr>
<tr>
<td>–append</td>
<td>指定以增量方式追加</td>
</tr>
</tbody>
</table>
<p>使用增量导入（以时间为标识作参考）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop  import -fs hdfs://192.168.6.63:9000 --target-dir /user/admin/<span class="built_in">export</span>_<span class="built_in">test</span>_admin_user11  --table admin_user --connect jdbc:mysql://192.168.6.201:3306/forseti_core --username forseti -P--incremental lastmodified --check-column gmt_create --last-value <span class="string">'2012-02-01 11:0:00'</span> --verbose --append</span><br></pre></td></tr></table></figure></p>
<p>使用增量导入（以id为标识作为参考）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop  import -fs hdfs://192.168.6.63:9000 --target-dir /user/admin/<span class="built_in">export</span>_<span class="built_in">test</span>_admin_user11  --table admin_user --connect jdbc:mysql://192.168.6.201:3306/forseti_core --username forseti -P--incremental append --check-column id --verbose --append</span><br></pre></td></tr></table></figure></p>
<h2 id="使用select语句-e或者–query参数"><a href="#使用select语句-e或者–query参数" class="headerlink" title="使用select语句(-e或者–query参数)"></a>使用select语句(-e或者–query参数)</h2><p>如果使用这个参数，那么可以执行自定义语句，比如可以执行join操作等其他复杂sql语句，但是语句中where是必须的，而且where后面要加 $CONDITIONS 参数。sql语句本身可以用单引号包裹，但是如果sql语句中已经包含了单引号，那么可以用双引号包裹。另外，使用了这个参数，那么参数 –split-by 在import命令中是必须的，而且该参数后面指定的字段必须出现在sql查询结果中。因为通过观察sqoop执行过程中输出的执行sql可以发现，它是在原有的sql上包裹一层，如下示例中，结果就变成了 SELECT MIN(gmt_modified), MAX(gmt_modified) FROM (select id from admin_user where  (1 = 1) ) AS t1。<br>使用示例：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop  import  --connect jdbc:mysql://192.168.6.201:3306/<span class="built_in">test</span> --username username -P <span class="_">-e</span> <span class="string">"select id from test where <span class="variable">$CONDITIONS</span>"</span> --split-by id</span><br></pre></td></tr></table></figure></p>
<h1 id="job-使用"><a href="#job-使用" class="headerlink" title="job 使用"></a>job 使用</h1><h2 id="主要参数"><a href="#主要参数" class="headerlink" title="主要参数"></a>主要参数</h2><table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>–create <job-id></job-id></td>
<td>Create a new saved job</td>
</tr>
<tr>
<td>–delete <job-id></job-id></td>
<td>Delete a saved job</td>
</tr>
<tr>
<td>–exec <job-id></job-id></td>
<td>Run a saved job</td>
</tr>
<tr>
<td>–help</td>
<td>Print usage instructions</td>
</tr>
<tr>
<td>–list</td>
<td>List saved jobs</td>
</tr>
<tr>
<td>–show <job-id></job-id></td>
<td>Show the parameters for a saved job</td>
</tr>
<tr>
<td>-fs &lt;local</td>
<td>namenode:port&gt;</td>
<td>specify a namenode</td>
</tr>
<tr>
<td>-libjars <comma separated="" list="" of="" jars=""></comma></td>
<td>specify comma separated jar files to include in the classpath.</td>
</tr>
<tr>
<td>-conf <configuration file=""></configuration></td>
<td>specify an application configuration file</td>
</tr>
</tbody>
</table>
<h2 id="创建Job示例："><a href="#创建Job示例：" class="headerlink" title="创建Job示例："></a>创建Job示例：</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop job --create <span class="built_in">export</span>_mysql_table -- import --table admin_user --connect jdbc:mysql://192.168.6.201:3306/forseti_core</span><br></pre></td></tr></table></figure>
<h2 id="执行Job示例："><a href="#执行Job示例：" class="headerlink" title="执行Job示例："></a>执行Job示例：</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop job -fs hdfs://192.168.6.63:9000 --exec  <span class="built_in">export</span>_mysql_table --  --username forseti -P --target-dir /user/admin/<span class="built_in">export</span>_<span class="built_in">test</span>_admin_user11112</span><br></pre></td></tr></table></figure>
<h2 id="执行带密码的任务"><a href="#执行带密码的任务" class="headerlink" title="执行带密码的任务"></a>执行带密码的任务</h2><p>有密码要求的任务，如果不存储密码的话，每次执行任务都要求手动输入密码，如果是定时任务，那么这个肯定是不合理的。默认metastore是不保存密码的，如果需要保存，则在conf/sqoop-site.xml增加或者取消注释如下内容</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>sqoop.metastore.client.record.password<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, allow saved passwords in the metastore.</span><br><span class="line">   <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h1 id="错误解决"><a href="#错误解决" class="headerlink" title="错误解决"></a>错误解决</h1><ul>
<li><p>ERROR tool.ImportTool: Encountered IOException running import job: java.io.FileNotFoundException: File does not exist: hdfs://192.168.6.63:9000/home/du/software/dev/sqoop-1.4.5.bin__hadoop-0.20/lib/ant-contrib-1.0b3.jar</p>
<pre><code>在不同机器或者用户下执行sqoop，会查找hadoop集群指定的节点上的hdfs目录中的这个文件，比如我是用在/home/du/software/dev/sqoop-1.4.5.bin__hadoop-0.20 下执行的sqoop，并且SQOOP_HOME配置的也是这个路径，那么到hdfs://192.168.6.63:9000上就会查找/home/du/software/dev/sqoop-1.4.5.bin__hadoop-0.20/lib这个路径下的ant-contrib-1.0b3.jar这个文件，解决方法就是在hdfs上创建对应目录，并把sqoop拷贝到对应目录，目录结构和执行sqoop的目录结构一样即可。
</code></pre></li>
<li><p>Exception in thread “main” java.lang.IncompatibleClassChangeError: Found interface org.apache.hadoop.mapreduce.JobContext, but class was expected</p>
<pre><code>使用的hadoop版本问题，从2.6.0切换到2.4.0 解决
</code></pre></li>
<li><p>ERROR tool.ImportTool: Encountered IOException running import job: org.apache.hadoop.security.AccessControlException: Permission denied: user=du, access=WRITE, inode=”/user”:admin:supergroup:drwxr-xr-x</p>
</li>
<li><p>ERROR manager.SqlManager: Error executing statement: java.sql.SQLException: Access denied for user ‘forseti’@’192.168.6.165’ (using password: YES)</p>
<pre><code>很明显是mysql的用户登陆失败，填写正确的用户名和密码即可解决该问题。
</code></pre></li>
<li><p>15/03/05 17:40:10 INFO mapreduce.Job: Running job: job_1425543105230_0006<br>15/03/05 17:40:44 INFO ipc.Client: Retrying connect to server: archeagle/220.250.64.20:43175. Already tried 0 time(s); maxRetries=3<br>15/03/05 17:41:04 INFO ipc.Client: Retrying connect to server: archeagle/220.250.64.20:43175. Already tried 1 time(s); maxRetries=3<br>15/03/05 17:41:24 INFO ipc.Client: Retrying connect to server: archeagle/220.250.64.20:43175. Already tried 2 time(s); maxRetries=3<br>15/03/05 17:41:44 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=FAILED. Redirecting to job history server<br>15/03/05 17:41:44 ERROR tool.ImportTool: Encountered IOException running import job: java.io.IOException: Job status not available<br>  at org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:322)<br>  at org.apache.hadoop.mapreduce.Job.isComplete(Job.java:599)<br>  at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)<br>  at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1306)<br>  at org.apache.sqoop.mapreduce.ImportJobBase.doSubmitJob(ImportJobBase.java:186)<br>  at org.apache.sqoop.mapreduce.ImportJobBase.runJob(ImportJobBase.java:159)<br>  at org.apache.sqoop.mapreduce.ImportJobBase.runImport(ImportJobBase.java:247)<br>  at org.apache.sqoop.manager.DirectMySQLManager.importTable(DirectMySQLManager.java:92)<br>  at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:497)<br>  at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:601)<br>  at org.apache.sqoop.Sqoop.run(Sqoop.java:143)<br>  at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)<br>  at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:179)<br>  at org.apache.sqoop.Sqoop.runTool(Sqoop.java:218)<br>  at org.apache.sqoop.Sqoop.runTool(Sqoop.java:227)<br>  at org.apache.sqoop.Sqoop.main(Sqoop.java:236)</p>
<pre><code>在运行sqoop的主机hosts文件增减加hadoop节点ip映射 192.168.6.63 archeagle
</code></pre></li>
<li><p>使用–direct参数<br>Error: java.io.IOException: Cannot run program “mysqldump”: error=2, No such file or directory<br>  at java.lang.ProcessBuilder.start(ProcessBuilder.java:1047)<br>  at java.lang.Runtime.exec(Runtime.java:617)<br>  at java.lang.Runtime.exec(Runtime.java:485)<br>  at org.apache.sqoop.mapreduce.MySQLDumpMapper.map(MySQLDumpMapper.java:405)<br>  at org.apache.sqoop.mapreduce.MySQLDumpMapper.map(MySQLDumpMapper.java:49)<br>  at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)<br>  at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)<br>  at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)<br>  at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)<br>  at java.security.AccessController.doPrivileged(Native Method)<br>  at javax.security.auth.Subject.doAs(Subject.java:415)<br>  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)<br>  at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)<br>Caused by: java.io.IOException: error=2, No such file or directory<br>  at java.lang.UNIXProcess.forkAndExec(Native Method)<br>  at java.lang.UNIXProcess.<init>(UNIXProcess.java:186)<br>  at java.lang.ProcessImpl.start(ProcessImpl.java:130)<br>  at java.lang.ProcessBuilder.start(ProcessBuilder.java:1028)<br>  … 12 more</init></p>
<ul>
<li><p>ERROR tool.ImportTool: Encountered IOException running import job: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot delete /user/du/.staging/job_1425543105230_0010. Name node is in safe mode.<br>The reported blocks 0 needs additional 963 blocks to reach the threshold 0.9990 of total blocks 963.<br>The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.<br>at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1199)<br>at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInternal(FSNamesystem.java:3336)<br>at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.deleteInt(FSNamesystem.java:3296)<br>at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:3280)<br>at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:727)</p>
<pre><code>hdfs上(用户)目录不存在。
</code></pre></li>
</ul>
</li>
<li><p>INFO ipc.Client: Retrying connect to server: arch57/220.250.64.20:56564. Already tried 2 time(s); maxRetries=3<br>15/03/10 15:47:55 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server<br>15/03/10 15:47:55 ERROR tool.ImportTool: Encountered IOException running import job: java.io.IOException: Job status not available<br>  at org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:322)<br>  at org.apache.hadoop.mapreduce.Job.isComplete(Job.java:599)<br>  at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)<br>  at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1306)<br>  at org.apache.sqoop.mapreduce.ImportJobBase.doSubmitJob(ImportJobBase.java:186)<br>  at org.apache.sqoop.mapreduce.ImportJobBase.runJob(ImportJobBase.java:159)<br>  at org.apache.sqoop.mapreduce.ImportJobBase.runImport(ImportJobBase.java:247)<br>  at org.apache.sqoop.manager.SqlManager.importTable(SqlManager.java:665)<br>  at org.apache.sqoop.manager.MySQLManager.importTable(MySQLManager.java:118)<br>  at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:497)<br>  at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:601)<br>  at org.apache.sqoop.tool.JobTool.execJob(JobTool.java:228)<br>  at org.apache.sqoop.tool.JobTool.run(JobTool.java:283)<br>  at org.apache.sqoop.Sqoop.run(Sqoop.java:143)<br>  at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)<br>  at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:179)<br>  at org.apache.sqoop.Sqoop.runTool(Sqoop.java:218)<br>  at org.apache.sqoop.Sqoop.runTool(Sqoop.java:227)<br>  at org.apache.sqoop.Sqoop.main(Sqoop.java:236)</p>
<pre><code>在执行sqoop的机器的hosts增加 arch57 这个主机ip映射（PS:arch57 是一台hadoop机器的名字）
</code></pre></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Apache-Sqoop 安装]]></title>
      <url>http://todu.top/sqoop/Apache-Sqoop-%E5%AE%89%E8%A3%85/</url>
      <content type="html"><![CDATA[<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>首先当然是<a href="http://archive.apache.org/dist/sqoop/1.4.4/sqoop-1.4.4.bin__hadoop-2.0.4-alpha.tar.gz" target="_blank" rel="external">下载sqoop</a><br>sqoop 依赖以下软件,点击链接可以直接下载<br>&gt;<br><a href="http://ftp.yz.yamagata-u.ac.jp/pub/network/apache/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz" target="_blank" rel="external">hadoop</a><br><a href="http://ftp.yz.yamagata-u.ac.jp/pub/network/apache/accumulo/1.6.2/accumulo-1.6.2-bin.tar.gz" target="_blank" rel="external">accumulo</a><br><a href="http://ftp.tsukuba.wide.ad.jp/software/apache/hive/hive-1.0.0/apache-hive-1.0.0-bin.tar.gz" target="_blank" rel="external">apache-hive</a><br><a href="http://ftp.kddilabs.jp/infosystems/apache/hbase/hbase-1.0.0/hbase-1.0.0-bin.tar.gz" target="_blank" rel="external">hbase</a><br><a href="http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz" target="_blank" rel="external">zookeeper</a></p>
<h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><h2 id="配置JAVA环境变量"><a href="#配置JAVA环境变量" class="headerlink" title="配置JAVA环境变量"></a>配置JAVA环境变量</h2><p>JAVA_HOME=/home/du/software/dev/jdk1.7.0_45<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/install/java  <span class="comment">#此处换成自己的jdk目录</span></span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/jre/lib</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br></pre></td></tr></table></figure></p>
<h2 id="配置sqoop运行依赖"><a href="#配置sqoop运行依赖" class="headerlink" title="配置sqoop运行依赖"></a>配置sqoop运行依赖</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=/home/du/software/dev/hadoop-2.6.0</span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_COMMON_HOME</span>/share/hadoop/mapreduce</span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/home/du/software/dev/zookeeper-3.4.6</span><br><span class="line"><span class="built_in">export</span> ACCUMULO_HOME=/usr/install/accumulo-1.6.2</span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/install/apache-hive-1.0.0-bin</span><br><span class="line"><span class="built_in">export</span> HCAT_HOME=/usr/install/apache-hive-1.0.0-bin/hcatalog</span><br><span class="line"><span class="built_in">export</span> HBASE_HOME=/usr/install/hbase-1.0.0</span><br><span class="line"><span class="built_in">export</span> SQOOP_HOME=/usr/install/sqoop-1.4.4.bin__hadoop-2.0.4-alpha</span><br></pre></td></tr></table></figure>
<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>切换到sqoop目录，运行 <code>bin/sqoop help</code>， 如果打印帮助文档则说明成功。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[alert]]></title>
      <url>http://todu.top/fun/%E8%80%81%E5%85%AC%E6%9D%A5%E4%BA%86/</url>
      <content type="html"><![CDATA[<script>
alert("老公来了，快来接驾");
alert("开玩笑的");
alert("老公不是在群里吗");
alert("其实我是故意整你的");
alert("输入密码解除弹窗");
var pw = null;
do  {
    pw = prompt("输入密码");
} while(pw!="豆芽老公我爱你")
alert("真乖");
    location.href="http://todu.top"
</script>]]></content>
    </entry>
    
  
  
</search>
